{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bca4a78b8c4247baa58d460b577f286f": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_75855a67e42442d494e6ee0f3332a34d",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "\u001b[38;2;106;0;255m⠹\u001b[0m ✨ You're running DeepEval's latest \u001b[38;2;106;0;255mRole Adherence Metric\u001b[0m! \u001b[38;2;55;65;81m(using gpt-4o, strict=False, async_mode=True)...\u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">⠹</span> ✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Role Adherence Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using gpt-4o, strict=False, async_mode=True)...</span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "75855a67e42442d494e6ee0f3332a34d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f53260ea252416d949501fedb872c40": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_7c4db1ab27614243bac43f27b085cf8c",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "\u001b[38;2;106;0;255m⠹\u001b[0m ✨ You're running DeepEval's latest \u001b[38;2;106;0;255mKnowledge Retention Metric\u001b[0m! \u001b[38;2;55;65;81m(using gpt-4o, strict=False, async_mode=True)...\u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">⠹</span> ✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Knowledge Retention Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using gpt-4o, strict=False, async_mode=True)...</span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "7c4db1ab27614243bac43f27b085cf8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe414bdb4c7b48ab967630e7ae4dc2bc": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_820b1f8bd41f4525abb1e4375e7ba4a0",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mConversation Completeness Metric\u001b[0m! \u001b[38;2;55;65;81m(using gpt-4o, strict=False, async_mode=True…\u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Conversation Completeness Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using gpt-4o, strict=False, async_mode=True…</span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "820b1f8bd41f4525abb1e4375e7ba4a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f3802c304de4844b4db3e672b7ca47b": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_ae49467c01a347d4b46660628eda6cc2",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mConversation Relevancy Metric\u001b[0m! \u001b[38;2;55;65;81m(using gpt-4o, strict=False, async_mode=True)...\u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Conversation Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using gpt-4o, strict=False, async_mode=True)...</span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "ae49467c01a347d4b46660628eda6cc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "bud5EAeQ7OIu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZH3K3iB6_Sd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a20d76c5-bb38-437f-e20b-611fce6ed831"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/558.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m558.7/558.7 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qqU deepeval datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code installs two Python packages silently: deepeval and datasets.\n",
        "\n",
        "The `!` at the start tells Jupyter notebook or Google Colab to run this as a shell command rather than Python code.\n",
        "\n",
        "The `pip install` command downloads and installs packages from the Python Package Index (PyPI). The flags `-qqU` modify how pip behaves:\n",
        "- `-qq` means \"very quiet\" - it suppresses most output messages\n",
        "- `-U` means \"upgrade\" - it updates the packages to their latest versions if they're already installed\n",
        "\n",
        "deepeval is a package for evaluating deep learning models, while datasets provides easy access to many public datasets used in machine learning. Installing them together suggests this code is part of setting up an environment for machine learning work, specifically focused on model evaluation.\n",
        "\n",
        "The quiet installation flags indicate this is likely part of a larger notebook where the installation output isn't meant to distract from the main content."
      ],
      "metadata": {
        "id": "avL_-C6j99jW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Standard library imports\n",
        "import json\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "\n",
        "# Third-party imports\n",
        "import numpy as np\n",
        "from google.colab import drive, userdata\n",
        "from deepeval import evaluate\n",
        "from deepeval.metrics import (\n",
        "    ConversationalGEval,\n",
        "    RoleAdherenceMetric,\n",
        "    KnowledgeRetentionMetric,\n",
        "    ConversationCompletenessMetric,\n",
        "    ConversationRelevancyMetric\n",
        ")\n",
        "from deepeval.test_case import LLMTestCase, ConversationalTestCase, LLMTestCaseParams\n",
        "\n",
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "A6v8PghoCyVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code organizes the import statements for a machine learning evaluation project, specifically focused on analyzing conversations. Let me break down each part:\n",
        "\n",
        "The standard library imports bring in essential Python tools:\n",
        "- `json` handles reading and writing JSON data formats\n",
        "- `os` and its specific functions (`listdir`, `join`, `isfile`) help work with files and directories across different operating systems\n",
        "\n",
        "The third-party imports bring in specialized tools for machine learning evaluation:\n",
        "\n",
        "From NumPy (`np`), we get powerful numerical computing capabilities, which form the foundation for most machine learning operations.\n",
        "\n",
        "The Google Colab imports (`drive`, `userdata`) let the code interact with Google Drive storage and user-specific data in the Colab environment.\n",
        "\n",
        "The `deepeval` imports set up a comprehensive conversation evaluation framework:\n",
        "- `ConversationalGEval` evaluates the general quality of conversations\n",
        "- `RoleAdherenceMetric` checks if participants stay true to their assigned roles\n",
        "- `KnowledgeRetentionMetric` measures how well information is remembered throughout a conversation\n",
        "- `ConversationCompletenessMetric` assesses if conversations reach satisfactory conclusions\n",
        "- `ConversationRelevancyMetric` evaluates if responses stay on topic\n",
        "\n",
        "The test case imports (`LLMTestCase`, `ConversationalTestCase`, `LLMTestCaseParams`) provide structures for organizing and running these evaluations systematically.\n",
        "\n",
        "Finally, `load_dataset` from the `datasets` library gives access to pre-made datasets, which serve as benchmarks or training data for the evaluation process.\n"
      ],
      "metadata": {
        "id": "ilqrpe2u9-BO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CFG:\n",
        "    model = 'gpt-4o-mini'\n",
        "    temp = 0.3\n",
        "    dataset = 'flpelerin/ChatAlpaca-10k'"
      ],
      "metadata": {
        "id": "9silUTN17ehG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code defines a configuration class named `CFG` that acts as a central place to store important settings for a machine learning project. Let me explain how this works and why it's useful.\n",
        "\n",
        "The class functions like a container for project-wide settings, following a common pattern in machine learning where configurations need to be easily accessible and modifiable. Inside the class, three key parameters are defined:\n",
        "\n",
        "First, `model` is set to 'gpt-4o-mini', which specifies which language model will be used for the project. The name suggests this is a smaller version of a GPT-4-like model, optimized for efficiency while maintaining reasonable performance.\n",
        "\n",
        "Second, `temp` (short for temperature) is set to 0.3. Temperature is a crucial parameter in language models that controls how random or deterministic the model's outputs will be. A temperature of 0.3 is relatively low, which means the model will generate more focused, consistent responses rather than creative or diverse ones. Think of it like a thermostat - lower settings produce more predictable results.\n",
        "\n",
        "Third, `dataset` points to 'flpelerin/ChatAlpaca-10k', which identifies the specific dataset that will be used. The format suggests this is hosted on a platform like Hugging Face, and contains 10,000 conversation examples based on the Alpaca training format.\n",
        "\n",
        "By grouping these settings in a class, the code makes it simple to maintain consistent configurations across different parts of the project. If you need to change the model or adjust the temperature, you only need to modify it in one place rather than hunting through multiple files or functions. This organization style also makes it easier for team members to understand and modify the project's core settings."
      ],
      "metadata": {
        "id": "h1YShLTs9-mQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# setup OpenAI connection\n",
        "api_key = userdata.get('openaivision')\n",
        "os.environ['OPENAI_API_KEY'] = api_key"
      ],
      "metadata": {
        "id": "I1xRO7SIB5OT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let me explain how this code sets up a secure connection to OpenAI's API, which will be used for making calls to their AI models. This is a critical piece of security infrastructure that bridges your local development environment with OpenAI's services.\n",
        "\n",
        "The first line `api_key = userdata.get('openaivision')` retrieves an API key that's been securely stored in Google Colab's user data system. Think of this like retrieving a special password from a secure vault - the 'openaivision' parameter tells Colab which specific key to fetch. This approach is much safer than hardcoding the API key directly in the code, where it could be accidentally shared or exposed.\n",
        "\n",
        "The second line `os.environ['OPENAI_API_KEY'] = api_key` takes that retrieved key and stores it in the system's environment variables. Environment variables act like a secure, temporary storage space that exists only while your program is running. When you store the API key here, other parts of your code can access it safely without needing to pass it around explicitly.\n",
        "\n",
        "The name 'openaivision' suggests this key might be specifically for accessing OpenAI's vision-related APIs, though it could potentially be used for other OpenAI services as well. This setup follows security best practices by keeping sensitive credentials out of the source code and managing them through proper credential management systems.\n",
        "\n",
        "It's worth noting that this setup is running in Google Colab, which provides additional security benefits since Colab sessions are temporary and isolated. When the session ends, these environment variables are cleared automatically, adding an extra layer of security to your API key management."
      ],
      "metadata": {
        "id": "kyN5ph5h9_GX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Funkcje"
      ],
      "metadata": {
        "id": "bISzCqwIS7qL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# largest even number no greater than k\n",
        "def laevnu(k):\n",
        "\n",
        "    if k % 2 == 0:\n",
        "        return k\n",
        "\n",
        "    return k - 1"
      ],
      "metadata": {
        "id": "4SJor2VxS89I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let me explain this function, which finds the largest even number that doesn't exceed a given input number. Let's break it down step by step to understand how it works.\n",
        "\n",
        "The function name `laevnu` appears to be an acronym for \"largest even number no greater than k\", where k is the input parameter. When you call this function with any number k, it will return the largest possible even number that's less than or equal to k.\n",
        "\n",
        "Here's how the function makes its decision:\n",
        "\n",
        "First, it checks if k is already even by using the modulo operator `%`. When you divide a number by 2, the modulo operation gives you the remainder. If k % 2 equals 0, that means k divides evenly by 2 with no remainder – in other words, k is even. In this case, the function simply returns k since it's already the largest even number no greater than itself.\n",
        "\n",
        "If k is not even (meaning k % 2 equals 1), then k must be odd. In this case, we need to go down by 1 to reach the next even number. The function does this with `k - 1`. This works because every odd number has an even number exactly one less than it.\n",
        "\n",
        "For example:\n",
        "- If k = 8, it's even, so the function returns 8\n",
        "- If k = 7, it's odd, so the function returns 6\n",
        "- If k = 4, it's even, so the function returns 4\n",
        "- If k = 3, it's odd, so the function returns 2\n",
        "\n",
        "This function is quite efficient because it makes just one simple check and at most one simple calculation, regardless of how large the input number is. It's a good example of how understanding the mathematical relationship between even and odd numbers lets us solve what might seem like a searching problem with just a single comparison."
      ],
      "metadata": {
        "id": "Vxd9j-UPTAJu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_list_of_test_cases(dd):\n",
        "  test_cases = []\n",
        "  for jj in range(0, laevnu(len(dd)) , 2):\n",
        "    tc = LLMTestCase(  input = dd[jj]['value'], actual_output= dd[jj+1]['value'] )\n",
        "    test_cases.append(tc)\n",
        "\n",
        "  return test_cases"
      ],
      "metadata": {
        "id": "KCJOGmHgTLkW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let me explain this function from the ground up. It's designed to pair up items from a dataset into test cases that can evaluate how well an AI model performs. I'll break it down step by step and explain the underlying concepts.\n",
        "\n",
        "First, let's understand what this function is trying to achieve. When testing AI models, we need organized pairs of inputs and corresponding expected outputs. Think of it like creating flash cards for studying – each card has a question on one side and the correct answer on the other. This function automates that pairing process.\n",
        "\n",
        "The function takes a parameter `dd`, which stands for data and represents our raw testing material. This data is structured as a list of dictionaries, where each dictionary has a 'value' key. Imagine you have a sequence like this:\n",
        "```python\n",
        "dd = [\n",
        "    {'value': 'What is the capital of France?'},\n",
        "    {'value': 'Paris'},\n",
        "    {'value': 'What is 2+2?'},\n",
        "    {'value': '4'}\n",
        "]\n",
        "```\n",
        "\n",
        "The function processes this data in three main steps:\n",
        "\n",
        "1. It starts by creating an empty list called `test_cases`. This will be our collection of paired questions and answers.\n",
        "\n",
        "2. The core of the function is a loop that processes items two at a time. The loop uses `range(0, laevnu(len(dd)), 2)`, which means:\n",
        "   - Start at index 0\n",
        "   - Count up by 2s (to grab pairs of items)\n",
        "   - Stop at the largest even number no greater than the length of dd (that's what laevnu does)\n",
        "\n",
        "   This clever use of `laevnu` ensures we only process complete pairs. If we have an odd number of items, the last unpaired item is safely ignored, preventing errors.\n",
        "\n",
        "3. For each pair of items, the function creates a `LLMTestCase` object. This object is designed specifically for testing language models (LLM stands for Large Language Model). It takes two parameters:\n",
        "   - `input`: The first item of the pair (the question)\n",
        "   - `actual_output`: The second item of the pair (the expected answer)\n",
        "\n",
        "Here's what happens in practice with our example data:\n",
        "```python\n",
        "First iteration (jj = 0):\n",
        "- input = \"What is the capital of France?\"\n",
        "- actual_output = \"Paris\"\n",
        "\n",
        "Second iteration (jj = 2):\n",
        "- input = \"What is 2+2?\"\n",
        "- actual_output = \"4\"\n",
        "```\n",
        "\n",
        "Each test case is added to our list, and finally, the complete collection is returned. This organized structure makes it easy to systematically test an AI model by comparing its responses to the expected outputs.\n",
        "\n",
        "The beauty of this function lies in its simplicity and robustness. By processing items in pairs and using `laevnu` to handle the list length, it elegantly manages potential edge cases like incomplete pairs. This careful design ensures reliable test case creation, which is crucial for meaningful AI model evaluation."
      ],
      "metadata": {
        "id": "IX2IGrY7Vkoh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dane"
      ],
      "metadata": {
        "id": "y0KE64SaDLlO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the conversational dataset\n",
        "dataset = load_dataset(CFG.dataset, split = \"train\")"
      ],
      "metadata": {
        "id": "IgVHjq1DDQVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let me explain this important line of code that loads data for training an AI model. The code connects to a specific dataset and prepares it for use in machine learning tasks, particularly those involving conversations.\n",
        "\n",
        "The `load_dataset` function comes from the Hugging Face datasets library, which serves as a central hub for machine learning datasets - think of it like a digital library where researchers and developers can access collections of organized data. This function reaches out to that library and retrieves the dataset we want to work with.\n",
        "\n",
        "The function takes two key parameters that tell it exactly what data we want and how we want it organized:\n",
        "\n",
        "First, `CFG.dataset` refers to the dataset identifier we specified earlier in our configuration class - in this case, 'flpelerin/ChatAlpaca-10k'. The format of this identifier tells us two things: 'flpelerin' is the creator or owner of the dataset, and 'ChatAlpaca-10k' suggests it's a collection of 10,000 conversation examples based on the Alpaca training format. Alpaca is a notable project that aims to create more natural and capable language models.\n",
        "\n",
        "Second, the `split = \"train\"` parameter specifies that we want the training portion of the dataset. In machine learning, datasets are often divided into different splits - typically training, validation, and testing. The training split is used to teach the model, while other splits would be used to evaluate its performance. By explicitly requesting the training split, we're preparing to use this data for model training rather than evaluation.\n",
        "\n",
        "Let's look at what happens when this code runs:\n",
        "1. The function connects to the Hugging Face dataset repository\n",
        "2. It locates the specific ChatAlpaca-10k dataset\n",
        "3. It downloads the training split of that dataset\n",
        "4. It returns the data in a format that's ready for machine learning tasks\n",
        "\n",
        "The resulting `dataset` variable will contain structured conversation data that can be used to train or evaluate language models. Each entry in this dataset likely contains pairs of inputs and outputs - perhaps questions and answers, or prompts and responses - that represent the kind of conversational behavior we want our AI model to learn.\n"
      ],
      "metadata": {
        "id": "0m3I9zW2WDOz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0]['conversations']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4CWlkpe-0U2",
        "outputId": "38861231-80ec-4764-a57d-4a8ff23bb85b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'from': 'human', 'value': 'Find the product of the numbers: 5 and 8'},\n",
              " {'from': 'gpt', 'value': 'The product of 5 and 8 is 40.'},\n",
              " {'from': 'human', 'value': 'What is the sum of the numbers 6 and 12?'},\n",
              " {'from': 'gpt', 'value': 'The sum of the numbers 6 and 12 is 18.'},\n",
              " {'from': 'human', 'value': 'Can you tell me the quotient of 20 and 5?'},\n",
              " {'from': 'gpt', 'value': 'Yes, the quotient of 20 and 5 is 4.'},\n",
              " {'from': 'human', 'value': 'What is the difference between 25 and 13?'},\n",
              " {'from': 'gpt', 'value': 'The difference between 25 and 13 is 12.'},\n",
              " {'from': 'human', 'value': 'What is the square of 9?'},\n",
              " {'from': 'gpt', 'value': 'The square of 9 is 81.'},\n",
              " {'from': 'human', 'value': 'What is the cube of 6?'},\n",
              " {'from': 'gpt', 'value': 'The cube of 6 is 216.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[12]['conversations']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyG7NDqLAVec",
        "outputId": "2078c0dc-24c0-4eec-a377-aab043ac85fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'from': 'human',\n",
              "  'value': 'Find the angle in the triangle using trigonometry: AB=5, BC=7, AC=9'},\n",
              " {'from': 'gpt', 'value': 'Angle A = 65.7 degrees'},\n",
              " {'from': 'human', 'value': 'What is the value of Angle B in the triangle?'},\n",
              " {'from': 'gpt',\n",
              "  'value': 'To find the value of angle B in the triangle using trigonometry, we can use the Law of Cosines:\\n\\ncos(B) = (a^2 + c^2 - b^2) / 2ac\\n\\nwhere a, b, and c are the lengths of the sides opposite to angles A, B, and C, respectively.\\n\\nIn this case, we have:\\n\\na = 5 (opposite to angle A)\\nb = ?\\nc = 7 (opposite to angle B)\\n\\nWe can use the Law of Cosines again to find the value of b:\\n\\nb^2 = a^2 + c^2 - 2ac cos(B)\\nb^2 = 5^2 + 7^2 - 2(5)(7) cos(B)\\nb^2 = 25 + 49 - 70 cos(B)\\nb^2 = 74 - 70 cos(B)\\n\\nNow we can substitute this expression for b^2 into the first equation:\\n\\ncos(B) = (a^2 + c^2 - b^2) / 2ac\\ncos(B) = (5^2 + 7^2 - (74 - 70 cos(B))) / (2)(5)(7)\\ncos(B) = (74 - 70 cos(B)) / 70\\n70 cos(B) = 74 - cos(B)\\n71 cos(B) = 74\\ncos(B) = 74 / 71\\nB = 21.37 degrees\\n\\nTherefore, the value of angle B in the triangle is approximately 21.37 degrees.'},\n",
              " {'from': 'human', 'value': 'What is the value of angle C in the triangle?'},\n",
              " {'from': 'gpt',\n",
              "  'value': 'To find the value of angle C in the triangle using trigonometry, we can use the Law of Cosines:\\n\\ncos(C) = (a^2 + b^2 - c^2) / 2ab\\n\\nwhere a, b, and c are the lengths of the sides opposite to angles A, B, and C, respectively.\\n\\nIn this case, we have:\\n\\na = 5 (opposite to angle A)\\nb = √(7^2 + 4^2) = √65 (using Pythagorean theorem with side lengths BC = 7 and AB = 4)\\nc = 9 (opposite to angle C)\\n\\nWe can substitute these values into the Law of Cosines:\\n\\ncos(C) = (5^2 + (√65)^2 - 9^2) / 2(5)(√65)\\ncos(C) = (25 + 65 - 81) / (10√65)\\ncos(C) = 9 / (10√65)\\nC = 29.1 degrees (using calculator)\\n\\nTherefore, the value of angle C in the triangle is approximately 29.1 degrees.'},\n",
              " {'from': 'human',\n",
              "  'value': 'Thank you for explaining the values of angle B and C in the triangle. Goodbye!'}]"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dd = dataset[0]['conversations']\n",
        "dd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ukmJ9IfBPf4",
        "outputId": "f5fa7d21-a70d-4ca8-a71c-558be8e1d3fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'from': 'human', 'value': 'Find the product of the numbers: 5 and 8'},\n",
              " {'from': 'gpt', 'value': 'The product of 5 and 8 is 40.'},\n",
              " {'from': 'human', 'value': 'What is the sum of the numbers 6 and 12?'},\n",
              " {'from': 'gpt', 'value': 'The sum of the numbers 6 and 12 is 18.'},\n",
              " {'from': 'human', 'value': 'Can you tell me the quotient of 20 and 5?'},\n",
              " {'from': 'gpt', 'value': 'Yes, the quotient of 20 and 5 is 4.'},\n",
              " {'from': 'human', 'value': 'What is the difference between 25 and 13?'},\n",
              " {'from': 'gpt', 'value': 'The difference between 25 and 13 is 12.'},\n",
              " {'from': 'human', 'value': 'What is the square of 9?'},\n",
              " {'from': 'gpt', 'value': 'The square of 9 is 81.'},\n",
              " {'from': 'human', 'value': 'What is the cube of 6?'},\n",
              " {'from': 'gpt', 'value': 'The cube of 6 is 216.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[12]['conversations']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7N5gWlqhBoEC",
        "outputId": "3a77e230-0b6a-4536-ee2c-f5d7b078740c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'from': 'human',\n",
              "  'value': 'Find the angle in the triangle using trigonometry: AB=5, BC=7, AC=9'},\n",
              " {'from': 'gpt', 'value': 'Angle A = 65.7 degrees'},\n",
              " {'from': 'human', 'value': 'What is the value of Angle B in the triangle?'},\n",
              " {'from': 'gpt',\n",
              "  'value': 'To find the value of angle B in the triangle using trigonometry, we can use the Law of Cosines:\\n\\ncos(B) = (a^2 + c^2 - b^2) / 2ac\\n\\nwhere a, b, and c are the lengths of the sides opposite to angles A, B, and C, respectively.\\n\\nIn this case, we have:\\n\\na = 5 (opposite to angle A)\\nb = ?\\nc = 7 (opposite to angle B)\\n\\nWe can use the Law of Cosines again to find the value of b:\\n\\nb^2 = a^2 + c^2 - 2ac cos(B)\\nb^2 = 5^2 + 7^2 - 2(5)(7) cos(B)\\nb^2 = 25 + 49 - 70 cos(B)\\nb^2 = 74 - 70 cos(B)\\n\\nNow we can substitute this expression for b^2 into the first equation:\\n\\ncos(B) = (a^2 + c^2 - b^2) / 2ac\\ncos(B) = (5^2 + 7^2 - (74 - 70 cos(B))) / (2)(5)(7)\\ncos(B) = (74 - 70 cos(B)) / 70\\n70 cos(B) = 74 - cos(B)\\n71 cos(B) = 74\\ncos(B) = 74 / 71\\nB = 21.37 degrees\\n\\nTherefore, the value of angle B in the triangle is approximately 21.37 degrees.'},\n",
              " {'from': 'human', 'value': 'What is the value of angle C in the triangle?'},\n",
              " {'from': 'gpt',\n",
              "  'value': 'To find the value of angle C in the triangle using trigonometry, we can use the Law of Cosines:\\n\\ncos(C) = (a^2 + b^2 - c^2) / 2ab\\n\\nwhere a, b, and c are the lengths of the sides opposite to angles A, B, and C, respectively.\\n\\nIn this case, we have:\\n\\na = 5 (opposite to angle A)\\nb = √(7^2 + 4^2) = √65 (using Pythagorean theorem with side lengths BC = 7 and AB = 4)\\nc = 9 (opposite to angle C)\\n\\nWe can substitute these values into the Law of Cosines:\\n\\ncos(C) = (5^2 + (√65)^2 - 9^2) / 2(5)(√65)\\ncos(C) = (25 + 65 - 81) / (10√65)\\ncos(C) = 9 / (10√65)\\nC = 29.1 degrees (using calculator)\\n\\nTherefore, the value of angle C in the triangle is approximately 29.1 degrees.'},\n",
              " {'from': 'human',\n",
              "  'value': 'Thank you for explaining the values of angle B and C in the triangle. Goodbye!'}]"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Metryki\n"
      ],
      "metadata": {
        "id": "lXEwA4Uj7nAl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dlist = create_list_of_test_cases(dataset[12]['conversations'])"
      ],
      "metadata": {
        "id": "upfQkpP7A0xx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Role adherence"
      ],
      "metadata": {
        "id": "D_lMIrNQG1V0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "convo_test_case = ConversationalTestCase(\n",
        "    chatbot_role = \"You are a helpful and polite assistant\",\n",
        "    turns = dlist)\n",
        "\n",
        "\n",
        "metric = RoleAdherenceMetric(threshold=0.5)\n",
        "\n",
        "metric.measure(convo_test_case)\n",
        "print(metric.score)\n",
        "metric.reason"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176,
          "referenced_widgets": [
            "bca4a78b8c4247baa58d460b577f286f",
            "75855a67e42442d494e6ee0f3332a34d"
          ]
        },
        "id": "lFgOQGSxDIQ0",
        "outputId": "c135a90c-a941-418a-83b0-13fe139892f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bca4a78b8c4247baa58d460b577f286f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "False @\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">False @\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.3333333333333333\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The score is 0.3333333333333333 because the LLM chatbot responses in turns #2 and #3 deviated significantly from the role of a \"helpful and polite assistant.\" \\n\\nIn turn #2, the response given is: \\'To find the value of angle B in the triangle using trigonometry, we can use the Law of Cosines... B = 21.37 degrees.\\' This response is overly technical and lengthy, making it difficult for a layperson to understand quickly. It lacks the conduciveness of a polite assistant by not simplifying or breaking down the explanation in a more approachable manner, potentially overwhelming the user.\\n\\nIn turn #3, the response \\'To find the value of angle C in the triangle using trigonometry, we can use the Law of Cosines... C = 29.1 degrees.\\' not only continues to offer intricate explanations but also contains a calculation error. This deviation results in the bot being perceived as unhelpful and inaccurate, contrasting the expected behavior of a helpful role. These two instances severely affected the role adherence, resulting in a low score of 0.3333333333333333.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Knowledge retention"
      ],
      "metadata": {
        "id": "SwdXrtv8G63O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_case = ConversationalTestCase(turns = dlist )\n",
        "metric = KnowledgeRetentionMetric(threshold = 0.5)\n",
        "\n",
        "metric.measure(test_case)\n",
        "print(metric.score)\n",
        "metric.reason"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70,
          "referenced_widgets": [
            "4f53260ea252416d949501fedb872c40",
            "7c4db1ab27614243bac43f27b085cf8c"
          ]
        },
        "id": "TXVyrNIVHCJm",
        "outputId": "b30c8794-825c-4784-9723-34fcce1ed7c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4f53260ea252416d949501fedb872c40"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The score is 1.00 because there are no attritions, indicating perfect retention of knowledge throughout the conversation.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conversation completeness"
      ],
      "metadata": {
        "id": "GCmrXjN3RTc6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_case = ConversationalTestCase(turns = dlist )\n",
        "metric = ConversationCompletenessMetric(threshold=0.5)\n",
        "\n",
        "metric.measure(convo_test_case)\n",
        "print(metric.score)\n",
        "metric.reason"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105,
          "referenced_widgets": [
            "fe414bdb4c7b48ab967630e7ae4dc2bc",
            "820b1f8bd41f4525abb1e4375e7ba4a0"
          ]
        },
        "id": "DwL5IRQGRXkH",
        "outputId": "7d2ae135-990c-446a-8daf-952e28996f42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fe414bdb4c7b48ab967630e7ae4dc2bc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The score is 0.5 because the LLM response partially meets the user's intention by calculating angles A and C using trigonometry. However, it falls short of the user's request for a detailed and accurate step-by-step approach, specifically for angle B. The response included inconsistencies in calculations for angle B, such as 'mixing up known lengths,' which undermines the reliability of solving all angles as the user desired.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conversation relevancy"
      ],
      "metadata": {
        "id": "ItRVEuIpRkRC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_case = ConversationalTestCase(turns = dlist )\n",
        "metric = ConversationRelevancyMetric(threshold=0.5)\n",
        "\n",
        "metric.measure(convo_test_case)\n",
        "print(metric.score)\n",
        "metric.reason"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88,
          "referenced_widgets": [
            "0f3802c304de4844b4db3e672b7ca47b",
            "ae49467c01a347d4b46660628eda6cc2"
          ]
        },
        "id": "mBHlS0uERuYZ",
        "outputId": "75d3fae3-7200-48cd-ae20-2a65c495bc4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0f3802c304de4844b4db3e672b7ca47b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6666666666666666\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The score is 0.67 because message number 3 contains an incorrect approach to calculating angle C in a triangle, using inconsistent values for sides 'a' and 'b'. This irrelevance stems from using the Pythagorean theorem incorrectly, leading to an erroneous solution for angle C, impacting the overall relevance of the actual outputs.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    }
  ]
}