{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "mB-tPK6XeC1r"
      },
      "id": "mB-tPK6XeC1r"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "628ee9b2",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2024-11-03T22:53:10.828832Z",
          "iopub.status.busy": "2024-11-03T22:53:10.828372Z",
          "iopub.status.idle": "2024-11-03T22:53:26.346236Z",
          "shell.execute_reply": "2024-11-03T22:53:26.344172Z"
        },
        "papermill": {
          "duration": 15.527324,
          "end_time": "2024-11-03T22:53:26.349386",
          "exception": false,
          "start_time": "2024-11-03T22:53:10.822062",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "628ee9b2",
        "outputId": "33789a5f-011a-4137-8d33-767e908e3ee9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/460.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m450.6/460.6 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m460.6/460.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qU openai pydantic"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This line of code installs two Python packages: `openai` and `pydantic`.\n",
        "\n",
        "- The `!` symbol at the start indicates that this command is being run in a Jupyter notebook or another environment where shell commands can be executed directly.\n",
        "- `pip install` is the command used to download and install packages from the Python Package Index (PyPI).\n",
        "- `-q` flag stands for quiet mode, which suppresses the output of the installation process, making it less verbose.\n",
        "- `-U` flag stands for upgrade, which ensures that the latest version of the package is installed, even if an older version already exists.\n",
        "- `openai` is a Python library developed by OpenAI that allows interaction with their AI models and services.\n",
        "- `pydantic` is a library used for building robust, scalable, and maintainable data validation and parsing. It provides runtime type checking and validation for Python data structures, making it useful in applications where data integrity is critical."
      ],
      "metadata": {
        "id": "FsGtbBBBeFsc"
      },
      "id": "FsGtbBBBeFsc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "437afef3",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-03T22:53:26.360363Z",
          "iopub.status.busy": "2024-11-03T22:53:26.359880Z",
          "iopub.status.idle": "2024-11-03T22:53:27.529094Z",
          "shell.execute_reply": "2024-11-03T22:53:27.527934Z"
        },
        "papermill": {
          "duration": 1.177565,
          "end_time": "2024-11-03T22:53:27.531760",
          "exception": false,
          "start_time": "2024-11-03T22:53:26.354195",
          "status": "completed"
        },
        "tags": [],
        "id": "437afef3"
      },
      "outputs": [],
      "source": [
        "# Standard library imports\n",
        "import os\n",
        "import time\n",
        "from typing import Literal\n",
        "\n",
        "# Third-party imports\n",
        "from openai import OpenAI\n",
        "from pydantic import BaseModel\n",
        "from google.colab import userdata\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code segment imports necessary modules and classes from both the Python standard library and third-party libraries.\n",
        "\n",
        "- **Standard library imports**:\n",
        "  - `os`: This module provides a way to use operating system dependent functionality. It allows functions such as working with the file system, processes, and environment variables.\n",
        "  - `time`: This module provides various time-related functions. It can be used for tasks like measuring the execution time of code segments, delaying execution, or handling dates and times.\n",
        "  - `Literal` from `typing`: This is a type hint that indicates a variable can only take on specific literal values. It's often used with enums or when a variable should only have one of a few possible string or integer values.\n",
        "\n",
        "- **Third-party imports**:\n",
        "  - `OpenAI` from `openai`: This class is likely the main interface to OpenAI's services, allowing for interaction with their AI models and APIs.\n",
        "  - `BaseModel` from `pydantic`: This is a base class provided by Pydantic for creating data models. It automatically generates validation logic based on type hints, making it easier to ensure data consistency and correctness.\n",
        "  - `userdata` from `google.colab`: The import statement here seems incorrect or incomplete because `google.colab` does not typically have a module named `userdata`. Google Colab is an environment for running Jupyter notebooks in the cloud, and its API might be used differently. Typically, you would see imports like `from google.colab import drive` to mount Google Drive, or other modules for specific functionalities within Colab. The correct usage depends on what functionality is needed from Google Colab.\n",
        "\n"
      ],
      "metadata": {
        "id": "RUJVkK1afRXt"
      },
      "id": "RUJVkK1afRXt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c214e0ac",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-03T22:53:27.541958Z",
          "iopub.status.busy": "2024-11-03T22:53:27.541355Z",
          "iopub.status.idle": "2024-11-03T22:53:27.546956Z",
          "shell.execute_reply": "2024-11-03T22:53:27.545720Z"
        },
        "papermill": {
          "duration": 0.01385,
          "end_time": "2024-11-03T22:53:27.549864",
          "exception": false,
          "start_time": "2024-11-03T22:53:27.536014",
          "status": "completed"
        },
        "tags": [],
        "id": "c214e0ac"
      },
      "outputs": [],
      "source": [
        "class CFG:\n",
        "    max_new_tokens = 100\n",
        "    model= 'gpt-4o-mini'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This defines a class named `CFG`.\n",
        "\n",
        "- `max_new_tokens = 100`: This is a class attribute that specifies the maximum number of new tokens to generate in a response. In the context of language models like those provided by OpenAI, a \"token\" can be a word, part of a word, or even a character, depending on how the model is configured. This setting controls how much text the model will produce when given a prompt.\n",
        "\n",
        "- `model = 'gpt-4o-mini'`: This specifies the AI model to use for generating text. The name indicates it's a variant of the GPT-4 model, specifically a \"mini\" version, which implies it's a smaller or more efficient version of the full GPT-4 model.  \n",
        "\n",
        "The `CFG` class seems to be used as a configuration or settings holder for an application that interacts with OpenAI's language generation capabilities. The attributes defined here can be accessed as class variables (e.g., `CFG.max_new_tokens`) and are used to configure how text is generated when interacting with the OpenAI model specified by the `model` attribute."
      ],
      "metadata": {
        "id": "dqHGJXO0fR1R"
      },
      "id": "dqHGJXO0fR1R"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d75c428a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-03T22:53:27.560354Z",
          "iopub.status.busy": "2024-11-03T22:53:27.559902Z",
          "iopub.status.idle": "2024-11-03T22:53:27.965223Z",
          "shell.execute_reply": "2024-11-03T22:53:27.964018Z"
        },
        "papermill": {
          "duration": 0.414025,
          "end_time": "2024-11-03T22:53:27.968198",
          "exception": false,
          "start_time": "2024-11-03T22:53:27.554173",
          "status": "completed"
        },
        "tags": [],
        "id": "d75c428a"
      },
      "outputs": [],
      "source": [
        "client = OpenAI(api_key = userdata.get('openaivision'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This line of code initializes an instance of the `OpenAI` class, which is used to interact with the OpenAI API. The `api_key` parameter is set to the value retrieved from the `userdata` dictionary using the key `'openaivision'`. This suggests that the API key for accessing OpenAI's services, specifically the vision model, is stored in the `userdata` dictionary under this key.\n",
        "\n",
        "The `OpenAI` class is not a built-in Python class, so it must be imported from a library that provides an interface to the OpenAI API. The `api_key` parameter is required to authenticate requests made to the OpenAI API.\n",
        "\n",
        "By setting up the client in this way, the code can use the instance to make calls to the OpenAI API, passing in the stored API key for authentication. This allows the code to access various OpenAI models and services, such as text or image generation, without having to manually handle API key management."
      ],
      "metadata": {
        "id": "62LLFPbBfSTG"
      },
      "id": "62LLFPbBfSTG"
    },
    {
      "cell_type": "markdown",
      "id": "2cebda5e",
      "metadata": {
        "papermill": {
          "duration": 0.003758,
          "end_time": "2024-11-03T22:53:27.976157",
          "exception": false,
          "start_time": "2024-11-03T22:53:27.972399",
          "status": "completed"
        },
        "tags": [],
        "id": "2cebda5e"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0193d5bd",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-03T22:53:27.985910Z",
          "iopub.status.busy": "2024-11-03T22:53:27.985476Z",
          "iopub.status.idle": "2024-11-03T22:53:27.990759Z",
          "shell.execute_reply": "2024-11-03T22:53:27.989513Z"
        },
        "papermill": {
          "duration": 0.013273,
          "end_time": "2024-11-03T22:53:27.993375",
          "exception": false,
          "start_time": "2024-11-03T22:53:27.980102",
          "status": "completed"
        },
        "tags": [],
        "id": "0193d5bd"
      },
      "outputs": [],
      "source": [
        "reviews = [\n",
        "   \"The room was clean and the staff was friendly.\",\n",
        "   \"The location was terrible and the service was slow.\",\n",
        "   \"The food was amazing but the room was too small.\",\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbaa122b",
      "metadata": {
        "papermill": {
          "duration": 0.003762,
          "end_time": "2024-11-03T22:53:28.001572",
          "exception": false,
          "start_time": "2024-11-03T22:53:27.997810",
          "status": "completed"
        },
        "tags": [],
        "id": "cbaa122b"
      },
      "source": [
        "# Basic eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09f04456",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-03T22:53:28.011558Z",
          "iopub.status.busy": "2024-11-03T22:53:28.011107Z",
          "iopub.status.idle": "2024-11-03T22:53:28.016971Z",
          "shell.execute_reply": "2024-11-03T22:53:28.015822Z"
        },
        "papermill": {
          "duration": 0.013808,
          "end_time": "2024-11-03T22:53:28.019454",
          "exception": false,
          "start_time": "2024-11-03T22:53:28.005646",
          "status": "completed"
        },
        "tags": [],
        "id": "09f04456"
      },
      "outputs": [],
      "source": [
        "SYSTEM_PROMPT = \"You are a sentiment classifier assistant.\"\n",
        "PROMPT_TEMPLATE = \"\"\"\n",
        "   Classify the sentiment of the following hotel review as positive, negative, or neutral:\\n\\n{review}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "These two lines define constants that will be used in a sentiment classification task.\n",
        "\n",
        "The `SYSTEM_PROMPT` constant is a string that defines the role of the assistant. In this case, it specifies that the assistant is a \"sentiment classifier assistant\", indicating its purpose is to classify text based on sentiment.\n",
        "\n",
        "The `PROMPT_TEMPLATE` constant is a multiline string that serves as a template for creating prompts to be used in sentiment classification tasks. The template includes a fixed part that provides context and instructions for the task, and a placeholder `{review}` where the actual hotel review to be classified will be inserted.\n",
        "\n",
        "When a hotel review is provided, it can be formatted into this template by replacing `{review}` with the review text, resulting in a complete prompt that can be used as input to a sentiment classification model. For example:\n"
      ],
      "metadata": {
        "id": "A6FH9gTuhAtb"
      },
      "id": "A6FH9gTuhAtb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f96c636",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-03T22:53:28.029517Z",
          "iopub.status.busy": "2024-11-03T22:53:28.029075Z",
          "iopub.status.idle": "2024-11-03T22:53:28.035723Z",
          "shell.execute_reply": "2024-11-03T22:53:28.034473Z"
        },
        "papermill": {
          "duration": 0.015168,
          "end_time": "2024-11-03T22:53:28.038747",
          "exception": false,
          "start_time": "2024-11-03T22:53:28.023579",
          "status": "completed"
        },
        "tags": [],
        "id": "0f96c636"
      },
      "outputs": [],
      "source": [
        "# normal eval\n",
        "def classify_sentiment(review):\n",
        "   response = client.beta.chat.completions.parse(\n",
        "       model = CFG.model,\n",
        "       messages=[\n",
        "           {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "           {\"role\": \"user\", \"content\": PROMPT_TEMPLATE.format(review=review)},\n",
        "       ],\n",
        "   )\n",
        "   return response.choices[0].message"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function, `classify_sentiment`, takes a hotel review as input and returns the sentiment classification result. Here's how it works:\n",
        "\n",
        "1. It sends a request to the OpenAI API using the `client.beta.chat.completions.parse` method.\n",
        "2. The request includes two messages:\n",
        "   - The first message has a \"system\" role and contains the content defined by the `SYSTEM_PROMPT` constant, which specifies that the assistant is a sentiment classifier.\n",
        "   - The second message has a \"user\" role and contains the content created by formatting the `PROMPT_TEMPLATE` with the provided hotel review. This template includes instructions to classify the sentiment of the review as positive, negative, or neutral.\n",
        "3. The request also specifies the model to use for parsing the messages, which is defined by the `CFG.model` variable.\n",
        "4. The response from the OpenAI API contains a list of choices, where each choice represents a possible completion of the conversation.\n",
        "5. The function returns the first message in the list of choices (`response.choices[0].message`), which should contain the sentiment classification result for the provided hotel review.\n",
        "\n",
        "This approach effectively uses the OpenAI model to classify the sentiment of a given hotel review based on its content, with the `SYSTEM_PROMPT` and `PROMPT_TEMPLATE` providing context and guidance for the classification task."
      ],
      "metadata": {
        "id": "f1ZciuHWhCTe"
      },
      "id": "f1ZciuHWhCTe"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af7e6105",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-03T22:53:28.050153Z",
          "iopub.status.busy": "2024-11-03T22:53:28.048647Z",
          "iopub.status.idle": "2024-11-03T22:53:31.015681Z",
          "shell.execute_reply": "2024-11-03T22:53:31.014389Z"
        },
        "papermill": {
          "duration": 2.97589,
          "end_time": "2024-11-03T22:53:31.018774",
          "exception": false,
          "start_time": "2024-11-03T22:53:28.042884",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af7e6105",
        "outputId": "96fb98f2-b9c0-4f08-ff8b-70140e9704b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review: The room was clean and the staff was friendly.\n",
            "Sentiment: The sentiment of the review is positive.\n",
            "\n",
            "Review: The location was terrible and the service was slow.\n",
            "Sentiment: The sentiment of the review is negative.\n",
            "\n",
            "Review: The food was amazing but the room was too small.\n",
            "Sentiment: The sentiment of the hotel review is mixed; however, if I have to classify it into one of the three categories, I would classify it as **neutral**. The reviewer expresses a positive sentiment about the food and a negative sentiment about the room size, balancing each other out.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for review in reviews:\n",
        "   sentiment = classify_sentiment(review)\n",
        "   print(f\"Review: {review}\\nSentiment: {sentiment.content}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code iterates over a collection of hotel reviews (`reviews`) and classifies the sentiment of each one using the `classify_sentiment` function. For each review, it then prints out the original review text and its corresponding sentiment classification.\n",
        "\n",
        "Here's a step-by-step breakdown:\n",
        "\n",
        "1. The loop `for review in reviews:` iterates over each review in the `reviews` collection.\n",
        "2. Within the loop, `sentiment = classify_sentiment(review)` calls the `classify_sentiment` function to classify the sentiment of the current review. The result is stored in the `sentiment` variable.\n",
        "3. `print(f\"Review: {review}\\nSentiment: {sentiment.content}\\n\")` prints out two lines:\n",
        "   - The first line displays the original review text, prefixed with \"Review: \".\n",
        "   - The second line displays the classified sentiment, prefixed with \"Sentiment: \". The `.content` attribute is used to access the content of the `sentiment` message.\n",
        "4. A newline character (`\\n`) is added at the end of the print statement to separate each review's output.\n",
        "\n",
        "This code effectively classifies and prints the sentiments of all reviews in the `reviews` collection, providing a clear and organized output that shows both the original review text and its corresponding sentiment classification."
      ],
      "metadata": {
        "id": "XfAo-0SdiT4J"
      },
      "id": "XfAo-0SdiT4J"
    },
    {
      "cell_type": "markdown",
      "id": "39ecf1bb",
      "metadata": {
        "papermill": {
          "duration": 0.005049,
          "end_time": "2024-11-03T22:53:31.028374",
          "exception": false,
          "start_time": "2024-11-03T22:53:31.023325",
          "status": "completed"
        },
        "tags": [],
        "id": "39ecf1bb"
      },
      "source": [
        "# SO eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8da23760",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-03T22:53:31.039059Z",
          "iopub.status.busy": "2024-11-03T22:53:31.038495Z",
          "iopub.status.idle": "2024-11-03T22:53:31.047277Z",
          "shell.execute_reply": "2024-11-03T22:53:31.045333Z"
        },
        "papermill": {
          "duration": 0.017363,
          "end_time": "2024-11-03T22:53:31.050009",
          "exception": false,
          "start_time": "2024-11-03T22:53:31.032646",
          "status": "completed"
        },
        "tags": [],
        "id": "8da23760"
      },
      "outputs": [],
      "source": [
        "class SentimentResponse(BaseModel):\n",
        "   sentiment: Literal[\"positive\", \"negative\", \"neutral\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code defines a class `SentimentResponse` using the `BaseModel` from a library such as Pydantic.\n",
        "\n",
        "The `SentimentResponse` class has a single attribute `sentiment`, which is typed as a `Literal`. The `Literal` type means that the `sentiment` attribute can only take on one of the explicitly specified values, which in this case are:\n",
        "\n",
        "- \"positive\"\n",
        "- \"negative\"\n",
        "- \"neutral\"\n",
        "\n",
        "This implies that any instance of the `SentimentResponse` class will have a `sentiment` attribute with one of these three string values. The use of `Literal` provides strong typing and helps catch errors at runtime or during static type checking if an invalid value is assigned to the `sentiment` attribute.\n",
        "\n",
        "For example, attempting to create an instance of `SentimentResponse` with an invalid sentiment value would result in an error:\n",
        "```python\n",
        "response = SentimentResponse(sentiment=\"unknown\")  # This would raise a validation error\n",
        "```\n",
        "However, creating an instance with one of the allowed values would be valid:\n",
        "```python\n",
        "response = SentimentResponse(sentiment=\"positive\")  # This is a valid sentiment value\n",
        "```"
      ],
      "metadata": {
        "id": "jLiR1Ikwib6r"
      },
      "id": "jLiR1Ikwib6r"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e300c120",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-03T22:53:31.060216Z",
          "iopub.status.busy": "2024-11-03T22:53:31.059771Z",
          "iopub.status.idle": "2024-11-03T22:53:31.066418Z",
          "shell.execute_reply": "2024-11-03T22:53:31.065116Z"
        },
        "papermill": {
          "duration": 0.014787,
          "end_time": "2024-11-03T22:53:31.069067",
          "exception": false,
          "start_time": "2024-11-03T22:53:31.054280",
          "status": "completed"
        },
        "tags": [],
        "id": "e300c120"
      },
      "outputs": [],
      "source": [
        "def classify_sentiment_with_structured_outputs(review):\n",
        "   response = client.beta.chat.completions.parse(\n",
        "       model= CFG.model,\n",
        "       messages=[\n",
        "           {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "           {\"role\": \"user\", \"content\": PROMPT_TEMPLATE.format(review=review)},\n",
        "       ],\n",
        "       response_format=SentimentResponse\n",
        "   )\n",
        "   return response.choices[0].message\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function, `classify_sentiment_with_structured_outputs`, is similar to the previous `classify_sentiment` function. However, it includes an additional parameter `response_format` in the `client.beta.chat.completions.parse` method call.\n",
        "\n",
        "The `response_format` parameter specifies that the response from the API should be parsed into an instance of the `SentimentResponse` class. This means that the API's response will be expected to conform to the structure defined by the `SentimentResponse` model, which includes a single attribute `sentiment` with one of the allowed values (\"positive\", \"negative\", or \"neutral\").\n",
        "\n",
        "By specifying the `response_format`, this function provides stronger typing and validation for the response data. If the API's response does not match the expected structure (i.e., it does not contain a valid sentiment value), a validation error will be raised.\n",
        "\n",
        "The rest of the function remains the same: it sends a request to the OpenAI API with the provided review, and returns the first message in the list of choices from the response. However, because of the `response_format` parameter, the returned message is expected to contain a structured sentiment classification result that conforms to the `SentimentResponse` model.\n",
        "\n",
        "For example, the returned message might be an instance of `SentimentResponse` with a `sentiment` attribute set to one of the allowed values:\n",
        "```python\n",
        "response = SentimentResponse(sentiment=\"positive\")\n",
        "```\n",
        "This allows for more robust and type-safe handling of the sentiment classification results."
      ],
      "metadata": {
        "id": "440Jf1N6imyI"
      },
      "id": "440Jf1N6imyI"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05335c20",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-03T22:53:31.080619Z",
          "iopub.status.busy": "2024-11-03T22:53:31.080097Z",
          "iopub.status.idle": "2024-11-03T22:53:33.573139Z",
          "shell.execute_reply": "2024-11-03T22:53:33.571806Z"
        },
        "papermill": {
          "duration": 2.502195,
          "end_time": "2024-11-03T22:53:33.576088",
          "exception": false,
          "start_time": "2024-11-03T22:53:31.073893",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05335c20",
        "outputId": "151ace5c-a5ea-4a46-e6ee-09765bee6f6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review: The room was clean and the staff was friendly.\n",
            "Sentiment: {\"sentiment\":\"positive\"}\n",
            "----------\n",
            "Review: The location was terrible and the service was slow.\n",
            "Sentiment: {\"sentiment\":\"negative\"}\n",
            "----------\n",
            "Review: The food was amazing but the room was too small.\n",
            "Sentiment: {\"sentiment\":\"neutral\"}\n",
            "----------\n"
          ]
        }
      ],
      "source": [
        "for review in reviews:\n",
        "    sentiment = classify_sentiment_with_structured_outputs(review)\n",
        "    print(f\"Review: {review}\\nSentiment: {sentiment.content}\")\n",
        "    print('-' * 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code iterates over a collection of hotel reviews (`reviews`) and classifies the sentiment of each one using the `classify_sentiment_with_structured_outputs` function. For each review, it then prints out the original review text and its corresponding sentiment classification.\n",
        "\n",
        "Here's a step-by-step breakdown:\n",
        "\n",
        "1. The loop `for review in reviews:` iterates over each review in the `reviews` collection.\n",
        "2. Within the loop, `sentiment = classify_sentiment_with_structured_outputs(review)` calls the function to classify the sentiment of the current review and stores the result in the `sentiment` variable.\n",
        "3. `print(f\"Review: {review}\\nSentiment: {sentiment.content}\")` prints out two lines:\n",
        "   - The first line displays the original review text, prefixed with \"Review: \".\n",
        "   - The second line displays the classified sentiment, prefixed with \"Sentiment: \". The `.content` attribute is used to access the content of the `sentiment` message.\n",
        "4. `print('-' * 10)` prints a horizontal line of 10 dashes, which serves as a separator between each review's output.\n",
        "This approach takes advantage of the structured output provided by the `classify_sentiment_with_structured_outputs` function."
      ],
      "metadata": {
        "id": "HiPxyiOvi1Id"
      },
      "id": "HiPxyiOvi1Id"
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 30786,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 26.788977,
      "end_time": "2024-11-03T22:53:34.202551",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2024-11-03T22:53:07.413574",
      "version": "2.6.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}