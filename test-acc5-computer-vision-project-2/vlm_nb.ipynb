{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/acc_vis/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'LlavaMiniLlamaForCausalLM' from 'transformers' (/opt/miniconda3/envs/acc_vis/lib/python3.11/site-packages/transformers/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mvlm_answers_gen\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mvlm\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-IKEA/Documents/test-acc5-computer-vision-project-2/vlm_answers_gen.py:9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BlipProcessor, BlipForConditionalGeneration\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LlavaProcessor, AutoTokenizer\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LlavaMiniLlamaForCausalLM\n\u001b[1;32m     11\u001b[0m CACHE_DIR \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcache\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_model\u001b[39m(model_name, processor_type, model_type, attn_implementation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'LlavaMiniLlamaForCausalLM' from 'transformers' (/opt/miniconda3/envs/acc_vis/lib/python3.11/site-packages/transformers/__init__.py)"
     ]
    }
   ],
   "source": [
    "import vlm_answers_gen as vlm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/deepseek-ai/Janus\n",
      "  Cloning https://github.com/deepseek-ai/Janus to /private/var/folders/nw/ssdc3p8s1pqbp4lsgsj33ys00000gp/T/pip-req-build-3otb0xgx\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/deepseek-ai/Janus /private/var/folders/nw/ssdc3p8s1pqbp4lsgsj33ys00000gp/T/pip-req-build-3otb0xgx\n",
      "  Resolved https://github.com/deepseek-ai/Janus to commit 1daa72fa409002d40931bd7b36a9280362469ead\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch>=2.0.1 in /opt/miniconda3/envs/acc_vis/lib/python3.11/site-packages (from janus==1.0.0) (2.6.0)\n",
      "Requirement already satisfied: transformers>=4.38.2 in /opt/miniconda3/envs/acc_vis/lib/python3.11/site-packages (from janus==1.0.0) (4.45.2)\n",
      "Collecting timm>=0.9.16 (from janus==1.0.0)\n",
      "  Downloading timm-1.0.14-py3-none-any.whl.metadata (50 kB)\n",
      "Collecting accelerate (from janus==1.0.0)\n",
      "  Downloading accelerate-1.3.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: sentencepiece in /opt/miniconda3/envs/acc_vis/lib/python3.11/site-packages (from janus==1.0.0) (0.2.0)\n",
      "Collecting attrdict (from janus==1.0.0)\n",
      "  Downloading attrdict-2.0.1-py2.py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting einops (from janus==1.0.0)\n",
      "  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting torchvision (from timm>=0.9.16->janus==1.0.0)\n",
      "  Downloading torchvision-0.21.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: pyyaml in /opt/miniconda3/envs/acc_vis/lib/python3.11/site-packages (from timm>=0.9.16->janus==1.0.0) (6.0.2)\n",
      "Requirement already satisfied: huggingface_hub in /opt/miniconda3/envs/acc_vis/lib/python3.11/site-packages (from timm>=0.9.16->janus==1.0.0) (0.28.1)\n",
      "Requirement already satisfied: safetensors in /opt/miniconda3/envs/acc_vis/lib/python3.11/site-packages (from timm>=0.9.16->janus==1.0.0) (0.5.2)\n",
      "Requirement already satisfied: filelock in /opt/miniconda3/envs/acc_vis/lib/python3.11/site-packages (from torch>=2.0.1->janus==1.0.0) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/miniconda3/envs/acc_vis/lib/python3.11/site-packages (from torch>=2.0.1->janus==1.0.0) (4.12.2)\n",
      "Requirement already satisfied: networkx in /opt/miniconda3/envs/acc_vis/lib/python3.11/site-packages (from torch>=2.0.1->janus==1.0.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/miniconda3/envs/acc_vis/lib/python3.11/site-packages (from torch>=2.0.1->janus==1.0.0) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /opt/miniconda3/envs/acc_vis/lib/python3.11/site-packages (from torch>=2.0.1->janus==1.0.0) (2025.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/miniconda3/envs/acc_vis/lib/python3.11/site-packages (from torch>=2.0.1->janus==1.0.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/miniconda3/envs/acc_vis/lib/python3.11/site-packages (from sympy==1.13.1->torch>=2.0.1->janus==1.0.0) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/miniconda3/envs/acc_vis/lib/python3.11/site-packages (from transformers>=4.38.2->janus==1.0.0) (2.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/miniconda3/envs/acc_vis/lib/python3.11/site-packages (from transformers>=4.38.2->janus==1.0.0) (24.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/miniconda3/envs/acc_vis/lib/python3.11/site-packages (from transformers>=4.38.2->janus==1.0.0) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/miniconda3/envs/acc_vis/lib/python3.11/site-packages (from transformers>=4.38.2->janus==1.0.0) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/miniconda3/envs/acc_vis/lib/python3.11/site-packages (from transformers>=4.38.2->janus==1.0.0) (0.20.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/miniconda3/envs/acc_vis/lib/python3.11/site-packages (from transformers>=4.38.2->janus==1.0.0) (4.67.1)\n",
      "Requirement already satisfied: psutil in /opt/miniconda3/envs/acc_vis/lib/python3.11/site-packages (from accelerate->janus==1.0.0) (6.1.1)\n",
      "Requirement already satisfied: six in /opt/miniconda3/envs/acc_vis/lib/python3.11/site-packages (from attrdict->janus==1.0.0) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/miniconda3/envs/acc_vis/lib/python3.11/site-packages (from jinja2->torch>=2.0.1->janus==1.0.0) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/envs/acc_vis/lib/python3.11/site-packages (from requests->transformers>=4.38.2->janus==1.0.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/envs/acc_vis/lib/python3.11/site-packages (from requests->transformers>=4.38.2->janus==1.0.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/envs/acc_vis/lib/python3.11/site-packages (from requests->transformers>=4.38.2->janus==1.0.0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/envs/acc_vis/lib/python3.11/site-packages (from requests->transformers>=4.38.2->janus==1.0.0) (2025.1.31)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/miniconda3/envs/acc_vis/lib/python3.11/site-packages (from torchvision->timm>=0.9.16->janus==1.0.0) (11.1.0)\n",
      "Downloading timm-1.0.14-py3-none-any.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-1.3.0-py3-none-any.whl (336 kB)\n",
      "Downloading attrdict-2.0.1-py2.py3-none-any.whl (9.9 kB)\n",
      "Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
      "Downloading torchvision-0.21.0-cp311-cp311-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: janus\n",
      "  Building wheel for janus (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for janus: filename=janus-1.0.0-py3-none-any.whl size=85499 sha256=85dc39fa9b1d9b871f7edb8c54e4428b9ee5f8453ff1da4f74ae963458b0d41c\n",
      "  Stored in directory: /private/var/folders/nw/ssdc3p8s1pqbp4lsgsj33ys00000gp/T/pip-ephem-wheel-cache-2kqraupt/wheels/d4/4f/75/619703dcd03931e7d8276b4afa17b3d9ba83c490ab3b7c1a16\n",
      "Successfully built janus\n",
      "Installing collected packages: einops, attrdict, torchvision, accelerate, timm, janus\n",
      "Successfully installed accelerate-1.3.0 attrdict-2.0.1 einops-0.8.0 janus-1.0.0 timm-1.0.14 torchvision-0.21.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install git+https://github.com/deepseek-ai/Janus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = 'partition_6_9.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'vlm_answers_gen' has no attribute 'LlavaMiniLlamaForCausalLM'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# model_name = \"deepseek-ai/Janus-Pro-7B\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mICTNLP/llava-mini-llama-3.1-8b\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m processor, model \u001b[38;5;241m=\u001b[39m vlm\u001b[38;5;241m.\u001b[39mload_model(model_name, vlm\u001b[38;5;241m.\u001b[39mLlavaProcessor, \u001b[43mvlm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLlavaMiniLlamaForCausalLM\u001b[49m)\n\u001b[1;32m      5\u001b[0m generation_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_new_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1024\u001b[39m,\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_beams\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_sample\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m      9\u001b[0m }\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'vlm_answers_gen' has no attribute 'LlavaMiniLlamaForCausalLM'"
     ]
    }
   ],
   "source": [
    "# model_name = \"deepseek-ai/Janus-Pro-7B\"\n",
    "model_name = \"ICTNLP/llava-mini-llama-3.1-8b\"\n",
    "processor, model = vlm.load_model(model_name, vlm.LlavaProcessor, vlm.LlavaMiniLlamaForCausalLM)\n",
    "\n",
    "generation_kwargs = {\n",
    "    \"max_new_tokens\": 1024,\n",
    "    \"num_beams\": 1,\n",
    "    \"do_sample\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = vlm.process_questions(csv_file, model, processor, generation_kwargs, \"test_vlm_output.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Questions: 22question [00:00, 689.00question/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to test_vlm_output.csv\n",
      "Checkpoint saved to test_vlm_output.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'path': 'img/test/008.jpg',\n",
       "  'question': 'Where is the toilet positioned with respect to the room?',\n",
       "  'true_answer': 'On the left side of the room',\n",
       "  'type_question': 'qualitative',\n",
       "  'answer': '\\n    You will be provided an image and a question about the image.\\n    You will also be told if the answer expected is a qualitative or quantitative answer.\\n    Please provide an answer to the question. \\n\\n    Example 1:\\n    Question: \"How far is the yellow finger from the silver can?\"\\n    Expected Answer Type: Quantitative\\n    Output: \"The yellow finger is one and a half meters away from the silver can\"\\n\\n    Example 2:\\n    Question: \"What is next to the blue sofa?\"\\n    Expected Answer Type: Qualitative\\n    Output: \"The yellow chair is next to the blue sofa\"\\n\\n    Your task: Provide an answer to the question. No greetings or comments. Just provide the answer.\\n    Question: Where is the toilet positioned with respect to the room?\\n    Question Type: qualitative\\n    '},\n",
       " {'path': 'img/test/008.jpg',\n",
       "  'question': 'Where is the shower curtain positioned with respect to the toilet?',\n",
       "  'true_answer': 'Next to the toilet',\n",
       "  'type_question': 'qualitative',\n",
       "  'answer': '\\n    You will be provided an image and a question about the image.\\n    You will also be told if the answer expected is a qualitative or quantitative answer.\\n    Please provide an answer to the question. \\n\\n    Example 1:\\n    Question: \"How far is the yellow finger from the silver can?\"\\n    Expected Answer Type: Quantitative\\n    Output: \"The yellow finger is one and a half meters away from the silver can\"\\n\\n    Example 2:\\n    Question: \"What is next to the blue sofa?\"\\n    Expected Answer Type: Qualitative\\n    Output: \"The yellow chair is next to the blue sofa\"\\n\\n    Your task: Provide an answer to the question. No greetings or comments. Just provide the answer.\\n    Question: Where is the shower curtain positioned with respect to the toilet?\\n    Question Type: qualitative\\n    '},\n",
       " {'path': 'img/test/008.jpg',\n",
       "  'question': 'Where is the sink positioned with respect to the room?',\n",
       "  'true_answer': 'On the right side of the room',\n",
       "  'type_question': 'qualitative',\n",
       "  'answer': '\\n    You will be provided an image and a question about the image.\\n    You will also be told if the answer expected is a qualitative or quantitative answer.\\n    Please provide an answer to the question. \\n\\n    Example 1:\\n    Question: \"How far is the yellow finger from the silver can?\"\\n    Expected Answer Type: Quantitative\\n    Output: \"The yellow finger is one and a half meters away from the silver can\"\\n\\n    Example 2:\\n    Question: \"What is next to the blue sofa?\"\\n    Expected Answer Type: Qualitative\\n    Output: \"The yellow chair is next to the blue sofa\"\\n\\n    Your task: Provide an answer to the question. No greetings or comments. Just provide the answer.\\n    Question: Where is the sink positioned with respect to the room?\\n    Question Type: qualitative\\n    '},\n",
       " {'path': 'img/test/008.jpg',\n",
       "  'question': 'Where is the bathtub positioned with respect to the sink?',\n",
       "  'true_answer': 'Next to the sink',\n",
       "  'type_question': 'qualitative',\n",
       "  'answer': '\\n    You will be provided an image and a question about the image.\\n    You will also be told if the answer expected is a qualitative or quantitative answer.\\n    Please provide an answer to the question. \\n\\n    Example 1:\\n    Question: \"How far is the yellow finger from the silver can?\"\\n    Expected Answer Type: Quantitative\\n    Output: \"The yellow finger is one and a half meters away from the silver can\"\\n\\n    Example 2:\\n    Question: \"What is next to the blue sofa?\"\\n    Expected Answer Type: Qualitative\\n    Output: \"The yellow chair is next to the blue sofa\"\\n\\n    Your task: Provide an answer to the question. No greetings or comments. Just provide the answer.\\n    Question: Where is the bathtub positioned with respect to the sink?\\n    Question Type: qualitative\\n    '},\n",
       " {'path': 'img/test/008.jpg',\n",
       "  'question': 'Where is the handbag positioned with respect to the bathtub?',\n",
       "  'true_answer': 'Near the bathtub',\n",
       "  'type_question': 'qualitative',\n",
       "  'answer': '\\n    You will be provided an image and a question about the image.\\n    You will also be told if the answer expected is a qualitative or quantitative answer.\\n    Please provide an answer to the question. \\n\\n    Example 1:\\n    Question: \"How far is the yellow finger from the silver can?\"\\n    Expected Answer Type: Quantitative\\n    Output: \"The yellow finger is one and a half meters away from the silver can\"\\n\\n    Example 2:\\n    Question: \"What is next to the blue sofa?\"\\n    Expected Answer Type: Qualitative\\n    Output: \"The yellow chair is next to the blue sofa\"\\n\\n    Your task: Provide an answer to the question. No greetings or comments. Just provide the answer.\\n    Question: Where is the handbag positioned with respect to the bathtub?\\n    Question Type: qualitative\\n    '},\n",
       " {'path': 'img/test/008.jpg',\n",
       "  'question': 'How far is the toilet from the sink?',\n",
       "  'true_answer': '3 feet',\n",
       "  'type_question': 'quantitative',\n",
       "  'answer': '\\n    You will be provided an image and a question about the image.\\n    You will also be told if the answer expected is a qualitative or quantitative answer.\\n    Please provide an answer to the question. \\n\\n    Example 1:\\n    Question: \"How far is the yellow finger from the silver can?\"\\n    Expected Answer Type: Quantitative\\n    Output: \"The yellow finger is one and a half meters away from the silver can\"\\n\\n    Example 2:\\n    Question: \"What is next to the blue sofa?\"\\n    Expected Answer Type: Qualitative\\n    Output: \"The yellow chair is next to the blue sofa\"\\n\\n    Your task: Provide an answer to the question. No greetings or comments. Just provide the answer.\\n    Question: How far is the toilet from the sink?\\n    Question Type: quantitative\\n    '},\n",
       " {'path': 'img/test/008.jpg',\n",
       "  'question': 'How far is the bathtub from the toilet?',\n",
       "  'true_answer': '2 meters',\n",
       "  'type_question': 'quantitative',\n",
       "  'answer': '\\n    You will be provided an image and a question about the image.\\n    You will also be told if the answer expected is a qualitative or quantitative answer.\\n    Please provide an answer to the question. \\n\\n    Example 1:\\n    Question: \"How far is the yellow finger from the silver can?\"\\n    Expected Answer Type: Quantitative\\n    Output: \"The yellow finger is one and a half meters away from the silver can\"\\n\\n    Example 2:\\n    Question: \"What is next to the blue sofa?\"\\n    Expected Answer Type: Qualitative\\n    Output: \"The yellow chair is next to the blue sofa\"\\n\\n    Your task: Provide an answer to the question. No greetings or comments. Just provide the answer.\\n    Question: How far is the bathtub from the toilet?\\n    Question Type: quantitative\\n    '},\n",
       " {'path': 'img/test/008.jpg',\n",
       "  'question': 'How far is the handbag from the bathtub?',\n",
       "  'true_answer': '1 foot',\n",
       "  'type_question': 'quantitative',\n",
       "  'answer': '\\n    You will be provided an image and a question about the image.\\n    You will also be told if the answer expected is a qualitative or quantitative answer.\\n    Please provide an answer to the question. \\n\\n    Example 1:\\n    Question: \"How far is the yellow finger from the silver can?\"\\n    Expected Answer Type: Quantitative\\n    Output: \"The yellow finger is one and a half meters away from the silver can\"\\n\\n    Example 2:\\n    Question: \"What is next to the blue sofa?\"\\n    Expected Answer Type: Qualitative\\n    Output: \"The yellow chair is next to the blue sofa\"\\n\\n    Your task: Provide an answer to the question. No greetings or comments. Just provide the answer.\\n    Question: How far is the handbag from the bathtub?\\n    Question Type: quantitative\\n    '},\n",
       " {'path': 'img/test/indoor_0258.jpg',\n",
       "  'question': 'Where is the sink positioned with respect to the mirror?',\n",
       "  'true_answer': 'Below the mirror',\n",
       "  'type_question': 'qualitative',\n",
       "  'answer': '\\n    You will be provided an image and a question about the image.\\n    You will also be told if the answer expected is a qualitative or quantitative answer.\\n    Please provide an answer to the question. \\n\\n    Example 1:\\n    Question: \"How far is the yellow finger from the silver can?\"\\n    Expected Answer Type: Quantitative\\n    Output: \"The yellow finger is one and a half meters away from the silver can\"\\n\\n    Example 2:\\n    Question: \"What is next to the blue sofa?\"\\n    Expected Answer Type: Qualitative\\n    Output: \"The yellow chair is next to the blue sofa\"\\n\\n    Your task: Provide an answer to the question. No greetings or comments. Just provide the answer.\\n    Question: Where is the sink positioned with respect to the mirror?\\n    Question Type: qualitative\\n    '},\n",
       " {'path': 'img/test/indoor_0258.jpg',\n",
       "  'question': 'Where is the toilet positioned with respect to the sink?',\n",
       "  'true_answer': 'Next to the sink',\n",
       "  'type_question': 'qualitative',\n",
       "  'answer': '\\n    You will be provided an image and a question about the image.\\n    You will also be told if the answer expected is a qualitative or quantitative answer.\\n    Please provide an answer to the question. \\n\\n    Example 1:\\n    Question: \"How far is the yellow finger from the silver can?\"\\n    Expected Answer Type: Quantitative\\n    Output: \"The yellow finger is one and a half meters away from the silver can\"\\n\\n    Example 2:\\n    Question: \"What is next to the blue sofa?\"\\n    Expected Answer Type: Qualitative\\n    Output: \"The yellow chair is next to the blue sofa\"\\n\\n    Your task: Provide an answer to the question. No greetings or comments. Just provide the answer.\\n    Question: Where is the toilet positioned with respect to the sink?\\n    Question Type: qualitative\\n    '},\n",
       " {'path': 'img/test/indoor_0258.jpg',\n",
       "  'question': 'Where is the shower curtain positioned with respect to the sink?',\n",
       "  'true_answer': 'On the left side of the sink',\n",
       "  'type_question': 'qualitative',\n",
       "  'answer': '\\n    You will be provided an image and a question about the image.\\n    You will also be told if the answer expected is a qualitative or quantitative answer.\\n    Please provide an answer to the question. \\n\\n    Example 1:\\n    Question: \"How far is the yellow finger from the silver can?\"\\n    Expected Answer Type: Quantitative\\n    Output: \"The yellow finger is one and a half meters away from the silver can\"\\n\\n    Example 2:\\n    Question: \"What is next to the blue sofa?\"\\n    Expected Answer Type: Qualitative\\n    Output: \"The yellow chair is next to the blue sofa\"\\n\\n    Your task: Provide an answer to the question. No greetings or comments. Just provide the answer.\\n    Question: Where is the shower curtain positioned with respect to the sink?\\n    Question Type: qualitative\\n    '},\n",
       " {'path': 'img/test/indoor_0258.jpg',\n",
       "  'question': 'How far is the shower curtain from the sink?',\n",
       "  'true_answer': '0.5 meters',\n",
       "  'type_question': 'quantitative',\n",
       "  'answer': '\\n    You will be provided an image and a question about the image.\\n    You will also be told if the answer expected is a qualitative or quantitative answer.\\n    Please provide an answer to the question. \\n\\n    Example 1:\\n    Question: \"How far is the yellow finger from the silver can?\"\\n    Expected Answer Type: Quantitative\\n    Output: \"The yellow finger is one and a half meters away from the silver can\"\\n\\n    Example 2:\\n    Question: \"What is next to the blue sofa?\"\\n    Expected Answer Type: Qualitative\\n    Output: \"The yellow chair is next to the blue sofa\"\\n\\n    Your task: Provide an answer to the question. No greetings or comments. Just provide the answer.\\n    Question: How far is the shower curtain from the sink?\\n    Question Type: quantitative\\n    '},\n",
       " {'path': 'img/test/indoor_0258.jpg',\n",
       "  'question': 'Where is the floor positioned with respect to the toilet?',\n",
       "  'true_answer': 'Beneath the toilet',\n",
       "  'type_question': 'qualitative',\n",
       "  'answer': '\\n    You will be provided an image and a question about the image.\\n    You will also be told if the answer expected is a qualitative or quantitative answer.\\n    Please provide an answer to the question. \\n\\n    Example 1:\\n    Question: \"How far is the yellow finger from the silver can?\"\\n    Expected Answer Type: Quantitative\\n    Output: \"The yellow finger is one and a half meters away from the silver can\"\\n\\n    Example 2:\\n    Question: \"What is next to the blue sofa?\"\\n    Expected Answer Type: Qualitative\\n    Output: \"The yellow chair is next to the blue sofa\"\\n\\n    Your task: Provide an answer to the question. No greetings or comments. Just provide the answer.\\n    Question: Where is the floor positioned with respect to the toilet?\\n    Question Type: qualitative\\n    '},\n",
       " {'path': 'img/test/indoor_0258.jpg',\n",
       "  'question': 'Where is the wall positioned with respect to the toilet?',\n",
       "  'true_answer': 'Around the toilet',\n",
       "  'type_question': 'qualitative',\n",
       "  'answer': '\\n    You will be provided an image and a question about the image.\\n    You will also be told if the answer expected is a qualitative or quantitative answer.\\n    Please provide an answer to the question. \\n\\n    Example 1:\\n    Question: \"How far is the yellow finger from the silver can?\"\\n    Expected Answer Type: Quantitative\\n    Output: \"The yellow finger is one and a half meters away from the silver can\"\\n\\n    Example 2:\\n    Question: \"What is next to the blue sofa?\"\\n    Expected Answer Type: Qualitative\\n    Output: \"The yellow chair is next to the blue sofa\"\\n\\n    Your task: Provide an answer to the question. No greetings or comments. Just provide the answer.\\n    Question: Where is the wall positioned with respect to the toilet?\\n    Question Type: qualitative\\n    '},\n",
       " {'path': 'img/test/aa016553.jpg',\n",
       "  'question': 'Where is the window positioned in the room?',\n",
       "  'true_answer': 'The centerpiece of the room',\n",
       "  'type_question': 'qualitative',\n",
       "  'answer': '\\n    You will be provided an image and a question about the image.\\n    You will also be told if the answer expected is a qualitative or quantitative answer.\\n    Please provide an answer to the question. \\n\\n    Example 1:\\n    Question: \"How far is the yellow finger from the silver can?\"\\n    Expected Answer Type: Quantitative\\n    Output: \"The yellow finger is one and a half meters away from the silver can\"\\n\\n    Example 2:\\n    Question: \"What is next to the blue sofa?\"\\n    Expected Answer Type: Qualitative\\n    Output: \"The yellow chair is next to the blue sofa\"\\n\\n    Your task: Provide an answer to the question. No greetings or comments. Just provide the answer.\\n    Question: Where is the window positioned in the room?\\n    Question Type: qualitative\\n    '},\n",
       " {'path': 'img/test/aa016553.jpg',\n",
       "  'question': 'Where are the chairs positioned with respect to the window?',\n",
       "  'true_answer': 'One near the left and one near the right',\n",
       "  'type_question': 'qualitative',\n",
       "  'answer': '\\n    You will be provided an image and a question about the image.\\n    You will also be told if the answer expected is a qualitative or quantitative answer.\\n    Please provide an answer to the question. \\n\\n    Example 1:\\n    Question: \"How far is the yellow finger from the silver can?\"\\n    Expected Answer Type: Quantitative\\n    Output: \"The yellow finger is one and a half meters away from the silver can\"\\n\\n    Example 2:\\n    Question: \"What is next to the blue sofa?\"\\n    Expected Answer Type: Qualitative\\n    Output: \"The yellow chair is next to the blue sofa\"\\n\\n    Your task: Provide an answer to the question. No greetings or comments. Just provide the answer.\\n    Question: Where are the chairs positioned with respect to the window?\\n    Question Type: qualitative\\n    '},\n",
       " {'path': 'img/test/aa016553.jpg',\n",
       "  'question': 'Where is the coffee table positioned in the room?',\n",
       "  'true_answer': 'In the middle of the room',\n",
       "  'type_question': 'qualitative',\n",
       "  'answer': '\\n    You will be provided an image and a question about the image.\\n    You will also be told if the answer expected is a qualitative or quantitative answer.\\n    Please provide an answer to the question. \\n\\n    Example 1:\\n    Question: \"How far is the yellow finger from the silver can?\"\\n    Expected Answer Type: Quantitative\\n    Output: \"The yellow finger is one and a half meters away from the silver can\"\\n\\n    Example 2:\\n    Question: \"What is next to the blue sofa?\"\\n    Expected Answer Type: Qualitative\\n    Output: \"The yellow chair is next to the blue sofa\"\\n\\n    Your task: Provide an answer to the question. No greetings or comments. Just provide the answer.\\n    Question: Where is the coffee table positioned in the room?\\n    Question Type: qualitative\\n    '},\n",
       " {'path': 'img/test/aa016553.jpg',\n",
       "  'question': 'Where is the vase positioned with respect to the coffee table?',\n",
       "  'true_answer': 'On the coffee table',\n",
       "  'type_question': 'qualitative',\n",
       "  'answer': '\\n    You will be provided an image and a question about the image.\\n    You will also be told if the answer expected is a qualitative or quantitative answer.\\n    Please provide an answer to the question. \\n\\n    Example 1:\\n    Question: \"How far is the yellow finger from the silver can?\"\\n    Expected Answer Type: Quantitative\\n    Output: \"The yellow finger is one and a half meters away from the silver can\"\\n\\n    Example 2:\\n    Question: \"What is next to the blue sofa?\"\\n    Expected Answer Type: Qualitative\\n    Output: \"The yellow chair is next to the blue sofa\"\\n\\n    Your task: Provide an answer to the question. No greetings or comments. Just provide the answer.\\n    Question: Where is the vase positioned with respect to the coffee table?\\n    Question Type: qualitative\\n    '},\n",
       " {'path': 'img/test/aa016553.jpg',\n",
       "  'question': 'Where is the book positioned with respect to the room?',\n",
       "  'true_answer': 'On the right side of the room',\n",
       "  'type_question': 'qualitative',\n",
       "  'answer': '\\n    You will be provided an image and a question about the image.\\n    You will also be told if the answer expected is a qualitative or quantitative answer.\\n    Please provide an answer to the question. \\n\\n    Example 1:\\n    Question: \"How far is the yellow finger from the silver can?\"\\n    Expected Answer Type: Quantitative\\n    Output: \"The yellow finger is one and a half meters away from the silver can\"\\n\\n    Example 2:\\n    Question: \"What is next to the blue sofa?\"\\n    Expected Answer Type: Qualitative\\n    Output: \"The yellow chair is next to the blue sofa\"\\n\\n    Your task: Provide an answer to the question. No greetings or comments. Just provide the answer.\\n    Question: Where is the book positioned with respect to the room?\\n    Question Type: qualitative\\n    '},\n",
       " {'path': 'img/test/aa016553.jpg',\n",
       "  'question': 'Where is the TV positioned with respect to the right chair?',\n",
       "  'true_answer': 'Mounted on the wall above the right chair',\n",
       "  'type_question': 'qualitative',\n",
       "  'answer': '\\n    You will be provided an image and a question about the image.\\n    You will also be told if the answer expected is a qualitative or quantitative answer.\\n    Please provide an answer to the question. \\n\\n    Example 1:\\n    Question: \"How far is the yellow finger from the silver can?\"\\n    Expected Answer Type: Quantitative\\n    Output: \"The yellow finger is one and a half meters away from the silver can\"\\n\\n    Example 2:\\n    Question: \"What is next to the blue sofa?\"\\n    Expected Answer Type: Qualitative\\n    Output: \"The yellow chair is next to the blue sofa\"\\n\\n    Your task: Provide an answer to the question. No greetings or comments. Just provide the answer.\\n    Question: Where is the TV positioned with respect to the right chair?\\n    Question Type: qualitative\\n    '},\n",
       " {'path': 'img/test/aa016553.jpg',\n",
       "  'question': 'Where is the fireplace positioned with respect to the room?',\n",
       "  'true_answer': 'On the right side of the room',\n",
       "  'type_question': 'qualitative',\n",
       "  'answer': '\\n    You will be provided an image and a question about the image.\\n    You will also be told if the answer expected is a qualitative or quantitative answer.\\n    Please provide an answer to the question. \\n\\n    Example 1:\\n    Question: \"How far is the yellow finger from the silver can?\"\\n    Expected Answer Type: Quantitative\\n    Output: \"The yellow finger is one and a half meters away from the silver can\"\\n\\n    Example 2:\\n    Question: \"What is next to the blue sofa?\"\\n    Expected Answer Type: Qualitative\\n    Output: \"The yellow chair is next to the blue sofa\"\\n\\n    Your task: Provide an answer to the question. No greetings or comments. Just provide the answer.\\n    Question: Where is the fireplace positioned with respect to the room?\\n    Question Type: qualitative\\n    '},\n",
       " {'path': 'img/test/aa016553.jpg',\n",
       "  'question': 'Where is the lamp positioned with respect to the room?',\n",
       "  'true_answer': 'On the left side of the room',\n",
       "  'type_question': 'qualitative',\n",
       "  'answer': '\\n    You will be provided an image and a question about the image.\\n    You will also be told if the answer expected is a qualitative or quantitative answer.\\n    Please provide an answer to the question. \\n\\n    Example 1:\\n    Question: \"How far is the yellow finger from the silver can?\"\\n    Expected Answer Type: Quantitative\\n    Output: \"The yellow finger is one and a half meters away from the silver can\"\\n\\n    Example 2:\\n    Question: \"What is next to the blue sofa?\"\\n    Expected Answer Type: Qualitative\\n    Output: \"The yellow chair is next to the blue sofa\"\\n\\n    Your task: Provide an answer to the question. No greetings or comments. Just provide the answer.\\n    Question: Where is the lamp positioned with respect to the room?\\n    Question Type: qualitative\\n    '}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vlm.process_questions(, None, None, None, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version is above 3.10, patching the collections module.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/acc_vis/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:517: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoConfig, AutoModelForCausalLM\n",
    "from janus.models import MultiModalityCausalLM, VLChatProcessor\n",
    "from PIL import Image\n",
    "\n",
    "def load_model(model_path: str = \"deepseek-ai/Janus-1.3B\"):\n",
    "    \"\"\"\n",
    "    Loads the Janus model and processor.\n",
    "    \"\"\"\n",
    "    config = AutoConfig.from_pretrained(model_path)\n",
    "    # For improved performance or if you get CUDA-related errors:\n",
    "    # config.language_config._attn_implementation = 'eager'\n",
    "    language_config = config.language_config\n",
    "    language_config._attn_implementation = 'eager'\n",
    "\n",
    "    # Load the base model\n",
    "    vl_gpt = AutoModelForCausalLM.from_pretrained(\n",
    "        model_path,\n",
    "        language_config=language_config,\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "\n",
    "    # Move model to GPU if available, otherwise CPU\n",
    "    if torch.cuda.is_available():\n",
    "        vl_gpt = vl_gpt.to(torch.bfloat16).cuda()\n",
    "    else:\n",
    "        vl_gpt = vl_gpt.to(torch.float16)\n",
    "\n",
    "    # Load the processor\n",
    "    vl_chat_processor = VLChatProcessor.from_pretrained(model_path)\n",
    "\n",
    "    return vl_gpt, vl_chat_processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading model...\")\n",
    "vl_gpt, vl_chat_processor = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.inference_mode()\n",
    "def ask_janus(\n",
    "    vl_gpt: MultiModalityCausalLM,\n",
    "    vl_chat_processor: VLChatProcessor,\n",
    "    image_path: str,\n",
    "    question: str,\n",
    "    seed: int = 42,\n",
    "    top_p: float = 0.95,\n",
    "    temperature: float = 0.1\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Given an image path and a question, returns the answer predicted by the Janus model.\n",
    "    \"\"\"\n",
    "    # Set random seeds for reproducibility\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "\n",
    "    # Read and prepare the image\n",
    "    pil_image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "    # Build conversation data\n",
    "    conversation = [\n",
    "        {\n",
    "            \"role\": \"User\",\n",
    "            \"content\": f\"<image_placeholder>\\n{question}\",\n",
    "            \"images\": [pil_image],\n",
    "        },\n",
    "        {\"role\": \"Assistant\", \"content\": \"\"},\n",
    "    ]\n",
    "\n",
    "    # Move data to correct device / dtype\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    dtype = torch.bfloat16 if torch.cuda.is_available() else torch.float16\n",
    "\n",
    "    # Process input (tokenization, image features, etc.)\n",
    "    prepare_inputs = vl_chat_processor(\n",
    "        conversations=conversation, images=[pil_image], force_batchify=True\n",
    "    ).to(device, dtype=dtype)\n",
    "\n",
    "    # Convert tokens + embeddings for the model\n",
    "    inputs_embeds = vl_gpt.prepare_inputs_embeds(**prepare_inputs)\n",
    "\n",
    "    # Generate the answer\n",
    "    tokenizer = vl_chat_processor.tokenizer\n",
    "    outputs = vl_gpt.language_model.generate(\n",
    "        inputs_embeds=inputs_embeds,\n",
    "        attention_mask=prepare_inputs.attention_mask,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        bos_token_id=tokenizer.bos_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        max_new_tokens=512,\n",
    "        do_sample=(temperature != 0.0),\n",
    "        use_cache=True,\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "    )\n",
    "\n",
    "    # Decode model output into text\n",
    "    answer = tokenizer.decode(outputs[0].cpu().tolist(), skip_special_tokens=True)\n",
    "    return answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acc_vis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
