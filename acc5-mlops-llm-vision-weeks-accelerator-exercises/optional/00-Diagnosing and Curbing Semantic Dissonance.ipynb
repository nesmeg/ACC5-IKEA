{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Dissonance in RAG Systems\n",
    "\n",
    "Semantic dissonance occurs when the relationships between a query and its retrieved knowledge are misaligned, producing unreliable or irrelevant results. This often happens in Retrieval-Augmented Generation (RAG) systems when embeddings fail to capture the true semantic intent of a query, resulting in comparisons that appear random or noisy.\n",
    "\n",
    "This problem is particularly common when the task involves highly specific domains or when embeddings rely on general-purpose language models without domain-specific fine-tuning. Below, we’ll explore an example illustrating semantic dissonance and outline strategies to mitigate it.\n",
    "\n",
    "---\n",
    "\n",
    "## Use Case: RAG for SQL Table Retrieval\n",
    "\n",
    "Imagine building a RAG system to help internal teams identify the most relevant SQL tables for specific business questions. In this example, we explore how different retrieval strategies can affect performance.\n",
    "\n",
    "### Example Setup\n",
    "\n",
    "The setup involves two distinct SQL table schemas and a series of hypothetical questions. The goal is to determine how well the RAG system retrieves the most relevant table based on the input query.\n",
    "\n",
    "#### SQL Table Schemas:\n",
    "1. **`sales.purchases`**: Contains highly detailed, raw user event data within product flows.\n",
    "2. **`analytics.purchases`**: Summarized analytics with aggregated purchase data.\n",
    "\n",
    "#### Hypothetical Questions:\n",
    "1. What is the impact of IP address on the types of products viewed and purchased?\n",
    "2. What is the overall trend in fourniture sales this quarter?\n",
    "3. Is there unusual behavior within a few seconds of each hour?\n",
    "4. How does user engagement change around major events like New Year’s?\n",
    "\n",
    "#### Metadata for Tables:\n",
    "- Brief descriptions of each table.\n",
    "- Example questions that each table is uniquely qualified to answer.\n",
    "\n",
    "---\n",
    "\n",
    "## Exploring Noisy Cosine Similarity\n",
    "\n",
    "To highlight semantic dissonance, we compared the queries against randomly generated embeddings (\"garbage\"). The noisy cosine similarity scores revealed that the system had no consistent ability to rank the most relevant tables. This inconsistency demonstrates how raw embeddings alone can fail to establish meaningful connections between queries and knowledge.\n",
    "\n",
    "---\n",
    "\n",
    "## Comparing Retrieval Strategies\n",
    "\n",
    "To better understand how to reduce semantic dissonance, we evaluated four retrieval strategies, combining different levels of context and metadata:\n",
    "\n",
    "### Strategy 1: **Table Schema Only**\n",
    "- Uses just the raw schema definitions for comparisons.\n",
    "- Performance: Minimal semantic alignment. Queries often fail to map to the intended tables.\n",
    "\n",
    "### Strategy 2: **Table Schema + Brief Description**\n",
    "- Augments schema definitions with a concise summary of the table's purpose.\n",
    "- Performance: Slight improvement. Context from descriptions helps guide matches, but results remain inconsistent.\n",
    "\n",
    "### Strategy 3: **Table Schema + Brief Description + Sample Questions**\n",
    "- Adds example questions that each table is uniquely qualified to answer.\n",
    "- Performance: Significant improvement. Sample questions create a bridge between the intent of the query and the table’s purpose.\n",
    "\n",
    "### Strategy 4: **Sample Questions Only**\n",
    "- Compares queries exclusively against the sample questions.\n",
    "- Performance: Highly effective. Matching directly against example questions provides the most reliable semantic alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the embedding model (gte-large from Hugging Face)\n",
    "model = SentenceTransformer(\"Alibaba-NLP/gte-large-en-v1.5\", trust_remote_code=True)\n",
    "\n",
    "# Utility functions for embedding and cosine similarity\n",
    "def get_embedding(text):\n",
    "    \"\"\"Generate an embedding for the input text.\"\"\"\n",
    "    return model.encode([text])[0]\n",
    "\n",
    "def cosine_sim(v1, v2):\n",
    "    \"\"\"Calculate the cosine similarity between two vectors.\"\"\"\n",
    "    return cosine_similarity([v1], [v2])[0][0]\n",
    "\n",
    "# Define table schemas, descriptions, and sample questions for the furniture industry\n",
    "base_table_text_1 = \"\"\"\n",
    "CREATE TABLE customers.raw_customer_data (\n",
    "    customer_id SERIAL PRIMARY KEY,\n",
    "    first_name VARCHAR(50),\n",
    "    last_name VARCHAR(50),\n",
    "    email VARCHAR(100),\n",
    "    phone_number VARCHAR(20),\n",
    "    address TEXT,\n",
    "    customer_segment VARCHAR(50),\n",
    "    activity_data JSONB,\n",
    "    preferences JSONB,\n",
    "    history JSONB\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "# Product sales summary schema\n",
    "base_table_text_2 = \"\"\"\n",
    "CREATE TABLE analytics.product_sales_summary (\n",
    "    category_id INT PRIMARY KEY,\n",
    "    category_name VARCHAR(50),\n",
    "    metrics JSONB,\n",
    "    performance_data JSONB,\n",
    "    market_data JSONB,\n",
    "    trends JSONB\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "# Enhanced descriptions with strong business context\n",
    "desc1 = \"\"\"Comprehensive customer intelligence platform that serves as the foundation for our personalized retail experience strategy. This data warehouse captures the complete customer lifecycle, from initial browsing patterns to long-term loyalty behavior, enabling sophisticated customer understanding and engagement optimization.\n",
    "\n",
    "Strategic Applications:\n",
    "- Identify customers entering new life stages (moving, marriage, etc.) for targeted campaigns\n",
    "- Predict luxury segment expansion opportunities through browsing pattern analysis\n",
    "- Track customer journey evolution from first purchase to brand advocate\n",
    "- Monitor cross-channel engagement patterns for omnichannel optimization\n",
    "- Analyze style preference shifts for merchandising insights\n",
    "- Detect early churn signals through engagement pattern changes\n",
    "- Profile high-value customer segments for VIP program expansion\n",
    "\n",
    "Key Business Impact:\n",
    "- Powers our 1:1 personalization engine for targeted recommendations\n",
    "- Drives proactive customer retention through early warning systems\n",
    "- Enables dynamic customer segmentation for marketing campaigns\n",
    "- Supports customer lifetime value optimization strategies\n",
    "- Guides service level customization based on customer profiles\"\"\"\n",
    "\n",
    "desc2 = \"\"\"Enterprise-wide market intelligence system integrating product performance analytics with market dynamics for strategic business planning. This platform combines historical performance data, competitive intelligence, and market trends to drive data-informed merchandising and inventory decisions.\n",
    "\n",
    "Strategic Capabilities:\n",
    "- Forecast market demand shifts based on leading indicators\n",
    "- Analyze cross-category purchase patterns for merchandising optimization\n",
    "- Track product lifecycle stages across different market segments\n",
    "- Monitor market share evolution in key geographic regions\n",
    "- Optimize assortment planning based on local preferences\n",
    "- Evaluate promotion effectiveness across customer segments\n",
    "- Plan inventory allocation based on regional dynamics\n",
    "\n",
    "Business Applications:\n",
    "- Guides seasonal collection planning and refresh cycles\n",
    "- Drives market expansion and penetration strategies\n",
    "- Informs pricing optimization across product categories\n",
    "- Supports efficient inventory distribution networks\n",
    "- Enables data-driven merchandising decisions\n",
    "- Powers competitive positioning strategies\n",
    "- Optimizes promotion planning and execution\"\"\"\n",
    "\n",
    "# Sample questions enriched with business context\n",
    "sq1 = \"\"\"\n",
    "- Which customers are showing early indicators of transitioning to luxury furniture segments?\n",
    "- How can we identify customers likely to renovate their entire home based on recent browsing patterns?\n",
    "- Which first-time buyers show potential for becoming lifetime customers?\n",
    "- What customer segments are most responsive to our designer collaboration collections?\n",
    "- Which loyal customers are at risk of switching to competitors based on engagement patterns?\n",
    "- How do we identify customers ready for our premium design consultation service?\n",
    "- Which customers' browsing patterns indicate upcoming major purchases?\n",
    "- How can we predict which customers will respond best to our seasonal collection previews?\n",
    "- What behavioral patterns indicate a customer's potential for VIP program enrollment?\n",
    "- Which customers should receive priority access to our limited edition collections?\n",
    "\"\"\"\n",
    "\n",
    "sq2 = \"\"\"\n",
    "- How do weather patterns impact seasonal furniture preferences across regions?\n",
    "- What market signals indicate emerging style trends in urban vs. suburban areas?\n",
    "- Which product categories show complementary purchase patterns in premium segments?\n",
    "- How does market saturation affect premium furniture pricing by region?\n",
    "- What seasonal factors influence outdoor furniture performance in different climates?\n",
    "- How do macroeconomic indicators affect luxury furniture segment performance?\n",
    "- Which product combinations drive highest customer lifetime value?\n",
    "- How do regional design preferences impact collection performance?\n",
    "- What market conditions signal optimal timing for new collection launches?\n",
    "- How does competitive pricing affect our premium line performance?\n",
    "\"\"\"\n",
    "\n",
    "# Questions requiring deep contextual understanding\n",
    "qas = [\n",
    "    (\"customers.raw_customer_data\", \"Which customers show early signs of upgrading their entire home furnishing style?\"),  \n",
    "    (\"analytics.product_sales_summary\", \"How should we adjust our collection launch timing for different climate zones?\"),  \n",
    "    (\"customers.raw_customer_data\", \"Which customers are most likely to become brand advocates for our artisan collection?\"),  \n",
    "    (\"analytics.product_sales_summary\", \"What product mix will maximize market share in emerging urban markets?\"),  \n",
    "    (\"customers.raw_customer_data\", \"Which customers should receive priority access to our limited edition designer collaboration?\"),  \n",
    "    (\"analytics.product_sales_summary\", \"How should we optimize our showroom layouts for the upcoming season across different regions?\") \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "\n",
    "\n",
    "class RAGMetrics:\n",
    "    def __init__(self):\n",
    "        self.correct = 0\n",
    "        self.total = 0\n",
    "        self.total_separation = 0.0\n",
    "        self.high_confidence_correct = 0  # Correct predictions with high separation\n",
    "        self.low_confidence_mistakes = 0  # Wrong predictions with low separation\n",
    "        self.separations = []  # Store all separations for statistical analysis\n",
    "\n",
    "    @property\n",
    "    def accuracy(self):\n",
    "        return (self.correct / self.total * 100) if self.total > 0 else 0\n",
    "\n",
    "    @property\n",
    "    def avg_separation(self):\n",
    "        return self.total_separation / self.total if self.total > 0 else 0\n",
    "\n",
    "    @property\n",
    "    def high_confidence_accuracy(self):\n",
    "        high_conf_total = len([s for s in self.separations if abs(s) >= 0.1])\n",
    "        return (self.high_confidence_correct / high_conf_total * 100) if high_conf_total > 0 else 0\n",
    "\n",
    "\n",
    "def get_confidence_color(separation: float) -> str:\n",
    "    HIGH_CONFIDENCE = 0.1\n",
    "    MEDIUM_CONFIDENCE = 0.05\n",
    "    if abs(separation) >= HIGH_CONFIDENCE:\n",
    "        return bcolors.OKGREEN\n",
    "    elif abs(separation) >= MEDIUM_CONFIDENCE:\n",
    "        return bcolors.WARNING\n",
    "    return bcolors.FAIL\n",
    "\n",
    "\n",
    "def print_confidence_indicator(separation: float) -> str:\n",
    "    HIGH_CONFIDENCE = 0.1\n",
    "    MEDIUM_CONFIDENCE = 0.05\n",
    "    if abs(separation) >= HIGH_CONFIDENCE:\n",
    "        return \"HIGH CONFIDENCE\"\n",
    "    elif abs(separation) >= MEDIUM_CONFIDENCE:\n",
    "        return \"MEDIUM CONFIDENCE\"\n",
    "    return \"LOW CONFIDENCE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[95m### Step 1: Analyzing similarities between garbage inputs and questions/table schemas ###\u001b[0m\n",
      "\n",
      "\u001b[94mGarbage Input: E = mc^2\u001b[0m\n",
      "\n",
      "\u001b[1mComparing garbage input with questions:\u001b[0m\n",
      "\u001b[93m  Q1: 'Which customers show early signs of upgrading their entire home furnishing style?'\n",
      "    Similarity: 0.366\u001b[0m\n",
      "\u001b[93m  Q2: 'How should we adjust our collection launch timing for different climate zones?'\n",
      "    Similarity: 0.382\u001b[0m\n",
      "\u001b[93m  Q3: 'Which customers are most likely to become brand advocates for our artisan collection?'\n",
      "    Similarity: 0.327\u001b[0m\n",
      "\u001b[93m  Q4: 'What product mix will maximize market share in emerging urban markets?'\n",
      "    Similarity: 0.341\u001b[0m\n",
      "\u001b[93m  Q5: 'Which customers should receive priority access to our limited edition designer collaboration?'\n",
      "    Similarity: 0.320\u001b[0m\n",
      "\u001b[91m  Q6: 'How should we optimize our showroom layouts for the upcoming season across different regions?'\n",
      "    Similarity: 0.297\u001b[0m\n",
      "\n",
      "\u001b[92mMost similar question: 'How should we adjust our collection launch timing for different climate zones?' with similarity 0.382\u001b[0m\n",
      "\n",
      "\u001b[1mComparing garbage input with table schemas:\u001b[0m\n",
      "\u001b[93m  Table 1: Schema Similarity: 0.403\u001b[0m\n",
      "\u001b[93m  Table 2: Schema Similarity: 0.374\u001b[0m\n",
      "\n",
      "\u001b[92mMost similar table schema: Table 1 with similarity 0.403\u001b[0m\n",
      "\n",
      "\u001b[1m--- End of analysis for this garbage input ---\u001b[0m\n",
      "\n",
      "\u001b[94mGarbage Input: Cristiano Ronaldo is the best football player in the world\u001b[0m\n",
      "\n",
      "\u001b[1mComparing garbage input with questions:\u001b[0m\n",
      "\u001b[93m  Q1: 'Which customers show early signs of upgrading their entire home furnishing style?'\n",
      "    Similarity: 0.404\u001b[0m\n",
      "\u001b[93m  Q2: 'How should we adjust our collection launch timing for different climate zones?'\n",
      "    Similarity: 0.315\u001b[0m\n",
      "\u001b[93m  Q3: 'Which customers are most likely to become brand advocates for our artisan collection?'\n",
      "    Similarity: 0.419\u001b[0m\n",
      "\u001b[93m  Q4: 'What product mix will maximize market share in emerging urban markets?'\n",
      "    Similarity: 0.388\u001b[0m\n",
      "\u001b[93m  Q5: 'Which customers should receive priority access to our limited edition designer collaboration?'\n",
      "    Similarity: 0.361\u001b[0m\n",
      "\u001b[93m  Q6: 'How should we optimize our showroom layouts for the upcoming season across different regions?'\n",
      "    Similarity: 0.309\u001b[0m\n",
      "\n",
      "\u001b[92mMost similar question: 'Which customers are most likely to become brand advocates for our artisan collection?' with similarity 0.419\u001b[0m\n",
      "\n",
      "\u001b[1mComparing garbage input with table schemas:\u001b[0m\n",
      "\u001b[93m  Table 1: Schema Similarity: 0.428\u001b[0m\n",
      "\u001b[93m  Table 2: Schema Similarity: 0.426\u001b[0m\n",
      "\n",
      "\u001b[92mMost similar table schema: Table 1 with similarity 0.428\u001b[0m\n",
      "\n",
      "\u001b[1m--- End of analysis for this garbage input ---\u001b[0m\n",
      "\n",
      "\u001b[94mGarbage Input: Fernando Alonso won the Formula 1 championship twice\u001b[0m\n",
      "\n",
      "\u001b[1mComparing garbage input with questions:\u001b[0m\n",
      "\u001b[93m  Q1: 'Which customers show early signs of upgrading their entire home furnishing style?'\n",
      "    Similarity: 0.355\u001b[0m\n",
      "\u001b[93m  Q2: 'How should we adjust our collection launch timing for different climate zones?'\n",
      "    Similarity: 0.340\u001b[0m\n",
      "\u001b[93m  Q3: 'Which customers are most likely to become brand advocates for our artisan collection?'\n",
      "    Similarity: 0.334\u001b[0m\n",
      "\u001b[93m  Q4: 'What product mix will maximize market share in emerging urban markets?'\n",
      "    Similarity: 0.369\u001b[0m\n",
      "\u001b[93m  Q5: 'Which customers should receive priority access to our limited edition designer collaboration?'\n",
      "    Similarity: 0.333\u001b[0m\n",
      "\u001b[93m  Q6: 'How should we optimize our showroom layouts for the upcoming season across different regions?'\n",
      "    Similarity: 0.301\u001b[0m\n",
      "\n",
      "\u001b[92mMost similar question: 'What product mix will maximize market share in emerging urban markets?' with similarity 0.369\u001b[0m\n",
      "\n",
      "\u001b[1mComparing garbage input with table schemas:\u001b[0m\n",
      "\u001b[93m  Table 1: Schema Similarity: 0.383\u001b[0m\n",
      "\u001b[93m  Table 2: Schema Similarity: 0.360\u001b[0m\n",
      "\n",
      "\u001b[92mMost similar table schema: Table 1 with similarity 0.383\u001b[0m\n",
      "\n",
      "\u001b[1m--- End of analysis for this garbage input ---\u001b[0m\n",
      "\n",
      "\u001b[94mGarbage Input: Unrelated text about quantum physics\u001b[0m\n",
      "\n",
      "\u001b[1mComparing garbage input with questions:\u001b[0m\n",
      "\u001b[93m  Q1: 'Which customers show early signs of upgrading their entire home furnishing style?'\n",
      "    Similarity: 0.367\u001b[0m\n",
      "\u001b[93m  Q2: 'How should we adjust our collection launch timing for different climate zones?'\n",
      "    Similarity: 0.364\u001b[0m\n",
      "\u001b[93m  Q3: 'Which customers are most likely to become brand advocates for our artisan collection?'\n",
      "    Similarity: 0.338\u001b[0m\n",
      "\u001b[93m  Q4: 'What product mix will maximize market share in emerging urban markets?'\n",
      "    Similarity: 0.384\u001b[0m\n",
      "\u001b[93m  Q5: 'Which customers should receive priority access to our limited edition designer collaboration?'\n",
      "    Similarity: 0.305\u001b[0m\n",
      "\u001b[93m  Q6: 'How should we optimize our showroom layouts for the upcoming season across different regions?'\n",
      "    Similarity: 0.301\u001b[0m\n",
      "\n",
      "\u001b[92mMost similar question: 'What product mix will maximize market share in emerging urban markets?' with similarity 0.384\u001b[0m\n",
      "\n",
      "\u001b[1mComparing garbage input with table schemas:\u001b[0m\n",
      "\u001b[93m  Table 1: Schema Similarity: 0.416\u001b[0m\n",
      "\u001b[93m  Table 2: Schema Similarity: 0.398\u001b[0m\n",
      "\n",
      "\u001b[92mMost similar table schema: Table 1 with similarity 0.416\u001b[0m\n",
      "\n",
      "\u001b[1m--- End of analysis for this garbage input ---\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Garbage inputs for comparison\n",
    "garbage_inputs = [\n",
    "    \"E = mc^2\",\n",
    "    \"Cristiano Ronaldo is the best football player in the world\",\n",
    "    \"Fernando Alonso won the Formula 1 championship twice\",\n",
    "    \"Unrelated text about quantum physics\",\n",
    "]\n",
    "\n",
    "print(f\"\\n{bcolors.HEADER}### Step 1: Analyzing similarities between garbage inputs and questions/table schemas ###{bcolors.ENDC}\\n\")\n",
    "\n",
    "for garbage in garbage_inputs:\n",
    "    print(f\"{bcolors.OKBLUE}Garbage Input: {garbage}{bcolors.ENDC}\")\n",
    "    emb_garbage = get_embedding(garbage)\n",
    "\n",
    "    # Compare garbage input with questions\n",
    "    print(f\"\\n{bcolors.BOLD}Comparing garbage input with questions:{bcolors.ENDC}\")\n",
    "    max_question_similarity = -1\n",
    "    most_similar_question = None\n",
    "\n",
    "    for i, (_, question) in enumerate(qas):\n",
    "        emb_question = get_embedding(question)\n",
    "        similarity = cosine_sim(emb_garbage, emb_question)\n",
    "        if similarity > max_question_similarity:\n",
    "            max_question_similarity = similarity\n",
    "            most_similar_question = question\n",
    "        similarity_color = bcolors.OKGREEN if similarity > 0.5 else bcolors.WARNING if similarity > 0.3 else bcolors.FAIL\n",
    "        print(f\"{similarity_color}  Q{i+1}: '{question}'\\n    Similarity: {similarity:.3f}{bcolors.ENDC}\")\n",
    "\n",
    "    if most_similar_question:\n",
    "        print(f\"\\n{bcolors.OKGREEN}Most similar question: '{most_similar_question}' \"\n",
    "              f\"with similarity {max_question_similarity:.3f}{bcolors.ENDC}\")\n",
    "\n",
    "    # Compare garbage input with table schemas\n",
    "    print(f\"\\n{bcolors.BOLD}Comparing garbage input with table schemas:{bcolors.ENDC}\")\n",
    "    max_table_similarity = -1\n",
    "    most_similar_table = None\n",
    "\n",
    "    for i, (table_name, table_text) in enumerate([\n",
    "        (\"Table 1\", base_table_text_1),\n",
    "        (\"Table 2\", base_table_text_2),\n",
    "    ]):\n",
    "        emb_table = get_embedding(table_text)\n",
    "        similarity = cosine_sim(emb_garbage, emb_table)\n",
    "        if similarity > max_table_similarity:\n",
    "            max_table_similarity = similarity\n",
    "            most_similar_table = table_name\n",
    "        similarity_color = bcolors.OKGREEN if similarity > 0.5 else bcolors.WARNING if similarity > 0.3 else bcolors.FAIL\n",
    "        print(f\"{similarity_color}  {table_name}: Schema Similarity: {similarity:.3f}{bcolors.ENDC}\")\n",
    "\n",
    "    if most_similar_table:\n",
    "        print(f\"\\n{bcolors.OKGREEN}Most similar table schema: {most_similar_table} \"\n",
    "              f\"with similarity {max_table_similarity:.3f}{bcolors.ENDC}\")\n",
    "\n",
    "    print(f\"\\n{bcolors.BOLD}--- End of analysis for this garbage input ---{bcolors.ENDC}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[95m### Strategy 1: Table Schema Without Enrichment ###\u001b[0m\n",
      "\u001b[94mCosine similarity between Table 1 and Table 2 schemas: 0.8510000109672546\u001b[0m\n",
      "\n",
      "\u001b[94mProcessing Question: 'Which customers show early signs of upgrading their entire home furnishing style?'\u001b[0m\n",
      "\u001b[92mCorrect Table: customers.raw_customer_data\u001b[0m\n",
      "\n",
      "\u001b[94m  Cosine Similarity with customers.raw_customer_data: 0.466\u001b[0m\n",
      "\u001b[94m  Cosine Similarity with analytics.product_sales_summary: 0.456\u001b[0m\n",
      "\u001b[92m  Rank 1: customers.raw_customer_data (Similarity: 0.466) ✓\u001b[0m\n",
      "\u001b[91m  Rank 2: analytics.product_sales_summary (Similarity: 0.456) ✗\u001b[0m\n",
      "\u001b[91m  Separation: +0.010 - LOW CONFIDENCE\u001b[0m\n",
      "\n",
      "\u001b[94mProcessing Question: 'How should we adjust our collection launch timing for different climate zones?'\u001b[0m\n",
      "\u001b[92mCorrect Table: analytics.product_sales_summary\u001b[0m\n",
      "\n",
      "\u001b[94m  Cosine Similarity with customers.raw_customer_data: 0.420\u001b[0m\n",
      "\u001b[94m  Cosine Similarity with analytics.product_sales_summary: 0.406\u001b[0m\n",
      "\u001b[91m  Rank 1: customers.raw_customer_data (Similarity: 0.420) ✗\u001b[0m\n",
      "\u001b[92m  Rank 2: analytics.product_sales_summary (Similarity: 0.406) ✓\u001b[0m\n",
      "\u001b[91m  Separation: +0.014 - LOW CONFIDENCE\u001b[0m\n",
      "\n",
      "\u001b[94mProcessing Question: 'Which customers are most likely to become brand advocates for our artisan collection?'\u001b[0m\n",
      "\u001b[92mCorrect Table: customers.raw_customer_data\u001b[0m\n",
      "\n",
      "\u001b[94m  Cosine Similarity with customers.raw_customer_data: 0.470\u001b[0m\n",
      "\u001b[94m  Cosine Similarity with analytics.product_sales_summary: 0.447\u001b[0m\n",
      "\u001b[92m  Rank 1: customers.raw_customer_data (Similarity: 0.470) ✓\u001b[0m\n",
      "\u001b[91m  Rank 2: analytics.product_sales_summary (Similarity: 0.447) ✗\u001b[0m\n",
      "\u001b[91m  Separation: +0.023 - LOW CONFIDENCE\u001b[0m\n",
      "\n",
      "\u001b[94mProcessing Question: 'What product mix will maximize market share in emerging urban markets?'\u001b[0m\n",
      "\u001b[92mCorrect Table: analytics.product_sales_summary\u001b[0m\n",
      "\n",
      "\u001b[94m  Cosine Similarity with customers.raw_customer_data: 0.358\u001b[0m\n",
      "\u001b[94m  Cosine Similarity with analytics.product_sales_summary: 0.416\u001b[0m\n",
      "\u001b[92m  Rank 1: analytics.product_sales_summary (Similarity: 0.416) ✓\u001b[0m\n",
      "\u001b[91m  Rank 2: customers.raw_customer_data (Similarity: 0.358) ✗\u001b[0m\n",
      "\u001b[93m  Separation: +0.058 - MEDIUM CONFIDENCE\u001b[0m\n",
      "\n",
      "\u001b[94mProcessing Question: 'Which customers should receive priority access to our limited edition designer collaboration?'\u001b[0m\n",
      "\u001b[92mCorrect Table: customers.raw_customer_data\u001b[0m\n",
      "\n",
      "\u001b[94m  Cosine Similarity with customers.raw_customer_data: 0.415\u001b[0m\n",
      "\u001b[94m  Cosine Similarity with analytics.product_sales_summary: 0.392\u001b[0m\n",
      "\u001b[92m  Rank 1: customers.raw_customer_data (Similarity: 0.415) ✓\u001b[0m\n",
      "\u001b[91m  Rank 2: analytics.product_sales_summary (Similarity: 0.392) ✗\u001b[0m\n",
      "\u001b[91m  Separation: +0.023 - LOW CONFIDENCE\u001b[0m\n",
      "\n",
      "\u001b[94mProcessing Question: 'How should we optimize our showroom layouts for the upcoming season across different regions?'\u001b[0m\n",
      "\u001b[92mCorrect Table: analytics.product_sales_summary\u001b[0m\n",
      "\n",
      "\u001b[94m  Cosine Similarity with customers.raw_customer_data: 0.382\u001b[0m\n",
      "\u001b[94m  Cosine Similarity with analytics.product_sales_summary: 0.418\u001b[0m\n",
      "\u001b[92m  Rank 1: analytics.product_sales_summary (Similarity: 0.418) ✓\u001b[0m\n",
      "\u001b[91m  Rank 2: customers.raw_customer_data (Similarity: 0.382) ✗\u001b[0m\n",
      "\u001b[91m  Separation: +0.036 - LOW CONFIDENCE\u001b[0m\n",
      "\n",
      "\u001b[95m### Summary for table-schema-no-enrichment ###\u001b[0m\n",
      "\u001b[94m- Accuracy: 83.3%\u001b[0m\n",
      "\u001b[94m- Average Separation: 0.027\u001b[0m\n",
      "\u001b[94m- High Confidence Accuracy: 0.0%\u001b[0m\n",
      "\u001b[94m- Low Confidence Mistakes: 1\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Strategy 1: Table schema without enrichment\n",
    "def run_strategy_1(base_table_text_1, base_table_text_2, qas, rankings_by_question):\n",
    "    method = \"table-schema-no-enrichment\"\n",
    "    metrics = RAGMetrics()  # Initialize metrics for this strategy\n",
    "\n",
    "    # Handle the case where rankings_by_question is None\n",
    "    if rankings_by_question is None:\n",
    "        rankings_by_question = {}\n",
    "\n",
    "    tables = [\n",
    "        (\"customers.raw_customer_data\", base_table_text_1),\n",
    "        (\"analytics.product_sales_summary\", base_table_text_2),\n",
    "    ]\n",
    "\n",
    "    # Generate embeddings for the tables\n",
    "    emb_table1 = get_embedding(base_table_text_1)\n",
    "    emb_table2 = get_embedding(base_table_text_2)\n",
    "\n",
    "    print(f\"\\n{bcolors.HEADER}### Strategy 1: Table Schema Without Enrichment ###{bcolors.ENDC}\")\n",
    "    print(f\"{bcolors.OKBLUE}Cosine similarity between Table 1 and Table 2 schemas: \"\n",
    "          f\"{round(cosine_sim(emb_table1, emb_table2), 3)}{bcolors.ENDC}\\n\")\n",
    "\n",
    "    HIGH_CONFIDENCE = 0.1\n",
    "    MEDIUM_CONFIDENCE = 0.05\n",
    "\n",
    "    for (correct_table, question) in qas:\n",
    "        print(f\"{bcolors.OKBLUE}Processing Question: '{question}'{bcolors.ENDC}\")\n",
    "        print(f\"{bcolors.OKGREEN}Correct Table: {correct_table}{bcolors.ENDC}\\n\")\n",
    "\n",
    "        question_emb = get_embedding(question)\n",
    "        table_rankings = []\n",
    "\n",
    "        for (table_name, table_schema) in tables:\n",
    "            table_emb = get_embedding(table_schema)\n",
    "            similarity = round(cosine_sim(question_emb, table_emb), 3)\n",
    "            table_rankings.append((similarity, table_name))\n",
    "            print(f\"{bcolors.OKBLUE}  Cosine Similarity with {table_name}: {similarity:.3f}{bcolors.ENDC}\")\n",
    "\n",
    "        table_rankings = sorted(table_rankings, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        # Calculate separation and update metrics\n",
    "        separation = table_rankings[0][0] - table_rankings[1][0] if len(table_rankings) > 1 else 0\n",
    "        metrics.total += 1\n",
    "        metrics.total_separation += separation\n",
    "        metrics.separations.append(separation)\n",
    "\n",
    "        # Update metrics based on correctness and confidence\n",
    "        correct_prediction = table_rankings[0][1] == correct_table\n",
    "        if correct_prediction:\n",
    "            metrics.correct += 1\n",
    "            if abs(separation) >= HIGH_CONFIDENCE:\n",
    "                metrics.high_confidence_correct += 1\n",
    "        elif abs(separation) < MEDIUM_CONFIDENCE:\n",
    "            metrics.low_confidence_mistakes += 1\n",
    "\n",
    "        # Print rankings and confidence indicators\n",
    "        for rank, (similarity, table_name) in enumerate(table_rankings, start=1):\n",
    "            is_correct = table_name == correct_table\n",
    "            confidence_color = get_confidence_color(separation)\n",
    "            text = f\"  Rank {rank}: {table_name} (Similarity: {similarity:.3f})\"\n",
    "            print(f\"{bcolors.OKGREEN if is_correct else bcolors.FAIL}{text}{' ✓' if is_correct else ' ✗'}{bcolors.ENDC}\")\n",
    "\n",
    "        # Print separation with confidence level\n",
    "        confidence_color = get_confidence_color(separation)\n",
    "        confidence_text = print_confidence_indicator(separation)\n",
    "        print(f\"{confidence_color}  Separation: {separation:+.3f} - {confidence_text}{bcolors.ENDC}\\n\")\n",
    "\n",
    "        # Store results in rankings_by_question\n",
    "        if question not in rankings_by_question:\n",
    "            rankings_by_question[question] = {}\n",
    "        rankings_by_question[question][method] = table_rankings\n",
    "\n",
    "    # Print strategy-level summary metrics\n",
    "    print(f\"{bcolors.HEADER}### Summary for {method} ###{bcolors.ENDC}\")\n",
    "    print(f\"{bcolors.OKBLUE}- Accuracy: {metrics.accuracy:.1f}%{bcolors.ENDC}\")\n",
    "    print(f\"{bcolors.OKBLUE}- Average Separation: {metrics.avg_separation:.3f}{bcolors.ENDC}\")\n",
    "    print(f\"{bcolors.OKBLUE}- High Confidence Accuracy: {metrics.high_confidence_accuracy:.1f}%{bcolors.ENDC}\")\n",
    "    print(f\"{bcolors.OKBLUE}- Low Confidence Mistakes: {metrics.low_confidence_mistakes}{bcolors.ENDC}\\n\")\n",
    "\n",
    "    return rankings_by_question\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# Ensure rankings_by_question is carried forward or passed appropriately\n",
    "rankings_by_question = run_strategy_1(base_table_text_1, base_table_text_2, qas, rankings_by_question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[95m### Strategy 2: Table Schema With Enrichment ###\u001b[0m\n",
      "\u001b[94mCosine similarity between Table 1 and Table 2 schemas (with descriptions): 0.7710000276565552\u001b[0m\n",
      "\n",
      "\u001b[94mProcessing Question: 'Which customers show early signs of upgrading their entire home furnishing style?'\u001b[0m\n",
      "\u001b[92mCorrect Table: customers.raw_customer_data\u001b[0m\n",
      "\n",
      "\u001b[94m  Cosine Similarity with customers.raw_customer_data: 0.560\u001b[0m\n",
      "\u001b[94m  Cosine Similarity with analytics.product_sales_summary: 0.510\u001b[0m\n",
      "\u001b[92m  Rank 1: customers.raw_customer_data (Similarity: 0.560) ✓\u001b[0m\n",
      "\u001b[91m  Rank 2: analytics.product_sales_summary (Similarity: 0.510) ✗\u001b[0m\n",
      "\u001b[93m  Separation: +0.050 - MEDIUM CONFIDENCE\u001b[0m\n",
      "\n",
      "\u001b[94mProcessing Question: 'How should we adjust our collection launch timing for different climate zones?'\u001b[0m\n",
      "\u001b[92mCorrect Table: analytics.product_sales_summary\u001b[0m\n",
      "\n",
      "\u001b[94m  Cosine Similarity with customers.raw_customer_data: 0.439\u001b[0m\n",
      "\u001b[94m  Cosine Similarity with analytics.product_sales_summary: 0.483\u001b[0m\n",
      "\u001b[92m  Rank 1: analytics.product_sales_summary (Similarity: 0.483) ✓\u001b[0m\n",
      "\u001b[91m  Rank 2: customers.raw_customer_data (Similarity: 0.439) ✗\u001b[0m\n",
      "\u001b[91m  Separation: +0.044 - LOW CONFIDENCE\u001b[0m\n",
      "\n",
      "\u001b[94mProcessing Question: 'Which customers are most likely to become brand advocates for our artisan collection?'\u001b[0m\n",
      "\u001b[92mCorrect Table: customers.raw_customer_data\u001b[0m\n",
      "\n",
      "\u001b[94m  Cosine Similarity with customers.raw_customer_data: 0.594\u001b[0m\n",
      "\u001b[94m  Cosine Similarity with analytics.product_sales_summary: 0.522\u001b[0m\n",
      "\u001b[92m  Rank 1: customers.raw_customer_data (Similarity: 0.594) ✓\u001b[0m\n",
      "\u001b[91m  Rank 2: analytics.product_sales_summary (Similarity: 0.522) ✗\u001b[0m\n",
      "\u001b[93m  Separation: +0.072 - MEDIUM CONFIDENCE\u001b[0m\n",
      "\n",
      "\u001b[94mProcessing Question: 'What product mix will maximize market share in emerging urban markets?'\u001b[0m\n",
      "\u001b[92mCorrect Table: analytics.product_sales_summary\u001b[0m\n",
      "\n",
      "\u001b[94m  Cosine Similarity with customers.raw_customer_data: 0.440\u001b[0m\n",
      "\u001b[94m  Cosine Similarity with analytics.product_sales_summary: 0.488\u001b[0m\n",
      "\u001b[92m  Rank 1: analytics.product_sales_summary (Similarity: 0.488) ✓\u001b[0m\n",
      "\u001b[91m  Rank 2: customers.raw_customer_data (Similarity: 0.440) ✗\u001b[0m\n",
      "\u001b[91m  Separation: +0.048 - LOW CONFIDENCE\u001b[0m\n",
      "\n",
      "\u001b[94mProcessing Question: 'Which customers should receive priority access to our limited edition designer collaboration?'\u001b[0m\n",
      "\u001b[92mCorrect Table: customers.raw_customer_data\u001b[0m\n",
      "\n",
      "\u001b[94m  Cosine Similarity with customers.raw_customer_data: 0.512\u001b[0m\n",
      "\u001b[94m  Cosine Similarity with analytics.product_sales_summary: 0.481\u001b[0m\n",
      "\u001b[92m  Rank 1: customers.raw_customer_data (Similarity: 0.512) ✓\u001b[0m\n",
      "\u001b[91m  Rank 2: analytics.product_sales_summary (Similarity: 0.481) ✗\u001b[0m\n",
      "\u001b[91m  Separation: +0.031 - LOW CONFIDENCE\u001b[0m\n",
      "\n",
      "\u001b[94mProcessing Question: 'How should we optimize our showroom layouts for the upcoming season across different regions?'\u001b[0m\n",
      "\u001b[92mCorrect Table: analytics.product_sales_summary\u001b[0m\n",
      "\n",
      "\u001b[94m  Cosine Similarity with customers.raw_customer_data: 0.488\u001b[0m\n",
      "\u001b[94m  Cosine Similarity with analytics.product_sales_summary: 0.598\u001b[0m\n",
      "\u001b[92m  Rank 1: analytics.product_sales_summary (Similarity: 0.598) ✓\u001b[0m\n",
      "\u001b[91m  Rank 2: customers.raw_customer_data (Similarity: 0.488) ✗\u001b[0m\n",
      "\u001b[92m  Separation: +0.110 - HIGH CONFIDENCE\u001b[0m\n",
      "\n",
      "\u001b[95m### Summary for table-schema-desc ###\u001b[0m\n",
      "\u001b[94m- Accuracy: 100.0%\u001b[0m\n",
      "\u001b[94m- Average Separation: 0.059\u001b[0m\n",
      "\u001b[94m- High Confidence Accuracy: 100.0%\u001b[0m\n",
      "\u001b[94m- Low Confidence Mistakes: 0\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Strategy 2: Table schema with enrichment\n",
    "def run_strategy_2(base_table_text_1, base_table_text_2, desc1, desc2, qas, rankings_by_question):\n",
    "    method = \"table-schema-desc\"\n",
    "    metrics = RAGMetrics()  # Initialize metrics for this strategy\n",
    "\n",
    "    # Handle the case where rankings_by_question is None\n",
    "    if rankings_by_question is None:\n",
    "        rankings_by_question = {}\n",
    "\n",
    "    table1 = f\"\"\"\n",
    "    Description: {desc1}\n",
    "\n",
    "    {base_table_text_1}\n",
    "    \"\"\"\n",
    "    table2 = f\"\"\"\n",
    "    Description: {desc2}\n",
    "\n",
    "    {base_table_text_2}\n",
    "    \"\"\"\n",
    "    tables = [\n",
    "        (\"customers.raw_customer_data\", table1),\n",
    "        (\"analytics.product_sales_summary\", table2),\n",
    "    ]\n",
    "\n",
    "    # Generate embeddings for the tables with descriptions\n",
    "    emb_table1 = get_embedding(table1)\n",
    "    emb_table2 = get_embedding(table2)\n",
    "\n",
    "    print(f\"\\n{bcolors.HEADER}### Strategy 2: Table Schema With Enrichment ###{bcolors.ENDC}\")\n",
    "    print(f\"{bcolors.OKBLUE}Cosine similarity between Table 1 and Table 2 schemas (with descriptions): \"\n",
    "          f\"{round(cosine_sim(emb_table1, emb_table2), 3)}{bcolors.ENDC}\\n\")\n",
    "\n",
    "    HIGH_CONFIDENCE = 0.1\n",
    "    MEDIUM_CONFIDENCE = 0.05\n",
    "\n",
    "    for (correct_table, question) in qas:\n",
    "        print(f\"{bcolors.OKBLUE}Processing Question: '{question}'{bcolors.ENDC}\")\n",
    "        print(f\"{bcolors.OKGREEN}Correct Table: {correct_table}{bcolors.ENDC}\\n\")\n",
    "\n",
    "        question_emb = get_embedding(question)\n",
    "        table_rankings = []\n",
    "\n",
    "        for (table_name, enriched_table) in tables:\n",
    "            table_emb = get_embedding(enriched_table)\n",
    "            similarity = round(cosine_sim(question_emb, table_emb), 3)\n",
    "            table_rankings.append((similarity, table_name))\n",
    "            print(f\"{bcolors.OKBLUE}  Cosine Similarity with {table_name}: {similarity:.3f}{bcolors.ENDC}\")\n",
    "\n",
    "        table_rankings = sorted(table_rankings, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        # Calculate separation and update metrics\n",
    "        separation = table_rankings[0][0] - table_rankings[1][0] if len(table_rankings) > 1 else 0\n",
    "        metrics.total += 1\n",
    "        metrics.total_separation += separation\n",
    "        metrics.separations.append(separation)\n",
    "\n",
    "        correct_prediction = table_rankings[0][1] == correct_table\n",
    "        if correct_prediction:\n",
    "            metrics.correct += 1\n",
    "            if abs(separation) >= HIGH_CONFIDENCE:\n",
    "                metrics.high_confidence_correct += 1\n",
    "        elif abs(separation) < MEDIUM_CONFIDENCE:\n",
    "            metrics.low_confidence_mistakes += 1\n",
    "\n",
    "        # Print rankings with confidence indicators\n",
    "        for rank, (similarity, table_name) in enumerate(table_rankings, start=1):\n",
    "            is_correct = table_name == correct_table\n",
    "            confidence_color = get_confidence_color(separation)\n",
    "            text = f\"  Rank {rank}: {table_name} (Similarity: {similarity:.3f})\"\n",
    "            print(f\"{bcolors.OKGREEN if is_correct else bcolors.FAIL}{text}{' ✓' if is_correct else ' ✗'}{bcolors.ENDC}\")\n",
    "\n",
    "        # Print separation with confidence level\n",
    "        confidence_color = get_confidence_color(separation)\n",
    "        confidence_text = print_confidence_indicator(separation)\n",
    "        print(f\"{confidence_color}  Separation: {separation:+.3f} - {confidence_text}{bcolors.ENDC}\\n\")\n",
    "\n",
    "        # Store results in rankings_by_question\n",
    "        if question not in rankings_by_question:\n",
    "            rankings_by_question[question] = {}\n",
    "        rankings_by_question[question][method] = table_rankings\n",
    "\n",
    "    # Print strategy-level summary metrics\n",
    "    print(f\"{bcolors.HEADER}### Summary for {method} ###{bcolors.ENDC}\")\n",
    "    print(f\"{bcolors.OKBLUE}- Accuracy: {metrics.accuracy:.1f}%{bcolors.ENDC}\")\n",
    "    print(f\"{bcolors.OKBLUE}- Average Separation: {metrics.avg_separation:.3f}{bcolors.ENDC}\")\n",
    "    print(f\"{bcolors.OKBLUE}- High Confidence Accuracy: {metrics.high_confidence_accuracy:.1f}%{bcolors.ENDC}\")\n",
    "    print(f\"{bcolors.OKBLUE}- Low Confidence Mistakes: {metrics.low_confidence_mistakes}{bcolors.ENDC}\\n\")\n",
    "\n",
    "    return rankings_by_question\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# Ensure rankings_by_question is carried forward or passed appropriately\n",
    "rankings_by_question = run_strategy_2(\n",
    "    base_table_text_1, base_table_text_2, desc1, desc2, qas, rankings_by_question\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[95m### Strategy 3: Sample Questions Only ###\u001b[0m\n",
      "\u001b[94mCosine similarity between sample questions for Table 1 and Table 2: 0.7670000195503235\u001b[0m\n",
      "\n",
      "\u001b[94mProcessing Question: 'Which customers show early signs of upgrading their entire home furnishing style?'\u001b[0m\n",
      "\u001b[92mCorrect Table: customers.raw_customer_data\u001b[0m\n",
      "\n",
      "\u001b[94m  Cosine Similarity with customers.raw_customer_data (sample questions): 0.737\u001b[0m\n",
      "\u001b[94m  Cosine Similarity with analytics.product_sales_summary (sample questions): 0.640\u001b[0m\n",
      "\u001b[92m  Rank 1: customers.raw_customer_data (Similarity: 0.737) ✓\u001b[0m\n",
      "\u001b[91m  Rank 2: analytics.product_sales_summary (Similarity: 0.640) ✗\u001b[0m\n",
      "\u001b[93m  Separation: +0.097 - MEDIUM CONFIDENCE\u001b[0m\n",
      "\n",
      "\u001b[94mProcessing Question: 'How should we adjust our collection launch timing for different climate zones?'\u001b[0m\n",
      "\u001b[92mCorrect Table: analytics.product_sales_summary\u001b[0m\n",
      "\n",
      "\u001b[94m  Cosine Similarity with customers.raw_customer_data (sample questions): 0.486\u001b[0m\n",
      "\u001b[94m  Cosine Similarity with analytics.product_sales_summary (sample questions): 0.612\u001b[0m\n",
      "\u001b[92m  Rank 1: analytics.product_sales_summary (Similarity: 0.612) ✓\u001b[0m\n",
      "\u001b[91m  Rank 2: customers.raw_customer_data (Similarity: 0.486) ✗\u001b[0m\n",
      "\u001b[92m  Separation: +0.126 - HIGH CONFIDENCE\u001b[0m\n",
      "\n",
      "\u001b[94mProcessing Question: 'Which customers are most likely to become brand advocates for our artisan collection?'\u001b[0m\n",
      "\u001b[92mCorrect Table: customers.raw_customer_data\u001b[0m\n",
      "\n",
      "\u001b[94m  Cosine Similarity with customers.raw_customer_data (sample questions): 0.752\u001b[0m\n",
      "\u001b[94m  Cosine Similarity with analytics.product_sales_summary (sample questions): 0.644\u001b[0m\n",
      "\u001b[92m  Rank 1: customers.raw_customer_data (Similarity: 0.752) ✓\u001b[0m\n",
      "\u001b[91m  Rank 2: analytics.product_sales_summary (Similarity: 0.644) ✗\u001b[0m\n",
      "\u001b[92m  Separation: +0.108 - HIGH CONFIDENCE\u001b[0m\n",
      "\n",
      "\u001b[94mProcessing Question: 'What product mix will maximize market share in emerging urban markets?'\u001b[0m\n",
      "\u001b[92mCorrect Table: analytics.product_sales_summary\u001b[0m\n",
      "\n",
      "\u001b[94m  Cosine Similarity with customers.raw_customer_data (sample questions): 0.533\u001b[0m\n",
      "\u001b[94m  Cosine Similarity with analytics.product_sales_summary (sample questions): 0.611\u001b[0m\n",
      "\u001b[92m  Rank 1: analytics.product_sales_summary (Similarity: 0.611) ✓\u001b[0m\n",
      "\u001b[91m  Rank 2: customers.raw_customer_data (Similarity: 0.533) ✗\u001b[0m\n",
      "\u001b[93m  Separation: +0.078 - MEDIUM CONFIDENCE\u001b[0m\n",
      "\n",
      "\u001b[94mProcessing Question: 'Which customers should receive priority access to our limited edition designer collaboration?'\u001b[0m\n",
      "\u001b[92mCorrect Table: customers.raw_customer_data\u001b[0m\n",
      "\n",
      "\u001b[94m  Cosine Similarity with customers.raw_customer_data (sample questions): 0.739\u001b[0m\n",
      "\u001b[94m  Cosine Similarity with analytics.product_sales_summary (sample questions): 0.629\u001b[0m\n",
      "\u001b[92m  Rank 1: customers.raw_customer_data (Similarity: 0.739) ✓\u001b[0m\n",
      "\u001b[91m  Rank 2: analytics.product_sales_summary (Similarity: 0.629) ✗\u001b[0m\n",
      "\u001b[92m  Separation: +0.110 - HIGH CONFIDENCE\u001b[0m\n",
      "\n",
      "\u001b[94mProcessing Question: 'How should we optimize our showroom layouts for the upcoming season across different regions?'\u001b[0m\n",
      "\u001b[92mCorrect Table: analytics.product_sales_summary\u001b[0m\n",
      "\n",
      "\u001b[94m  Cosine Similarity with customers.raw_customer_data (sample questions): 0.581\u001b[0m\n",
      "\u001b[94m  Cosine Similarity with analytics.product_sales_summary (sample questions): 0.629\u001b[0m\n",
      "\u001b[92m  Rank 1: analytics.product_sales_summary (Similarity: 0.629) ✓\u001b[0m\n",
      "\u001b[91m  Rank 2: customers.raw_customer_data (Similarity: 0.581) ✗\u001b[0m\n",
      "\u001b[91m  Separation: +0.048 - LOW CONFIDENCE\u001b[0m\n",
      "\n",
      "\u001b[95m### Summary for sample-questions-only ###\u001b[0m\n",
      "\u001b[94m- Accuracy: 100.0%\u001b[0m\n",
      "\u001b[94m- Average Separation: 0.095\u001b[0m\n",
      "\u001b[94m- High Confidence Accuracy: 100.0%\u001b[0m\n",
      "\u001b[94m- Low Confidence Mistakes: 0\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def run_strategy_3(sq1, sq2, qas, rankings_by_question):\n",
    "    method = \"sample-questions-only\"\n",
    "    metrics = RAGMetrics()  # Initialize metrics for this strategy\n",
    "\n",
    "    # Handle the case where rankings_by_question is None\n",
    "    if rankings_by_question is None:\n",
    "        rankings_by_question = {}\n",
    "\n",
    "    sample_questions = [\n",
    "        (\"customers.raw_customer_data\", sq1),\n",
    "        (\"analytics.product_sales_summary\", sq2),\n",
    "    ]\n",
    "\n",
    "    # Generate embeddings for sample questions\n",
    "    emb_sq1 = get_embedding(sq1)\n",
    "    emb_sq2 = get_embedding(sq2)\n",
    "\n",
    "    print(f\"\\n{bcolors.HEADER}### Strategy 3: Sample Questions Only ###{bcolors.ENDC}\")\n",
    "    print(f\"{bcolors.OKBLUE}Cosine similarity between sample questions for Table 1 and Table 2: \"\n",
    "          f\"{round(cosine_sim(emb_sq1, emb_sq2), 3)}{bcolors.ENDC}\\n\")\n",
    "\n",
    "    HIGH_CONFIDENCE = 0.1\n",
    "    MEDIUM_CONFIDENCE = 0.05\n",
    "\n",
    "    for (correct_table, question) in qas:\n",
    "        print(f\"{bcolors.OKBLUE}Processing Question: '{question}'{bcolors.ENDC}\")\n",
    "        print(f\"{bcolors.OKGREEN}Correct Table: {correct_table}{bcolors.ENDC}\\n\")\n",
    "\n",
    "        question_emb = get_embedding(question)\n",
    "        table_rankings = []\n",
    "\n",
    "        for (table_name, sample_qs) in sample_questions:\n",
    "            sample_qs_emb = get_embedding(sample_qs)\n",
    "            similarity = round(cosine_sim(question_emb, sample_qs_emb), 3)\n",
    "            table_rankings.append((similarity, table_name))\n",
    "            print(f\"{bcolors.OKBLUE}  Cosine Similarity with {table_name} (sample questions): {similarity:.3f}{bcolors.ENDC}\")\n",
    "\n",
    "        table_rankings = sorted(table_rankings, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        # Calculate separation and update metrics\n",
    "        separation = table_rankings[0][0] - table_rankings[1][0] if len(table_rankings) > 1 else 0\n",
    "        metrics.total += 1\n",
    "        metrics.total_separation += separation\n",
    "        metrics.separations.append(separation)\n",
    "\n",
    "        correct_prediction = table_rankings[0][1] == correct_table\n",
    "        if correct_prediction:\n",
    "            metrics.correct += 1\n",
    "            if abs(separation) >= HIGH_CONFIDENCE:\n",
    "                metrics.high_confidence_correct += 1\n",
    "        elif abs(separation) < MEDIUM_CONFIDENCE:\n",
    "            metrics.low_confidence_mistakes += 1\n",
    "\n",
    "        # Print rankings with confidence indicators\n",
    "        for rank, (similarity, table_name) in enumerate(table_rankings, start=1):\n",
    "            is_correct = table_name == correct_table\n",
    "            confidence_color = get_confidence_color(separation)\n",
    "            text = f\"  Rank {rank}: {table_name} (Similarity: {similarity:.3f})\"\n",
    "            print(f\"{bcolors.OKGREEN if is_correct else bcolors.FAIL}{text}{' ✓' if is_correct else ' ✗'}{bcolors.ENDC}\")\n",
    "\n",
    "        # Print separation with confidence level\n",
    "        confidence_color = get_confidence_color(separation)\n",
    "        confidence_text = print_confidence_indicator(separation)\n",
    "        print(f\"{confidence_color}  Separation: {separation:+.3f} - {confidence_text}{bcolors.ENDC}\\n\")\n",
    "\n",
    "        # Store results in rankings_by_question\n",
    "        if question not in rankings_by_question:\n",
    "            rankings_by_question[question] = {}\n",
    "        rankings_by_question[question][method] = table_rankings\n",
    "\n",
    "    # Print strategy-level summary metrics\n",
    "    print(f\"{bcolors.HEADER}### Summary for {method} ###{bcolors.ENDC}\")\n",
    "    print(f\"{bcolors.OKBLUE}- Accuracy: {metrics.accuracy:.1f}%{bcolors.ENDC}\")\n",
    "    print(f\"{bcolors.OKBLUE}- Average Separation: {metrics.avg_separation:.3f}{bcolors.ENDC}\")\n",
    "    print(f\"{bcolors.OKBLUE}- High Confidence Accuracy: {metrics.high_confidence_accuracy:.1f}%{bcolors.ENDC}\")\n",
    "    print(f\"{bcolors.OKBLUE}- Low Confidence Mistakes: {metrics.low_confidence_mistakes}{bcolors.ENDC}\\n\")\n",
    "\n",
    "    return rankings_by_question\n",
    "\n",
    "# Example usage:\n",
    "rankings_by_question = run_strategy_3(sq1, sq2, qas, rankings_by_question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[95m### Strategy 4: Table Schema, Short Description, and Sample Questions ###\u001b[0m\n",
      "\u001b[94mCosine similarity between enriched Table 1 and Table 2: 0.7990000247955322\u001b[0m\n",
      "\n",
      "\u001b[94mProcessing Question: 'Which customers show early signs of upgrading their entire home furnishing style?'\u001b[0m\n",
      "\u001b[92mCorrect Table: customers.raw_customer_data\u001b[0m\n",
      "\n",
      "\u001b[94m  Cosine Similarity with customers.raw_customer_data (enriched schema): 0.636\u001b[0m\n",
      "\u001b[94m  Cosine Similarity with analytics.product_sales_summary (enriched schema): 0.567\u001b[0m\n",
      "\u001b[92m  Rank 1: customers.raw_customer_data (Similarity: 0.636) ✓\u001b[0m\n",
      "\u001b[91m  Rank 2: analytics.product_sales_summary (Similarity: 0.567) ✗\u001b[0m\n",
      "\u001b[93m  Separation: +0.069 - MEDIUM CONFIDENCE\u001b[0m\n",
      "\n",
      "\u001b[94mProcessing Question: 'How should we adjust our collection launch timing for different climate zones?'\u001b[0m\n",
      "\u001b[92mCorrect Table: analytics.product_sales_summary\u001b[0m\n",
      "\n",
      "\u001b[94m  Cosine Similarity with customers.raw_customer_data (enriched schema): 0.449\u001b[0m\n",
      "\u001b[94m  Cosine Similarity with analytics.product_sales_summary (enriched schema): 0.523\u001b[0m\n",
      "\u001b[92m  Rank 1: analytics.product_sales_summary (Similarity: 0.523) ✓\u001b[0m\n",
      "\u001b[91m  Rank 2: customers.raw_customer_data (Similarity: 0.449) ✗\u001b[0m\n",
      "\u001b[93m  Separation: +0.074 - MEDIUM CONFIDENCE\u001b[0m\n",
      "\n",
      "\u001b[94mProcessing Question: 'Which customers are most likely to become brand advocates for our artisan collection?'\u001b[0m\n",
      "\u001b[92mCorrect Table: customers.raw_customer_data\u001b[0m\n",
      "\n",
      "\u001b[94m  Cosine Similarity with customers.raw_customer_data (enriched schema): 0.633\u001b[0m\n",
      "\u001b[94m  Cosine Similarity with analytics.product_sales_summary (enriched schema): 0.546\u001b[0m\n",
      "\u001b[92m  Rank 1: customers.raw_customer_data (Similarity: 0.633) ✓\u001b[0m\n",
      "\u001b[91m  Rank 2: analytics.product_sales_summary (Similarity: 0.546) ✗\u001b[0m\n",
      "\u001b[93m  Separation: +0.087 - MEDIUM CONFIDENCE\u001b[0m\n",
      "\n",
      "\u001b[94mProcessing Question: 'What product mix will maximize market share in emerging urban markets?'\u001b[0m\n",
      "\u001b[92mCorrect Table: analytics.product_sales_summary\u001b[0m\n",
      "\n",
      "\u001b[94m  Cosine Similarity with customers.raw_customer_data (enriched schema): 0.433\u001b[0m\n",
      "\u001b[94m  Cosine Similarity with analytics.product_sales_summary (enriched schema): 0.497\u001b[0m\n",
      "\u001b[92m  Rank 1: analytics.product_sales_summary (Similarity: 0.497) ✓\u001b[0m\n",
      "\u001b[91m  Rank 2: customers.raw_customer_data (Similarity: 0.433) ✗\u001b[0m\n",
      "\u001b[93m  Separation: +0.064 - MEDIUM CONFIDENCE\u001b[0m\n",
      "\n",
      "\u001b[94mProcessing Question: 'Which customers should receive priority access to our limited edition designer collaboration?'\u001b[0m\n",
      "\u001b[92mCorrect Table: customers.raw_customer_data\u001b[0m\n",
      "\n",
      "\u001b[94m  Cosine Similarity with customers.raw_customer_data (enriched schema): 0.603\u001b[0m\n",
      "\u001b[94m  Cosine Similarity with analytics.product_sales_summary (enriched schema): 0.537\u001b[0m\n",
      "\u001b[92m  Rank 1: customers.raw_customer_data (Similarity: 0.603) ✓\u001b[0m\n",
      "\u001b[91m  Rank 2: analytics.product_sales_summary (Similarity: 0.537) ✗\u001b[0m\n",
      "\u001b[93m  Separation: +0.066 - MEDIUM CONFIDENCE\u001b[0m\n",
      "\n",
      "\u001b[94mProcessing Question: 'How should we optimize our showroom layouts for the upcoming season across different regions?'\u001b[0m\n",
      "\u001b[92mCorrect Table: analytics.product_sales_summary\u001b[0m\n",
      "\n",
      "\u001b[94m  Cosine Similarity with customers.raw_customer_data (enriched schema): 0.541\u001b[0m\n",
      "\u001b[94m  Cosine Similarity with analytics.product_sales_summary (enriched schema): 0.615\u001b[0m\n",
      "\u001b[92m  Rank 1: analytics.product_sales_summary (Similarity: 0.615) ✓\u001b[0m\n",
      "\u001b[91m  Rank 2: customers.raw_customer_data (Similarity: 0.541) ✗\u001b[0m\n",
      "\u001b[93m  Separation: +0.074 - MEDIUM CONFIDENCE\u001b[0m\n",
      "\n",
      "\u001b[95m### Summary for table-schema-desc-questions ###\u001b[0m\n",
      "\u001b[94m- Accuracy: 100.0%\u001b[0m\n",
      "\u001b[94m- Average Separation: 0.072\u001b[0m\n",
      "\u001b[94m- High Confidence Accuracy: 0.0%\u001b[0m\n",
      "\u001b[94m- Low Confidence Mistakes: 0\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Strategy 4: Table Schema, Short Description, and Sample Questions\n",
    "def run_strategy_4(base_table_text_1, base_table_text_2, desc1, desc2, sq1, sq2, qas, rankings_by_question):\n",
    "    method = \"table-schema-desc-questions\"\n",
    "    metrics = RAGMetrics()  # Initialize metrics for this strategy\n",
    "\n",
    "    # Handle the case where rankings_by_question is None\n",
    "    if rankings_by_question is None:\n",
    "        rankings_by_question = {}\n",
    "\n",
    "    table1 = f\"\"\"\n",
    "    Description: {desc1}\n",
    "\n",
    "    Sample Questions:\n",
    "    {sq1}\n",
    "\n",
    "    {base_table_text_1}\n",
    "    \"\"\"\n",
    "\n",
    "    table2 = f\"\"\"\n",
    "    Description: {desc2}\n",
    "\n",
    "    Sample Questions:\n",
    "    {sq2}\n",
    "\n",
    "    {base_table_text_2}\n",
    "    \"\"\"\n",
    "\n",
    "    tables = [\n",
    "        (\"customers.raw_customer_data\", table1),\n",
    "        (\"analytics.product_sales_summary\", table2),\n",
    "    ]\n",
    "\n",
    "    # Generate embeddings for enriched table schemas\n",
    "    emb_table1 = get_embedding(table1)\n",
    "    emb_table2 = get_embedding(table2)\n",
    "\n",
    "    print(f\"\\n{bcolors.HEADER}### Strategy 4: Table Schema, Short Description, and Sample Questions ###{bcolors.ENDC}\")\n",
    "    print(f\"{bcolors.OKBLUE}Cosine similarity between enriched Table 1 and Table 2: \"\n",
    "          f\"{round(cosine_sim(emb_table1, emb_table2), 3)}{bcolors.ENDC}\\n\")\n",
    "\n",
    "    HIGH_CONFIDENCE = 0.1\n",
    "    MEDIUM_CONFIDENCE = 0.05\n",
    "\n",
    "    for (correct_table, question) in qas:\n",
    "        print(f\"{bcolors.OKBLUE}Processing Question: '{question}'{bcolors.ENDC}\")\n",
    "        print(f\"{bcolors.OKGREEN}Correct Table: {correct_table}{bcolors.ENDC}\\n\")\n",
    "\n",
    "        question_emb = get_embedding(question)\n",
    "        table_rankings = []\n",
    "\n",
    "        for (table_name, enriched_table) in tables:\n",
    "            enriched_table_emb = get_embedding(enriched_table)\n",
    "            similarity = round(cosine_sim(question_emb, enriched_table_emb), 3)\n",
    "            table_rankings.append((similarity, table_name))\n",
    "            print(f\"{bcolors.OKBLUE}  Cosine Similarity with {table_name} (enriched schema): {similarity:.3f}{bcolors.ENDC}\")\n",
    "\n",
    "        table_rankings = sorted(table_rankings, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        # Calculate separation and update metrics\n",
    "        separation = table_rankings[0][0] - table_rankings[1][0] if len(table_rankings) > 1 else 0\n",
    "        metrics.total += 1\n",
    "        metrics.total_separation += separation\n",
    "        metrics.separations.append(separation)\n",
    "\n",
    "        correct_prediction = table_rankings[0][1] == correct_table\n",
    "        if correct_prediction:\n",
    "            metrics.correct += 1\n",
    "            if abs(separation) >= HIGH_CONFIDENCE:\n",
    "                metrics.high_confidence_correct += 1\n",
    "        elif abs(separation) < MEDIUM_CONFIDENCE:\n",
    "            metrics.low_confidence_mistakes += 1\n",
    "\n",
    "        # Print rankings with confidence indicators\n",
    "        for rank, (similarity, table_name) in enumerate(table_rankings, start=1):\n",
    "            is_correct = table_name == correct_table\n",
    "            confidence_color = get_confidence_color(separation)\n",
    "            text = f\"  Rank {rank}: {table_name} (Similarity: {similarity:.3f})\"\n",
    "            print(f\"{bcolors.OKGREEN if is_correct else bcolors.FAIL}{text}{' ✓' if is_correct else ' ✗'}{bcolors.ENDC}\")\n",
    "\n",
    "        # Print separation with confidence level\n",
    "        confidence_color = get_confidence_color(separation)\n",
    "        confidence_text = print_confidence_indicator(separation)\n",
    "        print(f\"{confidence_color}  Separation: {separation:+.3f} - {confidence_text}{bcolors.ENDC}\\n\")\n",
    "\n",
    "        # Store results in rankings_by_question\n",
    "        if question not in rankings_by_question:\n",
    "            rankings_by_question[question] = {}\n",
    "        rankings_by_question[question][method] = table_rankings\n",
    "\n",
    "    # Print strategy-level summary metrics\n",
    "    print(f\"{bcolors.HEADER}### Summary for {method} ###{bcolors.ENDC}\")\n",
    "    print(f\"{bcolors.OKBLUE}- Accuracy: {metrics.accuracy:.1f}%{bcolors.ENDC}\")\n",
    "    print(f\"{bcolors.OKBLUE}- Average Separation: {metrics.avg_separation:.3f}{bcolors.ENDC}\")\n",
    "    print(f\"{bcolors.OKBLUE}- High Confidence Accuracy: {metrics.high_confidence_accuracy:.1f}%{bcolors.ENDC}\")\n",
    "    print(f\"{bcolors.OKBLUE}- Low Confidence Mistakes: {metrics.low_confidence_mistakes}{bcolors.ENDC}\\n\")\n",
    "\n",
    "    return rankings_by_question\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# Initialize the required inputs\n",
    "rankings_by_question = run_strategy_4(\n",
    "    base_table_text_1, base_table_text_2, desc1, desc2, sq1, sq2, qas, rankings_by_question\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m\n",
      "=== Detailed Strategy Analysis ===\n",
      "\u001b[0m\n",
      "\n",
      "====================================================================================================\n",
      "\u001b[95m\u001b[1mQuestion Analysis\u001b[0m\n",
      "\u001b[94mQuery: Which customers show early signs of upgrading their entire home furnishing style?\u001b[0m\n",
      "\u001b[92mExpected Table: customers.raw_customer_data\u001b[0m\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[95mStrategy: table-schema-no-enrichment\u001b[0m\n",
      "\u001b[92m  Rank 1: customers.raw_customer_data (Similarity: 0.466) ✓\u001b[0m\n",
      "\u001b[91m  Rank 2: analytics.product_sales_summary (Similarity: 0.456) ✗\u001b[0m\n",
      "\u001b[91m  Separation: +0.010 - LOW CONFIDENCE\u001b[0m\n",
      "\n",
      "\u001b[95mStrategy: table-schema-desc\u001b[0m\n",
      "\u001b[92m  Rank 1: customers.raw_customer_data (Similarity: 0.560) ✓\u001b[0m\n",
      "\u001b[91m  Rank 2: analytics.product_sales_summary (Similarity: 0.510) ✗\u001b[0m\n",
      "\u001b[93m  Separation: +0.050 - MEDIUM CONFIDENCE\u001b[0m\n",
      "\n",
      "\u001b[95mStrategy: table-schema-desc-questions\u001b[0m\n",
      "\u001b[92m  Rank 1: customers.raw_customer_data (Similarity: 0.636) ✓\u001b[0m\n",
      "\u001b[91m  Rank 2: analytics.product_sales_summary (Similarity: 0.567) ✗\u001b[0m\n",
      "\u001b[93m  Separation: +0.069 - MEDIUM CONFIDENCE\u001b[0m\n",
      "\n",
      "\u001b[95mStrategy: sample-questions-only\u001b[0m\n",
      "\u001b[92m  Rank 1: customers.raw_customer_data (Similarity: 0.737) ✓\u001b[0m\n",
      "\u001b[91m  Rank 2: analytics.product_sales_summary (Similarity: 0.640) ✗\u001b[0m\n",
      "\u001b[93m  Separation: +0.097 - MEDIUM CONFIDENCE\u001b[0m\n",
      "\n",
      "\u001b[95mQuestion Summary\u001b[0m\n",
      "\u001b[91mNo method predicted correctly with confidence\u001b[0m\n",
      "\n",
      "====================================================================================================\n",
      "\u001b[95m\u001b[1mQuestion Analysis\u001b[0m\n",
      "\u001b[94mQuery: How should we adjust our collection launch timing for different climate zones?\u001b[0m\n",
      "\u001b[92mExpected Table: analytics.product_sales_summary\u001b[0m\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[95mStrategy: table-schema-no-enrichment\u001b[0m\n",
      "\u001b[91m  Rank 1: customers.raw_customer_data (Similarity: 0.420) ✗\u001b[0m\n",
      "\u001b[92m  Rank 2: analytics.product_sales_summary (Similarity: 0.406) ✓\u001b[0m\n",
      "\u001b[91m  Separation: +0.014 - LOW CONFIDENCE\u001b[0m\n",
      "\n",
      "\u001b[95mStrategy: table-schema-desc\u001b[0m\n",
      "\u001b[92m  Rank 1: analytics.product_sales_summary (Similarity: 0.483) ✓\u001b[0m\n",
      "\u001b[91m  Rank 2: customers.raw_customer_data (Similarity: 0.439) ✗\u001b[0m\n",
      "\u001b[91m  Separation: +0.044 - LOW CONFIDENCE\u001b[0m\n",
      "\n",
      "\u001b[95mStrategy: table-schema-desc-questions\u001b[0m\n",
      "\u001b[92m  Rank 1: analytics.product_sales_summary (Similarity: 0.523) ✓\u001b[0m\n",
      "\u001b[91m  Rank 2: customers.raw_customer_data (Similarity: 0.449) ✗\u001b[0m\n",
      "\u001b[93m  Separation: +0.074 - MEDIUM CONFIDENCE\u001b[0m\n",
      "\n",
      "\u001b[95mStrategy: sample-questions-only\u001b[0m\n",
      "\u001b[92m  Rank 1: analytics.product_sales_summary (Similarity: 0.612) ✓\u001b[0m\n",
      "\u001b[91m  Rank 2: customers.raw_customer_data (Similarity: 0.486) ✗\u001b[0m\n",
      "\u001b[92m  Separation: +0.126 - HIGH CONFIDENCE\u001b[0m\n",
      "\n",
      "\u001b[95mQuestion Summary\u001b[0m\n",
      "\u001b[91mNo method predicted correctly with confidence\u001b[0m\n",
      "\n",
      "====================================================================================================\n",
      "\u001b[95m\u001b[1mQuestion Analysis\u001b[0m\n",
      "\u001b[94mQuery: Which customers are most likely to become brand advocates for our artisan collection?\u001b[0m\n",
      "\u001b[92mExpected Table: customers.raw_customer_data\u001b[0m\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[95mStrategy: table-schema-no-enrichment\u001b[0m\n",
      "\u001b[92m  Rank 1: customers.raw_customer_data (Similarity: 0.470) ✓\u001b[0m\n",
      "\u001b[91m  Rank 2: analytics.product_sales_summary (Similarity: 0.447) ✗\u001b[0m\n",
      "\u001b[91m  Separation: +0.023 - LOW CONFIDENCE\u001b[0m\n",
      "\n",
      "\u001b[95mStrategy: table-schema-desc\u001b[0m\n",
      "\u001b[92m  Rank 1: customers.raw_customer_data (Similarity: 0.594) ✓\u001b[0m\n",
      "\u001b[91m  Rank 2: analytics.product_sales_summary (Similarity: 0.522) ✗\u001b[0m\n",
      "\u001b[93m  Separation: +0.072 - MEDIUM CONFIDENCE\u001b[0m\n",
      "\n",
      "\u001b[95mStrategy: table-schema-desc-questions\u001b[0m\n",
      "\u001b[92m  Rank 1: customers.raw_customer_data (Similarity: 0.633) ✓\u001b[0m\n",
      "\u001b[91m  Rank 2: analytics.product_sales_summary (Similarity: 0.546) ✗\u001b[0m\n",
      "\u001b[93m  Separation: +0.087 - MEDIUM CONFIDENCE\u001b[0m\n",
      "\n",
      "\u001b[95mStrategy: sample-questions-only\u001b[0m\n",
      "\u001b[92m  Rank 1: customers.raw_customer_data (Similarity: 0.752) ✓\u001b[0m\n",
      "\u001b[91m  Rank 2: analytics.product_sales_summary (Similarity: 0.644) ✗\u001b[0m\n",
      "\u001b[92m  Separation: +0.108 - HIGH CONFIDENCE\u001b[0m\n",
      "\n",
      "\u001b[95mQuestion Summary\u001b[0m\n",
      "\u001b[91mNo method predicted correctly with confidence\u001b[0m\n",
      "\n",
      "====================================================================================================\n",
      "\u001b[95m\u001b[1mQuestion Analysis\u001b[0m\n",
      "\u001b[94mQuery: What product mix will maximize market share in emerging urban markets?\u001b[0m\n",
      "\u001b[92mExpected Table: analytics.product_sales_summary\u001b[0m\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[95mStrategy: table-schema-no-enrichment\u001b[0m\n",
      "\u001b[92m  Rank 1: analytics.product_sales_summary (Similarity: 0.416) ✓\u001b[0m\n",
      "\u001b[91m  Rank 2: customers.raw_customer_data (Similarity: 0.358) ✗\u001b[0m\n",
      "\u001b[93m  Separation: +0.058 - MEDIUM CONFIDENCE\u001b[0m\n",
      "\n",
      "\u001b[95mStrategy: table-schema-desc\u001b[0m\n",
      "\u001b[92m  Rank 1: analytics.product_sales_summary (Similarity: 0.488) ✓\u001b[0m\n",
      "\u001b[91m  Rank 2: customers.raw_customer_data (Similarity: 0.440) ✗\u001b[0m\n",
      "\u001b[91m  Separation: +0.048 - LOW CONFIDENCE\u001b[0m\n",
      "\n",
      "\u001b[95mStrategy: table-schema-desc-questions\u001b[0m\n",
      "\u001b[92m  Rank 1: analytics.product_sales_summary (Similarity: 0.497) ✓\u001b[0m\n",
      "\u001b[91m  Rank 2: customers.raw_customer_data (Similarity: 0.433) ✗\u001b[0m\n",
      "\u001b[93m  Separation: +0.064 - MEDIUM CONFIDENCE\u001b[0m\n",
      "\n",
      "\u001b[95mStrategy: sample-questions-only\u001b[0m\n",
      "\u001b[92m  Rank 1: analytics.product_sales_summary (Similarity: 0.611) ✓\u001b[0m\n",
      "\u001b[91m  Rank 2: customers.raw_customer_data (Similarity: 0.533) ✗\u001b[0m\n",
      "\u001b[93m  Separation: +0.078 - MEDIUM CONFIDENCE\u001b[0m\n",
      "\n",
      "\u001b[95mQuestion Summary\u001b[0m\n",
      "\u001b[91mNo method predicted correctly with confidence\u001b[0m\n",
      "\n",
      "====================================================================================================\n",
      "\u001b[95m\u001b[1mQuestion Analysis\u001b[0m\n",
      "\u001b[94mQuery: Which customers should receive priority access to our limited edition designer collaboration?\u001b[0m\n",
      "\u001b[92mExpected Table: customers.raw_customer_data\u001b[0m\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[95mStrategy: table-schema-no-enrichment\u001b[0m\n",
      "\u001b[92m  Rank 1: customers.raw_customer_data (Similarity: 0.415) ✓\u001b[0m\n",
      "\u001b[91m  Rank 2: analytics.product_sales_summary (Similarity: 0.392) ✗\u001b[0m\n",
      "\u001b[91m  Separation: +0.023 - LOW CONFIDENCE\u001b[0m\n",
      "\n",
      "\u001b[95mStrategy: table-schema-desc\u001b[0m\n",
      "\u001b[92m  Rank 1: customers.raw_customer_data (Similarity: 0.512) ✓\u001b[0m\n",
      "\u001b[91m  Rank 2: analytics.product_sales_summary (Similarity: 0.481) ✗\u001b[0m\n",
      "\u001b[91m  Separation: +0.031 - LOW CONFIDENCE\u001b[0m\n",
      "\n",
      "\u001b[95mStrategy: table-schema-desc-questions\u001b[0m\n",
      "\u001b[92m  Rank 1: customers.raw_customer_data (Similarity: 0.603) ✓\u001b[0m\n",
      "\u001b[91m  Rank 2: analytics.product_sales_summary (Similarity: 0.537) ✗\u001b[0m\n",
      "\u001b[93m  Separation: +0.066 - MEDIUM CONFIDENCE\u001b[0m\n",
      "\n",
      "\u001b[95mStrategy: sample-questions-only\u001b[0m\n",
      "\u001b[92m  Rank 1: customers.raw_customer_data (Similarity: 0.739) ✓\u001b[0m\n",
      "\u001b[91m  Rank 2: analytics.product_sales_summary (Similarity: 0.629) ✗\u001b[0m\n",
      "\u001b[92m  Separation: +0.110 - HIGH CONFIDENCE\u001b[0m\n",
      "\n",
      "\u001b[95mQuestion Summary\u001b[0m\n",
      "\u001b[91mNo method predicted correctly with confidence\u001b[0m\n",
      "\n",
      "====================================================================================================\n",
      "\u001b[95m\u001b[1mQuestion Analysis\u001b[0m\n",
      "\u001b[94mQuery: How should we optimize our showroom layouts for the upcoming season across different regions?\u001b[0m\n",
      "\u001b[92mExpected Table: analytics.product_sales_summary\u001b[0m\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[95mStrategy: table-schema-no-enrichment\u001b[0m\n",
      "\u001b[92m  Rank 1: analytics.product_sales_summary (Similarity: 0.418) ✓\u001b[0m\n",
      "\u001b[91m  Rank 2: customers.raw_customer_data (Similarity: 0.382) ✗\u001b[0m\n",
      "\u001b[91m  Separation: +0.036 - LOW CONFIDENCE\u001b[0m\n",
      "\n",
      "\u001b[95mStrategy: table-schema-desc\u001b[0m\n",
      "\u001b[92m  Rank 1: analytics.product_sales_summary (Similarity: 0.598) ✓\u001b[0m\n",
      "\u001b[91m  Rank 2: customers.raw_customer_data (Similarity: 0.488) ✗\u001b[0m\n",
      "\u001b[92m  Separation: +0.110 - HIGH CONFIDENCE\u001b[0m\n",
      "\n",
      "\u001b[95mStrategy: table-schema-desc-questions\u001b[0m\n",
      "\u001b[92m  Rank 1: analytics.product_sales_summary (Similarity: 0.615) ✓\u001b[0m\n",
      "\u001b[91m  Rank 2: customers.raw_customer_data (Similarity: 0.541) ✗\u001b[0m\n",
      "\u001b[93m  Separation: +0.074 - MEDIUM CONFIDENCE\u001b[0m\n",
      "\n",
      "\u001b[95mStrategy: sample-questions-only\u001b[0m\n",
      "\u001b[92m  Rank 1: analytics.product_sales_summary (Similarity: 0.629) ✓\u001b[0m\n",
      "\u001b[91m  Rank 2: customers.raw_customer_data (Similarity: 0.581) ✗\u001b[0m\n",
      "\u001b[91m  Separation: +0.048 - LOW CONFIDENCE\u001b[0m\n",
      "\n",
      "\u001b[95mQuestion Summary\u001b[0m\n",
      "\u001b[91mNo method predicted correctly with confidence\u001b[0m\n",
      "\u001b[95m\n",
      "=== Strategy Performance Analysis ===\u001b[0m\n",
      "\n",
      "Method                                  Accuracy  Avg Sep  High Conf  Low Conf Mistakes\n",
      "------------------------------------------------------------------------------------------\n",
      "\u001b[91mtable-schema-no-enrichment                   83.3%    0.027       0.0%                1\u001b[0m\n",
      "\u001b[93mtable-schema-desc                           100.0%    0.059     100.0%                0\u001b[0m\n",
      "\u001b[93mtable-schema-desc-questions                 100.0%    0.072       0.0%                0\u001b[0m\n",
      "\u001b[93msample-questions-only                       100.0%    0.095     100.0%                0\u001b[0m\n",
      "\n",
      "\u001b[1mBest Overall Method: \u001b[92msample-questions-only\u001b[0m\n",
      "\u001b[1mPerformance Metrics:\u001b[0m\n",
      "- Accuracy: 100.0%\n",
      "- High Confidence Accuracy: 100.0%\n",
      "- Average Separation: 0.095\n",
      "- Low Confidence Mistakes: 0\n"
     ]
    }
   ],
   "source": [
    "def print_results_comparison(rankings_by_question, qas):\n",
    "    method_order = [\n",
    "        \"table-schema-no-enrichment\",\n",
    "        \"table-schema-desc\",\n",
    "        \"table-schema-desc-questions\",\n",
    "        \"sample-questions-only\",\n",
    "    ]\n",
    "\n",
    "    HIGH_CONFIDENCE = 0.1\n",
    "    MEDIUM_CONFIDENCE = 0.05\n",
    "\n",
    "    metrics = {method: RAGMetrics() for method in method_order}\n",
    "\n",
    "    def print_comparison(question, correct_table, comps):\n",
    "        print(f\"\\n{'=' * 100}\")\n",
    "        print(f\"{bcolors.HEADER}{bcolors.BOLD}Question Analysis{bcolors.ENDC}\")\n",
    "        print(f\"{bcolors.OKBLUE}Query: {question}{bcolors.ENDC}\")\n",
    "        print(f\"{bcolors.OKGREEN}Expected Table: {correct_table}{bcolors.ENDC}\")\n",
    "        print(f\"{'-' * 100}\\n\")\n",
    "\n",
    "        best_confidence = -float('inf')\n",
    "        best_method = None\n",
    "\n",
    "        for method in method_order:\n",
    "            if method not in comps:\n",
    "                continue\n",
    "\n",
    "            print(f\"{bcolors.HEADER}Strategy: {method}{bcolors.ENDC}\")\n",
    "            ranking = comps[method]\n",
    "\n",
    "            # Update metrics\n",
    "            metrics[method].total += 1\n",
    "            separation = ranking[0][0] - ranking[1][0] if len(ranking) > 1 else 0\n",
    "            metrics[method].separations.append(separation)\n",
    "            metrics[method].total_separation += separation\n",
    "\n",
    "            correct_prediction = ranking[0][1] == correct_table\n",
    "            if correct_prediction:\n",
    "                metrics[method].correct += 1\n",
    "                if abs(separation) >= HIGH_CONFIDENCE:\n",
    "                    metrics[method].high_confidence_correct += 1\n",
    "            elif abs(separation) < MEDIUM_CONFIDENCE:\n",
    "                metrics[method].low_confidence_mistakes += 1\n",
    "\n",
    "            # Print rankings with confidence indicators\n",
    "            for rank, (similarity, table_name) in enumerate(ranking, start=1):\n",
    "                is_correct = table_name == correct_table\n",
    "                confidence_color = get_confidence_color(separation)\n",
    "                text = f\"  Rank {rank}: {table_name} (Similarity: {similarity:.3f})\"\n",
    "                print(f\"{bcolors.OKGREEN if is_correct else bcolors.FAIL}{text}{' ✓' if is_correct else ' ✗'}{bcolors.ENDC}\")\n",
    "\n",
    "            # Print separation with confidence level\n",
    "            confidence_color = get_confidence_color(separation)\n",
    "            confidence_text = print_confidence_indicator(separation)\n",
    "            print(f\"{confidence_color}  Separation: {separation:+.3f} - {confidence_text}{bcolors.ENDC}\\n\")\n",
    "\n",
    "            if abs(separation) > abs(best_confidence) and correct_prediction:\n",
    "                best_confidence = separation\n",
    "                best_method = method\n",
    "\n",
    "        print(f\"{bcolors.HEADER}Question Summary{bcolors.ENDC}\")\n",
    "        if best_method:\n",
    "            print(f\"{bcolors.OKGREEN}Best performing method: {best_method} (separation: {best_confidence:.3f}){bcolors.ENDC}\")\n",
    "        else:\n",
    "            print(f\"{bcolors.FAIL}No method predicted correctly with confidence{bcolors.ENDC}\")\n",
    "\n",
    "    # Generate comparison for all questions\n",
    "    print(f\"{bcolors.HEADER}\\n=== Detailed Strategy Analysis ===\\n{bcolors.ENDC}\")\n",
    "    for correct_table, question in qas:\n",
    "        comps = {method: rankings_by_question[question][method]\n",
    "                 for method in method_order\n",
    "                 if method in rankings_by_question.get(question, {})}\n",
    "        print_comparison(question, correct_table, comps)\n",
    "\n",
    "    # Print enhanced summary statistics\n",
    "    print(f\"{bcolors.HEADER}\\n=== Strategy Performance Analysis ==={bcolors.ENDC}\")\n",
    "    print(\"\\nMethod                                  Accuracy  Avg Sep  High Conf  Low Conf Mistakes\")\n",
    "    print(\"-\" * 90)\n",
    "\n",
    "    for method in method_order:\n",
    "        m = metrics[method]\n",
    "        color = (bcolors.OKGREEN if m.accuracy >= 75 and m.avg_separation >= HIGH_CONFIDENCE\n",
    "                 else bcolors.WARNING if m.accuracy >= 50 and m.avg_separation >= MEDIUM_CONFIDENCE\n",
    "                 else bcolors.FAIL)\n",
    "\n",
    "        print(f\"{color}{method:40s} {m.accuracy:8.1f}% {m.avg_separation:8.3f} {m.high_confidence_accuracy:9.1f}% {m.low_confidence_mistakes:>16d}{bcolors.ENDC}\")\n",
    "\n",
    "    # Find best performing method considering both accuracy and confidence\n",
    "    best_method = max(method_order,\n",
    "                      key=lambda m: (metrics[m].accuracy * 0.4 +\n",
    "                                     metrics[m].high_confidence_accuracy * 0.4 +\n",
    "                                     metrics[m].avg_separation * 100 * 0.2))\n",
    "\n",
    "    print(f\"\\n{bcolors.BOLD}Best Overall Method: {bcolors.OKGREEN}{best_method}{bcolors.ENDC}\")\n",
    "    print(f\"{bcolors.BOLD}Performance Metrics:{bcolors.ENDC}\")\n",
    "    print(f\"- Accuracy: {metrics[best_method].accuracy:.1f}%\")\n",
    "    print(f\"- High Confidence Accuracy: {metrics[best_method].high_confidence_accuracy:.1f}%\")\n",
    "    print(f\"- Average Separation: {metrics[best_method].avg_separation:.3f}\")\n",
    "    print(f\"- Low Confidence Mistakes: {metrics[best_method].low_confidence_mistakes}\")\n",
    "\n",
    "\n",
    "        \n",
    "print_results_comparison(rankings_by_question, qas)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reflection Questions on Semantic Dissonance and RAG Systems\n",
    "\n",
    "### Understanding the Problem\n",
    "1. What is semantic dissonance, and how does it affect the reliability of a RAG system?\n",
    "2. Why do general-purpose embedding models struggle with domain-specific tasks?\n",
    "3. In what ways can noisy cosine similarity scores mislead a RAG system’s performance?\n",
    "\n",
    "### Diagnosing Issues\n",
    "4. How can you determine if your RAG system is experiencing semantic dissonance?\n",
    "5. What are the limitations of using raw schema definitions for retrieval tasks?\n",
    "6. How might incomplete or poorly structured metadata contribute to irrelevant results?\n",
    "\n",
    "### Exploring Solutions\n",
    "7. How does enriching table schemas with descriptions or sample questions improve retrieval accuracy?\n",
    "8. What are the trade-offs between using sample questions alone versus combining schemas and metadata?\n",
    "9. How could domain-specific fine-tuning of embedding models reduce semantic dissonance?\n",
    "\n",
    "### Evaluating Strategies\n",
    "10. Which of the four retrieval strategies presented (schema only, schema + description, schema + description + sample questions, sample questions only) do you think is most applicable to your domain, and why?\n",
    "11. What additional metadata could be included to enhance the context for your RAG system?\n",
    "12. How can you balance the complexity of adding metadata with the potential improvement in system performance?\n",
    "\n",
    "### Broader Considerations\n",
    "13. In what ways might the structure and quality of your knowledge base impact the effectiveness of a RAG system?\n",
    "14. How can user feedback be incorporated into improving the ranking and retrieval strategies of your system?\n",
    "15. What role does explainability play in diagnosing and addressing semantic dissonance in RAG systems?\n",
    "\n",
    "### Practical Applications\n",
    "16. How would you adapt the strategies discussed here for a different domain, such as legal, healthcare, or customer support?\n",
    "17. If you were tasked with building a RAG system, what steps would you take to minimise semantic dissonance from the outset?\n",
    "18. What metrics would you use to evaluate the effectiveness of a RAG system in addressing semantic dissonance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reflection Questions and Suggested Answers on Semantic Dissonance and RAG Systems - This part will be hidden during accelerator session\n",
    " \n",
    "# Reflection Questions and Detailed Answers on Semantic Dissonance in the Furniture Industry (with Expanded Metrics for Evaluation)\n",
    "\n",
    "### Understanding the Problem\n",
    "\n",
    "1. **What is semantic dissonance, and how does it affect the reliability of a RAG system?**  \n",
    "   **Answer:** Semantic dissonance refers to a mismatch between the intent of a query, the system's understanding, and the retrieved results. In the furniture industry, this could mean a query like, *\"What materials are best for outdoor furniture?\"* retrieves results about indoor materials like velvet or leather instead of weather-resistant options like teak or aluminum. This reduces the system's reliability, leading to irrelevant answers that fail to meet user needs.\n",
    "\n",
    "2. **Why do general-purpose embedding models struggle with domain-specific tasks?**  \n",
    "   **Answer:** General-purpose models lack the nuanced understanding of industry-specific terminology and relationships. For example, in the furniture domain, the term \"chair\" might be associated with office chairs, dining chairs, or lounge chairs. Without domain-specific training, a general model might misinterpret *\"ergonomic chairs for remote work\"* and suggest irrelevant products like dining stools.\n",
    "\n",
    "3. **In what ways can noisy cosine similarity scores mislead a RAG system’s performance?**  \n",
    "   **Answer:** Noisy scores can rank irrelevant results higher. For instance, if the query is *\"Modern Scandinavian coffee tables,\"* and a table called *\"Traditional Oak Side Table\"* receives a higher cosine similarity score than a correctly labeled *\"Minimalist Birch Coffee Table,\"* the system fails to retrieve the most relevant item.\n",
    "\n",
    "---\n",
    "\n",
    "### Diagnosing Issues\n",
    "\n",
    "4. **How can you determine if your RAG system is experiencing semantic dissonance?**  \n",
    "   **Answer:** Test the system with real-world queries and evaluate retrieved results. Metrics like **context precision** and **context recall** are critical here:\n",
    "   - **Context precision**: The percentage of retrieved results that are relevant and match the intended query context. For instance, if a query like *\"Family-friendly sofas\"* retrieves five items, but only three are stain-resistant and durable, the precision is 60%.\n",
    "   - **Context recall**: The percentage of relevant items retrieved out of all possible relevant items in the database. If there are 10 family-friendly sofas in the database and the system retrieves five, the recall is 50%.\n",
    "   These metrics help identify whether irrelevant or missing results are contributing to semantic dissonance.\n",
    "\n",
    "5. **What are the limitations of using raw schema definitions for retrieval tasks?**  \n",
    "   **Answer:** Raw schemas like *“product_name,” “material,” “dimensions”* lack context. For example, a schema field labeled *“material”* doesn’t convey whether it pertains to upholstery, frame, or finish. This ambiguity hinders the system’s ability to match queries like *“durable wooden bed frames”* with the correct items.\n",
    "\n",
    "6. **How might incomplete or poorly structured metadata contribute to irrelevant results?**  \n",
    "   **Answer:** Poorly structured metadata leads to misalignment between user queries and product attributes. For instance, if metadata doesn’t specify whether wood is FSC-certified, a query like *\"Eco-friendly wooden chairs\"* might retrieve irrelevant results. Incomplete metadata can also introduce **bias**, such as favoring items with more detailed descriptions over simpler products that may still be relevant.\n",
    "\n",
    "---\n",
    "\n",
    "### Exploring Solutions\n",
    "\n",
    "7. **How does enriching table schemas with descriptions or sample questions improve retrieval accuracy?**  \n",
    "   **Answer:** Adding descriptions and sample questions helps clarify context. For instance, a schema enriched with a description like *“material: primary material used for the furniture frame”* and sample questions like *“What types of wood are used in this table?”* bridges the gap between user intent and data structure.\n",
    "\n",
    "8. **What are the trade-offs between using sample questions alone versus combining schemas and metadata?**  \n",
    "   **Answer:** Sample questions alone focus on user intent but might overlook broader data attributes. Combining them with schemas and metadata ensures comprehensive coverage. For example, a query like *“Stain-resistant dining chairs”* benefits from metadata about materials (e.g., treated fabric) alongside user-friendly sample questions.\n",
    "\n",
    "9. **How could domain-specific fine-tuning of embedding models reduce semantic dissonance?**  \n",
    "   **Answer:** Fine-tuning embeddings on furniture-specific datasets allows the model to learn nuances like *“Scandinavian design”* or *“ergonomic features.”* This improves retrieval accuracy by aligning vector representations with industry-relevant semantics.\n",
    "\n",
    "---\n",
    "\n",
    "### Evaluating Strategies\n",
    "\n",
    "10. **Which of the four retrieval strategies presented do you think is most applicable to your domain, and why?**  \n",
    "    **Answer:** In the furniture industry, *“schema + description + sample questions”* is most effective. This approach balances technical detail (schemas), semantic context (descriptions), and user perspective (sample questions). For example, a query like *“Compact dining tables for small apartments”* can leverage dimensions, product descriptions, and relevant questions.\n",
    "\n",
    "11. **What additional metadata could be included to enhance the context for your RAG system?**  \n",
    "    **Answer:** Include metadata like:\n",
    "    - **Usage context** (e.g., indoor/outdoor).\n",
    "    - **Design style** (e.g., modern, traditional).\n",
    "    - **Sustainability certifications** (e.g., FSC-certified wood).\n",
    "    - **Target audience** (e.g., family-friendly, workspace).\n",
    "    - **Bias-aware tags** (e.g., highlighting underrepresented product categories to promote fairness).\n",
    "    This allows queries like *“Eco-friendly cribs for toddlers”* to retrieve precise results.\n",
    "\n",
    "12. **How can you balance the complexity of adding metadata with the potential improvement in system performance?**  \n",
    "    **Answer:** Start with high-priority metadata (e.g., materials, dimensions, style) and expand iteratively based on user feedback. For example, if customers frequently ask about sustainable options, prioritize adding sustainability-related metadata.\n",
    "\n",
    "---\n",
    "\n",
    "### Broader Considerations\n",
    "\n",
    "13. **In what ways might the structure and quality of your knowledge base impact the effectiveness of a RAG system?**  \n",
    "    **Answer:** A well-structured knowledge base ensures data consistency and relevance. For example, categorizing products by *room type, material, and design style* allows a query like *“Mid-century modern armchairs for living rooms”* to return focused results. Metrics like **fairness** can ensure underrepresented product categories (e.g., budget-friendly or minority-sourced products) are equally considered.\n",
    "\n",
    "14. **How can user feedback be incorporated into improving the ranking and retrieval strategies of your system?**  \n",
    "    **Answer:** Gather feedback on retrieved results (e.g., thumbs up/down or relevance scores) and use it to refine ranking algorithms. Evaluate user feedback through metrics like:\n",
    "    - **Bias detection**: Check if certain categories (e.g., luxury furniture) are consistently overrepresented.\n",
    "    - **User satisfaction**: Measure how often users find what they need on the first try.\n",
    "\n",
    "15. **What role does explainability play in diagnosing and addressing semantic dissonance in RAG systems?**  \n",
    "    **Answer:** Explainability helps identify mismatches. For example, if a query retrieves irrelevant results, inspecting vector similarities, metadata mappings, and fairness metrics can reveal whether the issue lies in embeddings, metadata, or ranking logic.\n",
    "\n",
    "---\n",
    "\n",
    "### Practical Applications\n",
    "\n",
    "16. **If you were tasked with building a RAG system, what steps would you take to minimise semantic dissonance from the outset?**  \n",
    "    **Answer:** Steps include:\n",
    "    - Defining clear metadata for key attributes like style, material, and function.\n",
    "    - Fine-tuning embeddings with domain-specific data.\n",
    "    - Testing queries across common use cases (e.g., *“Space-saving furniture for studios”*).\n",
    "    - Incorporating metrics like **fairness** (e.g., ensuring products from small or minority-owned businesses are fairly represented).\n",
    "\n",
    "17. **What metrics would you use to evaluate the effectiveness of a RAG system in addressing semantic dissonance?**  \n",
    "    **Answer:** Metrics include:\n",
    "    - **Context precision**: Measures how well results align with query context.\n",
    "    - **Context recall**: Measures how many relevant items are retrieved out of all possible relevant items.\n",
    "    - **Fairness**: Evaluates if certain categories or groups (e.g., sustainable furniture) are underrepresented.\n",
    "    - **Bias detection**: Identifies systematic over- or under-representation of certain product types.\n",
    "    - **User satisfaction**: Tracks qualitative feedback and success rates.\n",
    "    - **Explainability**: Assesses how well the system justifies its ranking and retrieval logic.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ikea",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
