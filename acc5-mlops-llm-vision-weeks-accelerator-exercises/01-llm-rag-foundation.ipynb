{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Generation (RAG)\n",
    "\n",
    "## What is Retrieval Augmented Generation (RAG)?\n",
    "\n",
    "Retrieval Augmented Generation (RAG) is an artificial intelligence technique that combines the power of large language models (LLMs) with traditional information retrieval systems to improve the accuracy and relevance of generated answers.\n",
    "\n",
    "Large language models (LLMs), which are part of generative AI and are trained with huge volumes of data and billions of parameters, generate original answers and perform tasks such as answering questions, translating, and completing sentences. However, their knowledge is limited to the data they were trained on, which can result in reduced accuracy when specific subject knowledge or up-to-date information is needed.\n",
    "\n",
    "Retrieval Augmented Generation (RAG) overcomes these limitations by connecting the generative model to external information sources, such as databases, document repositories, or proprietary knowledge bases.\n",
    "\n",
    "RAG relies on two key components:\n",
    "- **Retrieval Model**: Searches through large databases or segmented knowledge bases.\n",
    "- **Generative Model**: Uses the retrieved information to generate natural language responses.\n",
    "\n",
    "This approach allows RAG to supplement an LLM's training data with specific, up-to-date information without the need for retraining, making it both efficient and cost-effective.\n",
    "\n",
    "### Why is RAG Important?\n",
    "\n",
    "RAG is particularly useful in scenarios where accessing recent or confidential information is critical, such as in corporate settings. It can be connected to internal knowledge databases, confidential documents, or specific business contexts, providing tailored responses.\n",
    "\n",
    "External sources are stored in vector databases, enabling the system to perform semantic or hybrid searches, retrieving only the most relevant information for a given query. This allows RAG to generate responses that are more accurate, relevant, and contextually aware.\n",
    "\n",
    "### Advantages of RAG:\n",
    "- **Customizes user experience** without high retraining costs.\n",
    "- **Provides up-to-date responses** by accessing external sources.\n",
    "- **Improves accuracy** in specialized domains.\n",
    "- **Saves computational resources** by avoiding unnecessary model retraining."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does Retrieval Augmented Generation (RAG) Work?\n",
    "\n",
    "The RAG process is structured in several stages to enhance the accuracy and relevance of responses generated by large language models (LLMs).\n",
    "\n",
    "### **RAG Process Overview**\n",
    "\n",
    "1. **Indexing and Data Preparation**\n",
    "   - Convert unstructured, semi-structured, or structured data into numerical embeddings.\n",
    "   - Store embeddings in a specialized vector database optimized for fast retrieval.\n",
    "\n",
    "2. **Retrieval**\n",
    "   - A retrieval model searches for relevant information from knowledge bases, external sources, or internal databases.\n",
    "   - The retrieved data is vectorized and ranked based on relevance.\n",
    "\n",
    "3. **Query Augmentation**\n",
    "   - The retrieved information is incorporated into the LLM's input context.\n",
    "   - Additional techniques, such as memory modules and domain adaptation, can further enhance responses.\n",
    "\n",
    "4. **Generation**\n",
    "   - The LLM generates a response based on both the original query and the retrieved information.\n",
    "   - Post-processing ensures grammatical correctness and removes redundancies.\n",
    "\n",
    "## **Retrieval Augmented Generation (RAG) Architecture**\n",
    "\n",
    "RAG architecture consists of two main components:\n",
    "1. **Retriever**: Responsible for fetching the most relevant documents from a knowledge base.\n",
    "2. **Generator**: Generates responses based on retrieved documents and the user query.\n",
    "\n",
    "### **Detailed Breakdown of the RAG Process**\n",
    "\n",
    "#### **1. Indexing and Data Preparation**\n",
    "Before the retrieval process begins, data must be prepared:\n",
    "- **Vectorization:** Data is transformed into high-dimensional embeddings that can be semantically searched.\n",
    "- **Storage in a Vector Database:** These embeddings are stored in a vector database that enables efficient search and retrieval.\n",
    "\n",
    "#### **2. Retrieval**\n",
    "- **Information Search:** The retriever scans the database for relevant information.\n",
    "- **Relevance Ranking:** Retrieved information is ranked and only the most relevant documents are selected.\n",
    "\n",
    "#### **3. Query Augmentation**\n",
    "- Retrieved documents are incorporated into the LLMâ€™s input.\n",
    "- The model's context is enriched with external data to improve accuracy.\n",
    "\n",
    "#### **4. Generation**\n",
    "- The LLM uses the enriched input to generate more accurate responses.\n",
    "- Post-processing ensures the response is structured and relevant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectives of this notebook\n",
    "- Compare responses of LLM vs RAG system\n",
    "- Evaluate how to use embeddings \n",
    "- Understand basic metrics of a RAG system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different ways to consume Embeddings models\n",
    "An embedding is a numerical representation of a piece of information, for example, text, documents, images, audio, etc. The representation captures the semantic meaning of what is being embedded, making it robust for many industry applications.\n",
    "\n",
    "Given the text \"What is the main benefit of voting?\", an embedding of the sentence could be represented in a vector space, for example, with a list of 384 numbers (for example, [0.84, 0.42, ..., 0.02]). Since this list captures the meaning, we can do exciting things, like calculating the distance between different embeddings to determine how well the meaning of two sentences matches.\n",
    "\n",
    "Embeddings are not limited to text! You can also create an embedding of an image (for example, a list of 384 numbers) and compare it with a text embedding to determine if a sentence describes the image. This concept is under powerful systems for image search, classification, description, and more!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ways to Consume Embeddings\n",
    "\n",
    "Usually, when weâ€™re developing an application that requires the use of an **embedding model**, our first inclination might be to install a library such as **sentence-transformers** and load the desired model within the same environment or hardware infrastructure. While this can be effective for smaller, proof-of-concept scenarios, it does present some limitations:\n",
    "\n",
    "- **Scalability**: As the volume of data or the number of requests grows, generating embeddings locally can become a bottleneck. You may need specialized hardware (e.g., GPUs) to maintain acceptable performance.\n",
    "- **Resource Contention**: On-prem or local deployments can block the main application logic if embedding generation is computationally expensive.\n",
    "- **Microservices Complexity**: Modern architectures often use microservices. If your embedding logic is tightly coupled with your main application code, scaling or updating only that component becomes more difficult.\n",
    "\n",
    "To address these challenges, many production systems **deploy the embedding model as a service**â€”a dedicated microservice or external API. This approach can be **scaled independently** and **monitored** with proper tools (e.g., logs, metrics, alerting) to ensure robust performance. Consuming embeddings via an API also grants flexibility to:\n",
    "\n",
    "1. **Switch Models Easily**: Just by changing the endpoint or model name, you can test or upgrade to a new embedding model.  \n",
    "2. **Distribute Loads**: You can deploy multiple replicas of the embedding service behind a load balancer, preventing any single instance from becoming overloaded.  \n",
    "3. **Version and Monitor**: Tracking requests, latencies, and model performance is simpler when embeddings are generated by a separate service with dedicated monitoring.  \n",
    "\n",
    "Below are **several approaches** to consuming embedding models, along with their benefits and trade-offs:\n",
    "\n",
    "\n",
    "#### 1. **Local Inference with a Library**\n",
    "- **How it works**: Install a library (like `sentence-transformers`), load a model locally in Python, and call it directly in your code.  \n",
    "- **Pros**:\n",
    "  - Straightforward setup for demos or prototyping.\n",
    "  - No network latency for inference.\n",
    "- **Cons**:\n",
    "  - May not scale well if you have many concurrent requests.\n",
    "  - Requires sufficient local GPU (or CPU) resources, which can be expensive or impractical.\n",
    "\n",
    "\n",
    "#### 2. **Hosted API (e.g., OpenAI Embedding Endpoint)**\n",
    "- **How it works**: You send text to a remote API that returns the embeddings, such as OpenAIâ€™s Embeddings endpoint.  \n",
    "- **Pros**:\n",
    "  - No need to manage your own GPU infrastructure.\n",
    "  - Easy to swap models by changing the endpoint or model name.\n",
    "  - Typically handles scaling for you.\n",
    "- **Cons**:\n",
    "  - Involves network latency and data privacy considerations (you are sending data externally).\n",
    "  - Cost depends on usage volume, can grow quickly.\n",
    "\n",
    "\n",
    "#### 3. **Self-Hosted Microservice**\n",
    "- **How it works**: Containerize your embedding model (e.g., using Docker and Kubernetes) and deploy it behind an API endpoint. Your application calls this service for embeddings.  \n",
    "- **Pros**:\n",
    "  - You maintain full control over the infrastructure and data privacy.\n",
    "  - Can be scaled independently with a load balancer or orchestration platform (e.g., Kubernetes).\n",
    "  - Facilitates advanced monitoring and versioning (each microservice can be updated or rolled back independently).\n",
    "- **Cons**:\n",
    "  - Requires DevOps expertise to manage containerization, orchestration, and scaling.\n",
    "  - Ongoing maintenance overhead.\n",
    "\n",
    "**It's important to notice MLOps team provide different endpoints that support any open-source embedding that can be consume in the same was as OpenAI**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "* Load the sentence-transformers model: \"sentence-transformers/all-MiniLM-L6-v2\".\n",
    "* Encode a list of example sentences into vector representations.\n",
    "* Print the shape of the generated embeddings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/acc-rag/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">ğŸ”„ Running Local Embedding Computation...</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mğŸ”„ Running Local Embedding Computation\u001b[0m\u001b[1;36m...\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Embeddings shape: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">384</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Embeddings shape: \u001b[1m(\u001b[0m\u001b[1;36m4\u001b[0m, \u001b[1;36m384\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Embeddings dimension: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">384</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Embeddings dimension: \u001b[1;36m384\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from rich.console import Console\n",
    "\n",
    "console = Console()\n",
    "\n",
    "# Example sentences\n",
    "sentences = [\n",
    "    \"That is a happy person.\",\n",
    "    \"That is a happy dog.\",\n",
    "    \"Today is a sunny day.\",\n",
    "    \"Artificial intelligence transforms industries.\"\n",
    "]\n",
    "\n",
    "# -------------------------\n",
    "# 1) Local Embedding (SentenceTransformer)\n",
    "# -------------------------\n",
    "console.print(\"\\n[bold cyan]ğŸ”„ Running Local Embedding Computation...[/bold cyan]\\n\")\n",
    "\n",
    "# âœ… TODO: Load the SentenceTransformer model -> https://sbert.net/\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "# âœ… TODO: Compute the embeddings for the given sentences\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "# âœ… TODO: Print the shape of the embeddings\n",
    "console.print(f\"Embeddings shape: {embeddings.shape}\")\n",
    "\n",
    "# âœ… QUESTION: What is the dimension of the embeddings? Why is it important?\n",
    "console.print(f\"Embeddings dimension: {embeddings.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "* Use OpenAI's Python client to connect to a local API server.\n",
    "* Send sentences for embedding generation.\n",
    "* Compare results with the local embeddings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">ğŸ”„ Running Remote Embedding Computation...</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mğŸ”„ Running Remote Embedding Computation\u001b[0m\u001b[1;36m...\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local vs. Remote Embeddings\n",
      "Local embeddings shape: (4, 384)\n",
      "Remote embeddings shape: (4, 384)\n",
      "Difference between local and remote embeddings: 0.517249709693715\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "console.print(\"\\n[bold cyan]ğŸ”„ Running Remote Embedding Computation...[/bold cyan]\\n\")\n",
    "\n",
    "# ASK MLOps team for these details\n",
    "API_KEY = \"eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICJTTzItd2puTVZOdTJGTGdiVXlXN3B6RW8wZ3hkTW5yMHY0MnVQS3pncDZVIn0.eyJleHAiOjE3NDAwNTM0MTgsImlhdCI6MTc0MDA0MjYxOCwiYXV0aF90aW1lIjoxNzQwMDQyNjE0LCJqdGkiOiJiNjdiYjcyNy01MzhiLTRhODEtYTBhNS1iZDliNTY3MDAyZTAiLCJpc3MiOiJodHRwczovL2Rldi5hdXRoLm1sb3BzLmluZ2thLmNvbS9yZWFsbXMvaXN0aW8iLCJhdWQiOiJhY2NvdW50Iiwic3ViIjoiNjdjMjYwMmQtMTA4Zi00MGVjLTlhMmQtNjk0ZWM4ZWEzZGRlIiwidHlwIjoiQmVhcmVyIiwiYXpwIjoiYXV0aGVudGljYXRvciIsInNlc3Npb25fc3RhdGUiOiI3ODUzNTc4Zi03OTJjLTQyMDktODk5Ny0yYjJjNDUzNTQ1ZmMiLCJhY3IiOiIxIiwiYWxsb3dlZC1vcmlnaW5zIjpbIi8qIl0sInJlYWxtX2FjY2VzcyI6eyJyb2xlcyI6WyJvZmZsaW5lX2FjY2VzcyIsInVtYV9hdXRob3JpemF0aW9uIiwiZGVmYXVsdC1yb2xlcy1pc3RpbyJdfSwicmVzb3VyY2VfYWNjZXNzIjp7ImFjY291bnQiOnsicm9sZXMiOlsibWFuYWdlLWFjY291bnQiLCJtYW5hZ2UtYWNjb3VudC1saW5rcyIsInZpZXctcHJvZmlsZSJdfX0sInNjb3BlIjoiZW1haWwgcHJvZmlsZSBvZmZsaW5lX2FjY2VzcyIsInNpZCI6Ijc4NTM1NzhmLTc5MmMtNDIwOS04OTk3LTJiMmM0NTM1NDVmYyIsImVtYWlsX3ZlcmlmaWVkIjpmYWxzZSwibmFtZSI6IkZlcm5hbmRvIERvcmFkbyBSdWVkYSIsImdyb3VwcyI6WyIvZGF0YXByb2Qtc3BhaW4tZGV2IiwiL2dsb2JhbC1sYW5ndWFnZS1zZXJ2aWNlcyIsIi9tbG9wcy1jb3JlIiwib2ZmbGluZV9hY2Nlc3MiLCJ1bWFfYXV0aG9yaXphdGlvbiIsImRlZmF1bHQtcm9sZXMtaXN0aW8iXSwicHJlZmVycmVkX3VzZXJuYW1lIjoiZmVybmFuZG9kb3JhZG8ucnVlZGFAaW5na2EuY29tIiwiZ2l2ZW5fbmFtZSI6IkZlcm5hbmRvIERvcmFkbyIsImZhbWlseV9uYW1lIjoiUnVlZGEiLCJlbWFpbCI6ImZlcm5hbmRvZG9yYWRvLnJ1ZWRhQGluZ2thLmNvbSJ9.MDyECkm99leVK0ba-OMRbj_LGdOCX_cUus9CEoVvkjYETtJJ-dD7jte7XWFM-jNYquZhox-h-iH7iOk-W4bCv9owrrj91PRzV4sHRXWdgbAzVTf2dNH7zP3_sa8TQlz12n-8QHSAvrkth3tGNV809aMUwcPZQgaGxUjahY6Ppx4yHDumF8xoRdMMUu90bYJSy3xhAJ4yBGwGCS5guhidD8NK1_oUh4dol3Mo8W5p-fmZDrzTD_8UTT3Iw4xDTBKnOdW4TCJRv4igrXB46v5Gzxj2xUHv4ysBNnOU7EYHlA0y6dyqzS0poA396WhC5xxGffQqeaqUzRQwDCvUq5csYQ\"\n",
    "\n",
    "# âœ… TODO: Initialize the OpenAI API client with correct settings\n",
    "# Parameters\n",
    "# - api_key: API_KEY\n",
    "# - base_url: \"https://mini-l6-v2-embedding-mlops-core.dev.inference.genai.mlops.ingka.com/v1\"\n",
    "client = openai.OpenAI(\n",
    "    api_key=API_KEY,\n",
    "    base_url=\"https://mini-l6-v2-embedding-mlops-core.dev.inference.genai.mlops.ingka.com/v1\"\n",
    ")\n",
    "\n",
    "# âœ… TODO: Compute embeddings using the remote API \n",
    "# TIP: Use this function: client.embeddings.create(input=text, model=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "# DOC: https://platform.openai.com/docs/guides/embeddings\n",
    "\n",
    "remote_embeddings = []\n",
    "for text in sentences:\n",
    "    response = client.embeddings.create(input=text, model=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    remote_embeddings.append(response.data[0].embedding)\n",
    "\n",
    "# âœ… QUESTION: Compare the embeddings from local and remote sources. Are they identical?\n",
    "print(\"Local vs. Remote Embeddings\")\n",
    "print(\"Local embeddings shape:\", embeddings.shape)\n",
    "print(\"Remote embeddings shape:\", np.array(remote_embeddings).shape) \n",
    "\n",
    "#check if the embdeddings are the same\n",
    "diff = np.array(remote_embeddings) - embeddings\n",
    "print(\"Difference between local and remote embeddings:\", np.sum(diff))\n",
    "\n",
    "# âœ… QUESTION: What are the potential benefits of using a remote API for embeddings?\n",
    "# âœ… QUESTION: Can embeddings be compared using cosine similarity? How would you implement this?\n",
    "# âœ… QUESTION: How does the choice of an embedding model impact the performance and quality of embeddings?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differentiating LLM Responses vs. RAG Responses\n",
    "\n",
    "When building a chatbotâ€”say, for a company like IKEAâ€”you can **ask the same question** in two different ways:\n",
    "\n",
    "1. **LLM-Only Prompt**: Send the userâ€™s query directly to the model, with no additional context.\n",
    "2. **RAG Prompt**: Fetch relevant context (e.g., details about IKEA products) first, then append that context to the userâ€™s query before sending it to the model.\n",
    "\n",
    "This **difference** in prompts highlights how **Retrieval-Augmented Generation (RAG)** uses **external data** to produce more **grounded** answers, whereas an **LLM-Only** approach relies **solely** on its internal training.\n",
    "\n",
    "Below, we show **two prompts** to illustrate the difference. Both revolve around a user asking for advice on IKEA products. In practice, youâ€™d perform a retrieval step (embedding + similarity search) in RAG, then inject the retrieved context into the prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. LLM-Only Prompt\n",
    "\n",
    "In this version, the chatbot receives **no external context**. The system role simply sets the style or domain of the assistant (e.g., â€œan IKEA specialistâ€), and the userâ€™s question is asked plainly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions:\n",
    "* Define a system message that sets the assistant's role.\n",
    "* Add a user message containing the query (e.g., finding a bed under $300).\n",
    "* Send the message to the LLM and retrieve the response.\n",
    "* Print metadata such as the model name, tokens used, and completion status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">ğŸ”„ Sending LLM-only request...</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mğŸ”„ Sending LLM-only request\u001b[0m\u001b[1;36m...\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletion</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-cbd52b55-de41-421d-a16c-42faa19a5c71'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">choices</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Choice</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">finish_reason</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'stop'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">index</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">logprobs</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletionMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"We have several bed options available at IKEA that are under $300. \\n\\nOne option could be</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the FYNDIG bedframe in white or black, it's made of metal and comes with a bed headboard. The price for this frame </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">is around $190 for a twin or full size mattress and $220 for a queen size.\\n\\nAnother option could be the BJURSTA </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">frame in white or black it has a similar design to the FYNDIG frame and costs around $230 for a queen size and $190</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">for twin size but it also comes with a slatted base for under the mattress for ventilation.\\n\\nHowever, I'd like to</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">bring to your attention of our latest FYNDIG 3 Drawer Bedframe, option this would also have space under it to add </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">any further storage with 3 drawers plus headboard so it starts at $279.\\n\\nWould you prefer any of these options or</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">would you like to explore more choices within our bed collections?\"</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">refusal</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">role</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">audio</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">function_call</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">reasoning_content</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">stop_reason</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1740047098</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'meta-llama/Meta-Llama-3.1-8B-Instruct'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chat.completion'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">service_tier</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">system_fingerprint</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">usage</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CompletionUsage</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">193</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">54</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">total_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">247</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">prompt_logprobs</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mChatCompletion\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-cbd52b55-de41-421d-a16c-42faa19a5c71'\u001b[0m,\n",
       "    \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mChoice\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mfinish_reason\u001b[0m=\u001b[32m'stop'\u001b[0m,\n",
       "            \u001b[33mindex\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "            \u001b[33mlogprobs\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mmessage\u001b[0m=\u001b[1;35mChatCompletionMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mcontent\u001b[0m=\u001b[32m\"We\u001b[0m\u001b[32m have several bed options available at IKEA that are under $300. \\n\\nOne option could be\u001b[0m\n",
       "\u001b[32mthe FYNDIG bedframe in white or black, it's made of metal and comes with a bed headboard. The price for this frame \u001b[0m\n",
       "\u001b[32mis around $190 for a twin or full size mattress and $220 for a queen size.\\n\\nAnother option could be the BJURSTA \u001b[0m\n",
       "\u001b[32mframe in white or black it has a similar design to the FYNDIG frame and costs around $230 for a queen size and $190\u001b[0m\n",
       "\u001b[32mfor twin size but it also comes with a slatted base for under the mattress for ventilation.\\n\\nHowever, I'd like to\u001b[0m\n",
       "\u001b[32mbring to your attention of our latest FYNDIG 3 Drawer Bedframe, option this would also have space under it to add \u001b[0m\n",
       "\u001b[32many further storage with 3 drawers plus headboard so it starts at $279.\\n\\nWould you prefer any of these options or\u001b[0m\n",
       "\u001b[32mwould you like to explore more choices within our bed collections?\"\u001b[0m,\n",
       "                \u001b[33mrefusal\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mrole\u001b[0m=\u001b[32m'assistant'\u001b[0m,\n",
       "                \u001b[33maudio\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mfunction_call\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mtool_calls\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "                \u001b[33mreasoning_content\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[33mstop_reason\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33mcreated\u001b[0m=\u001b[1;36m1740047098\u001b[0m,\n",
       "    \u001b[33mmodel\u001b[0m=\u001b[32m'meta-llama/Meta-Llama-3.1-8B-Instruct'\u001b[0m,\n",
       "    \u001b[33mobject\u001b[0m=\u001b[32m'chat.completion'\u001b[0m,\n",
       "    \u001b[33mservice_tier\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33msystem_fingerprint\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33musage\u001b[0m=\u001b[1;35mCompletionUsage\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mcompletion_tokens\u001b[0m=\u001b[1;36m193\u001b[0m,\n",
       "        \u001b[33mprompt_tokens\u001b[0m=\u001b[1;36m54\u001b[0m,\n",
       "        \u001b[33mtotal_tokens\u001b[0m=\u001b[1;36m247\u001b[0m,\n",
       "        \u001b[33mcompletion_tokens_details\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33mprompt_tokens_details\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[33mprompt_logprobs\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
       "â”‚ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">LLM-Only Response from model:</span> meta-llama/Meta-Llama-3.1-8B-Instruct â”‚\n",
       "â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
       "â”‚ \u001b[1;32mLLM-Only Response from model:\u001b[0m meta-llama/Meta-Llama-3.1-8B-Instruct â”‚\n",
       "â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                 LLM-Only Response Metadata                  </span>\n",
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Field             </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Value                                 </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> Model             </span>â”‚<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> meta-llama/Meta-Llama-3.1-8B-Instruct </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> Finish Reason     </span>â”‚<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> stop                                  </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> Tokens Used       </span>â”‚<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> 247                                   </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> Prompt Tokens     </span>â”‚<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> 54                                    </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> Completion Tokens </span>â”‚<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> 193                                   </span>â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                 LLM-Only Response Metadata                  \u001b[0m\n",
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mField            \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mValue                                \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36mModel            \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[37m \u001b[0m\u001b[37mmeta-llama/Meta-Llama-3.1-8B-Instruct\u001b[0m\u001b[37m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36mFinish Reason    \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[37m \u001b[0m\u001b[37mstop                                 \u001b[0m\u001b[37m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36mTokens Used      \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[37m \u001b[0m\u001b[37m247                                  \u001b[0m\u001b[37m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36mPrompt Tokens    \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[37m \u001b[0m\u001b[37m54                                   \u001b[0m\u001b[37m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36mCompletion Tokens\u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[37m \u001b[0m\u001b[37m193                                  \u001b[0m\u001b[37m \u001b[0mâ”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ¤– LLM-Only Response â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">We have several bed options available at IKEA that are under $300. </span>                                             <span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">One option could be the FYNDIG bedframe in white or black, it's made of metal and comes with a bed headboard. </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">The price for this frame is around $190 for a twin or full size mattress and $220 for a queen size.</span>             <span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">Another option could be the BJURSTA frame in white or black it has a similar design to the FYNDIG frame and </span>    <span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">costs around $230 for a queen size and $190 for twin size but it also comes with a slatted base for under the </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">mattress for ventilation.</span>                                                                                       <span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">However, I'd like to bring to your attention of our latest FYNDIG 3 Drawer Bedframe, option this would also </span>    <span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">have space under it to add any further storage with 3 drawers plus headboard so it starts at $279.</span>              <span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">Would you prefer any of these options or would you like to explore more choices within our bed collections?</span>     <span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mâ•­â”€\u001b[0m\u001b[34mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[34m ğŸ¤– LLM-Only Response \u001b[0m\u001b[34mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[34mâ”€â•®\u001b[0m\n",
       "\u001b[34mâ”‚\u001b[0m \u001b[1;37mWe have several bed options available at IKEA that are under $300. \u001b[0m                                             \u001b[34mâ”‚\u001b[0m\n",
       "\u001b[34mâ”‚\u001b[0m                                                                                                                 \u001b[34mâ”‚\u001b[0m\n",
       "\u001b[34mâ”‚\u001b[0m \u001b[1;37mOne option could be the FYNDIG bedframe in white or black, it's made of metal and comes with a bed headboard. \u001b[0m  \u001b[34mâ”‚\u001b[0m\n",
       "\u001b[34mâ”‚\u001b[0m \u001b[1;37mThe price for this frame is around $190 for a twin or full size mattress and $220 for a queen size.\u001b[0m             \u001b[34mâ”‚\u001b[0m\n",
       "\u001b[34mâ”‚\u001b[0m                                                                                                                 \u001b[34mâ”‚\u001b[0m\n",
       "\u001b[34mâ”‚\u001b[0m \u001b[1;37mAnother option could be the BJURSTA frame in white or black it has a similar design to the FYNDIG frame and \u001b[0m    \u001b[34mâ”‚\u001b[0m\n",
       "\u001b[34mâ”‚\u001b[0m \u001b[1;37mcosts around $230 for a queen size and $190 for twin size but it also comes with a slatted base for under the \u001b[0m  \u001b[34mâ”‚\u001b[0m\n",
       "\u001b[34mâ”‚\u001b[0m \u001b[1;37mmattress for ventilation.\u001b[0m                                                                                       \u001b[34mâ”‚\u001b[0m\n",
       "\u001b[34mâ”‚\u001b[0m                                                                                                                 \u001b[34mâ”‚\u001b[0m\n",
       "\u001b[34mâ”‚\u001b[0m \u001b[1;37mHowever, I'd like to bring to your attention of our latest FYNDIG 3 Drawer Bedframe, option this would also \u001b[0m    \u001b[34mâ”‚\u001b[0m\n",
       "\u001b[34mâ”‚\u001b[0m \u001b[1;37mhave space under it to add any further storage with 3 drawers plus headboard so it starts at $279.\u001b[0m              \u001b[34mâ”‚\u001b[0m\n",
       "\u001b[34mâ”‚\u001b[0m                                                                                                                 \u001b[34mâ”‚\u001b[0m\n",
       "\u001b[34mâ”‚\u001b[0m \u001b[1;37mWould you prefer any of these options or would you like to explore more choices within our bed collections?\u001b[0m     \u001b[34mâ”‚\u001b[0m\n",
       "\u001b[34mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from rich.console import Console\n",
    "from rich.table import Table\n",
    "from rich.panel import Panel\n",
    "from rich.text import Text\n",
    "from rich import print\n",
    "\n",
    "console = Console()\n",
    "\n",
    "base_url = \"https://llama31-inst-mlops-core.dev.inference.genai.mlops.ingka.com/v1\"\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=API_KEY,\n",
    "    base_url=base_url\n",
    ")\n",
    "\n",
    "# âœ… TODO: Define the LLM-only system prompt\n",
    "message_llm_only = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            \"You are an expert IKEA assistant helping a customer with questions.\"\n",
    "        )\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": (\n",
    "            \"Find a bed under $300\"\n",
    "        )\n",
    "    }\n",
    "]\n",
    "\n",
    "console.print(\"\\n[bold cyan]ğŸ”„ Sending LLM-only request...[/bold cyan]\\n\")\n",
    "\n",
    "# âœ… TODO: Send the request to the model and get a response -> https://platform.openai.com/docs/quickstart\n",
    "completion_llm_only = client.chat.completions.create(\n",
    "    messages=message_llm_only,\n",
    "    model=\"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
    ")\n",
    "\n",
    "print(completion_llm_only)\n",
    "# âœ… TODO: Extract response details\n",
    "generated_text_llm = completion_llm_only.choices[0].message.content\n",
    "finish_reason_llm = completion_llm_only.choices[0].finish_reason\n",
    "model_name_llm = completion_llm_only.model\n",
    "\n",
    "# âœ… TODO: Display model metadata\n",
    "console.print(Panel(f\"[bold green]LLM-Only Response from model:[/bold green] {model_name_llm}\", expand=False))\n",
    "\n",
    "table_llm = Table(title=\"LLM-Only Response Metadata\", show_header=True, header_style=\"bold magenta\")\n",
    "table_llm.add_column(\"Field\", justify=\"left\", style=\"cyan\", no_wrap=True)\n",
    "table_llm.add_column(\"Value\", justify=\"left\", style=\"white\")\n",
    "\n",
    "table_llm.add_row(\"Model\", model_name_llm)\n",
    "table_llm.add_row(\"Finish Reason\", finish_reason_llm if finish_reason_llm else \"Unknown\")\n",
    "table_llm.add_row(\"Tokens Used\", str(completion_llm_only.usage.total_tokens))\n",
    "table_llm.add_row(\"Prompt Tokens\", str(completion_llm_only.usage.prompt_tokens))\n",
    "table_llm.add_row(\"Completion Tokens\", str(completion_llm_only.usage.completion_tokens))\n",
    "\n",
    "console.print(table_llm)\n",
    "console.print(Panel(Text(generated_text_llm, style=\"bold white\"), title=\"ğŸ¤– LLM-Only Response\", border_style=\"blue\"))\n",
    "\n",
    "# âœ… QUESTION: How does the response look? Is it generic or specific? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG-Based Response\n",
    "\n",
    "#### Instructions\n",
    "* Retrieve relevant context (e.g., IKEA product details).\n",
    "* Append the retrieved context to the userâ€™s question.\n",
    "* Send the modified prompt to the LLM.\n",
    "* Compare the response with and without RAG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">ğŸ”„ Sending RAG-augmented request...</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mğŸ”„ Sending RAG-augmented request\u001b[0m\u001b[1;36m...\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
       "â”‚ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">RAG Response from model:</span> meta-llama/Meta-Llama-3.1-8B-Instruct â”‚\n",
       "â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
       "â”‚ \u001b[1;32mRAG Response from model:\u001b[0m meta-llama/Meta-Llama-3.1-8B-Instruct â”‚\n",
       "â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                    RAG Response Metadata                    </span>\n",
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Field             </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Value                                 </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> Model             </span>â”‚<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> meta-llama/Meta-Llama-3.1-8B-Instruct </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> Finish Reason     </span>â”‚<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> stop                                  </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> Tokens Used       </span>â”‚<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> 427                                   </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> Prompt Tokens     </span>â”‚<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> 126                                   </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> Completion Tokens </span>â”‚<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> 301                                   </span>â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                    RAG Response Metadata                    \u001b[0m\n",
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mField            \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mValue                                \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36mModel            \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[37m \u001b[0m\u001b[37mmeta-llama/Meta-Llama-3.1-8B-Instruct\u001b[0m\u001b[37m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36mFinish Reason    \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[37m \u001b[0m\u001b[37mstop                                 \u001b[0m\u001b[37m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36mTokens Used      \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[37m \u001b[0m\u001b[37m427                                  \u001b[0m\u001b[37m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36mPrompt Tokens    \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[37m \u001b[0m\u001b[37m126                                  \u001b[0m\u001b[37m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36mCompletion Tokens\u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[37m \u001b[0m\u001b[37m301                                  \u001b[0m\u001b[37m \u001b[0mâ”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ¤– RAG-Augmented Response â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">Based on your budget of $300, I can suggest a few bed options from IKEA that are below this price point. Here </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">are a few options:</span>                                                                                              <span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">1. **LURÃ–Y 2-drawer bed frame**: This bed frame has two storage drawers and comes in various sizes, including </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">160x200 cm that you mentioned. The price is around $130-$180 (depending on the size).</span>                           <span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">2. **MALM 3-drawer bed frame**: While the 4-drawer version is outside your budget, the 3-drawer version might </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">be more affordable. Prices start at around $200-$250 (depending on the size).</span>                                   <span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">3. **SVENSKA 3-drawer bed frame**: Another affordable option, the SVENSKA 3-drawer bed frame offers storage and</span> <span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">a clean design. The price is around $150-$200 (depending on the size).</span>                                          <span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">4. **BJURSTA 2-drawer bed frame**: For a more rustic look, the BJURSTA 2-drawer bed frame might be a great </span>     <span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">option. Prices start at around $100-$150 (depending on the size).</span>                                               <span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">5. **MALM basic bed frame**: If you're not looking for storage, the MALM basic bed frame is a simple and </span>       <span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">affordable option. Prices start at around $80-$120 (depending on the size).</span>                                     <span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">Please note that prices may vary depending on your location and availability. I can also check if there are any</span> <span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">discounts or promotions available.</span>                                                                              <span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mâ•­â”€\u001b[0m\u001b[34mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[34m ğŸ¤– RAG-Augmented Response \u001b[0m\u001b[34mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[34mâ”€â•®\u001b[0m\n",
       "\u001b[34mâ”‚\u001b[0m \u001b[1;37mBased on your budget of $300, I can suggest a few bed options from IKEA that are below this price point. Here \u001b[0m  \u001b[34mâ”‚\u001b[0m\n",
       "\u001b[34mâ”‚\u001b[0m \u001b[1;37mare a few options:\u001b[0m                                                                                              \u001b[34mâ”‚\u001b[0m\n",
       "\u001b[34mâ”‚\u001b[0m                                                                                                                 \u001b[34mâ”‚\u001b[0m\n",
       "\u001b[34mâ”‚\u001b[0m \u001b[1;37m1. **LURÃ–Y 2-drawer bed frame**: This bed frame has two storage drawers and comes in various sizes, including \u001b[0m  \u001b[34mâ”‚\u001b[0m\n",
       "\u001b[34mâ”‚\u001b[0m \u001b[1;37m160x200 cm that you mentioned. The price is around $130-$180 (depending on the size).\u001b[0m                           \u001b[34mâ”‚\u001b[0m\n",
       "\u001b[34mâ”‚\u001b[0m \u001b[1;37m2. **MALM 3-drawer bed frame**: While the 4-drawer version is outside your budget, the 3-drawer version might \u001b[0m  \u001b[34mâ”‚\u001b[0m\n",
       "\u001b[34mâ”‚\u001b[0m \u001b[1;37mbe more affordable. Prices start at around $200-$250 (depending on the size).\u001b[0m                                   \u001b[34mâ”‚\u001b[0m\n",
       "\u001b[34mâ”‚\u001b[0m \u001b[1;37m3. **SVENSKA 3-drawer bed frame**: Another affordable option, the SVENSKA 3-drawer bed frame offers storage and\u001b[0m \u001b[34mâ”‚\u001b[0m\n",
       "\u001b[34mâ”‚\u001b[0m \u001b[1;37ma clean design. The price is around $150-$200 (depending on the size).\u001b[0m                                          \u001b[34mâ”‚\u001b[0m\n",
       "\u001b[34mâ”‚\u001b[0m \u001b[1;37m4. **BJURSTA 2-drawer bed frame**: For a more rustic look, the BJURSTA 2-drawer bed frame might be a great \u001b[0m     \u001b[34mâ”‚\u001b[0m\n",
       "\u001b[34mâ”‚\u001b[0m \u001b[1;37moption. Prices start at around $100-$150 (depending on the size).\u001b[0m                                               \u001b[34mâ”‚\u001b[0m\n",
       "\u001b[34mâ”‚\u001b[0m \u001b[1;37m5. **MALM basic bed frame**: If you're not looking for storage, the MALM basic bed frame is a simple and \u001b[0m       \u001b[34mâ”‚\u001b[0m\n",
       "\u001b[34mâ”‚\u001b[0m \u001b[1;37maffordable option. Prices start at around $80-$120 (depending on the size).\u001b[0m                                     \u001b[34mâ”‚\u001b[0m\n",
       "\u001b[34mâ”‚\u001b[0m                                                                                                                 \u001b[34mâ”‚\u001b[0m\n",
       "\u001b[34mâ”‚\u001b[0m \u001b[1;37mPlease note that prices may vary depending on your location and availability. I can also check if there are any\u001b[0m \u001b[34mâ”‚\u001b[0m\n",
       "\u001b[34mâ”‚\u001b[0m \u001b[1;37mdiscounts or promotions available.\u001b[0m                                                                              \u001b[34mâ”‚\u001b[0m\n",
       "\u001b[34mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# âœ… TODO: Simulated RAG retrieval (normally, retrieved from a database or vector store) -> https://www.ikea.com/es/es/cat/productos-products/\n",
    "retrieved_context = (\n",
    "    \"BRIMNES, Bed frame with storage, white/LurÃ¶y, 160x200 cm 249â‚¬\"\n",
    "    \"NATTJASMIN Duvet cover and 2 pillowcases, white, 240x220/50x60 cm\"\n",
    "    \"MALM Bed frame with 4 drawers, white/LÃ¶nset, 180x200 cm 549â‚¬\"\n",
    ")\n",
    "\n",
    "# âœ… TODO: Define the RAG-augmented system prompt\n",
    "message_rag = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            \"You are an expert IKEA assistant helping a customer with questions.\"\n",
    "        )\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": (\n",
    "            \"Find beds below $300\"\n",
    "            f\"[Context]: {retrieved_context}\\n\\n\"\n",
    "        )\n",
    "    }\n",
    "]\n",
    "\n",
    "console.print(\"\\n[bold cyan]ğŸ”„ Sending RAG-augmented request...[/bold cyan]\\n\")\n",
    "\n",
    "# âœ… TODO: Send request with extra context -> https://platform.openai.com/docs/quickstart\n",
    "completion_rag = client.chat.completions.create(\n",
    "    messages=message_rag,\n",
    "    model=\"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
    ")\n",
    "\n",
    "# âœ… TODO: Extract response details\n",
    "generated_text_rag = completion_rag.choices[0].message.content\n",
    "finish_reason_rag = completion_rag.choices[0].finish_reason\n",
    "model_name_rag = completion_rag.model\n",
    "\n",
    "console.print(Panel(f\"[bold green]RAG Response from model:[/bold green] {model_name_rag}\", expand=False))\n",
    "\n",
    "# âœ… TODO: Display metadata for RAG response\n",
    "table_rag = Table(title=\"RAG Response Metadata\", show_header=True, header_style=\"bold magenta\")\n",
    "table_rag.add_column(\"Field\", justify=\"left\", style=\"cyan\", no_wrap=True)\n",
    "table_rag.add_column(\"Value\", justify=\"left\", style=\"white\")\n",
    "\n",
    "table_rag.add_row(\"Model\", model_name_rag)\n",
    "table_rag.add_row(\"Finish Reason\", finish_reason_rag if finish_reason_rag else \"Unknown\")\n",
    "table_rag.add_row(\"Tokens Used\", str(completion_rag.usage.total_tokens))\n",
    "table_rag.add_row(\"Prompt Tokens\", str(completion_rag.usage.prompt_tokens))\n",
    "table_rag.add_row(\"Completion Tokens\", str(completion_rag.usage.completion_tokens))\n",
    "\n",
    "console.print(table_rag)\n",
    "console.print(Panel(Text(generated_text_rag, style=\"bold white\"), title=\"ğŸ¤– RAG-Augmented Response\", border_style=\"blue\"))\n",
    "\n",
    "# âœ… QUESTION: How did the RAG-augmented response differ from the LLM-only response?\n",
    "# âœ… QUESTION: Why does adding context help the LLM provide a more accurate response?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acc-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
